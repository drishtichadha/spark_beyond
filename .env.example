# Spark Tune API Environment Configuration
# Copy this file to .env and customize for your environment

# ============================================================================
# SECURITY CONFIGURATION
# ============================================================================

# CORS Origins (comma-separated list of allowed origins)
# In production, specify only your frontend domain(s)
# Example: CORS_ORIGINS=https://app.sparktune.com,https://www.sparktune.com
CORS_ORIGINS=http://localhost:5173,http://localhost:3000,http://127.0.0.1:5173

# Allowed Data Directories (comma-separated absolute paths)
# Only files within these directories can be accessed
# CRITICAL: Set this to restrict file access in production
# Example: ALLOWED_DATA_DIRS=/app/data/uploads,/app/data/public
ALLOWED_DATA_DIRS=./data,./backend/data

# ============================================================================
# APPLICATION CONFIGURATION
# ============================================================================

# API Server
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=true

# Logging Level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# ============================================================================
# SESSION MANAGEMENT
# ============================================================================

# Redis Configuration (for session storage)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=
REDIS_SSL=false

# Session Storage
SESSION_STORAGE_PATH=./data/sessions
SESSION_TTL_SECONDS=86400  # 24 hours

# ============================================================================
# SPARK CONFIGURATION
# ============================================================================

# Spark Driver Memory
SPARK_DRIVER_MEMORY=4g

# Spark Master (local[*] for all cores, or specify cluster)
SPARK_MASTER=local[*]

# Spark Application Name
SPARK_APP_NAME=Spark Tune API

# ============================================================================
# DATA PROCESSING LIMITS
# ============================================================================

# Resource Tier (production, development, enterprise)
# Controls all resource limits including file size, row count, and features
# production: 500MB files, 1M rows (default)
# development: 1GB files, 5M rows
# enterprise: 2GB files, 5M rows, extended timeouts
RESOURCE_TIER=production

# File Size Limits (enforced at API level)
# Maximum CSV file size in MB
# Default: 500MB (production), 1000MB (development), 2000MB (enterprise)
# MAX_FILE_SIZE_MB=500

# Row Count Limits (enforced during data loading)
# Maximum number of rows to load from dataset
# Default: 1M (production), 5M (development/enterprise)
# Absolute hard limit: 10M rows across all tiers
# MAX_ROWS=1000000

# Maximum rows for Pandas conversion (to prevent memory issues)
MAX_PANDAS_ROWS=100000

# Maximum data profiling rows (enforced: 1-100K)
MAX_PROFILE_ROWS=50000

# Feature Generation Limits
# MAX_GENERATED_FEATURES=1000
# MAX_FEATURE_INTERACTIONS=500

# Training Time Limits (seconds)
# MAX_TRAINING_TIME=3600  # 1 hour
# MAX_AUTOML_TIME=600     # 10 minutes

# ============================================================================
# DEVELOPMENT SETTINGS (remove in production)
# ============================================================================

# Enable debug mode (DO NOT USE IN PRODUCTION)
DEBUG=false

# Allow hot reload (development only)
RELOAD=true
