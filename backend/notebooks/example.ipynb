{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "545c087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fdbf221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7ad9a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "26/01/15 08:11:45 WARN Utils: Your hostname, Yadvendras-MacBook-Pro.local, resolves to a loopback address: 127.0.0.1; using 192.168.0.5 instead (on interface en0)\n",
      "26/01/15 08:11:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/15 08:11:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(age=56, job='housemaid', marital='married', education='basic.4y', default='no', housing='no', loan='no', contact='telephone', month='may', day_of_week='mon', duration=261, campaign=1, pdays=999, previous=0, poutcome='nonexistent', emp.var.rate=1.1, cons.price.idx=93.994, cons.conf.idx=-36.4, euribor3m=4.857, nr.employed=5191.0, y='no')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"testing testing 123\").getOrCreate()\n",
    "\n",
    "df = spark.read.options(header=True, inferSchema='True',delimiter=',').csv(\"data/bank-additional-full.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a099a036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'default',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'month',\n",
       " 'day_of_week',\n",
       " 'duration',\n",
       " 'campaign',\n",
       " 'pdays',\n",
       " 'previous',\n",
       " 'poutcome',\n",
       " 'emp.var.rate',\n",
       " 'cons.price.idx',\n",
       " 'cons.conf.idx',\n",
       " 'euribor3m',\n",
       " 'nr.employed',\n",
       " 'y']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "760d058f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=56, job='housemaid', marital='married', education='basic.4y', default='no', housing='no', loan='no', contact='telephone', month='may', day_of_week='mon', duration=261, campaign=1, pdays=999, previous=0, poutcome='nonexistent', emp.var.rate=1.1, cons.price.idx=93.994, cons.conf.idx=-36.4, euribor3m=4.857, nr.employed=5191.0, y='no'),\n",
       " Row(age=57, job='services', marital='married', education='high.school', default='unknown', housing='no', loan='no', contact='telephone', month='may', day_of_week='mon', duration=149, campaign=1, pdays=999, previous=0, poutcome='nonexistent', emp.var.rate=1.1, cons.price.idx=93.994, cons.conf.idx=-36.4, euribor3m=4.857, nr.employed=5191.0, y='no'),\n",
       " Row(age=37, job='services', marital='married', education='high.school', default='no', housing='yes', loan='no', contact='telephone', month='may', day_of_week='mon', duration=226, campaign=1, pdays=999, previous=0, poutcome='nonexistent', emp.var.rate=1.1, cons.price.idx=93.994, cons.conf.idx=-36.4, euribor3m=4.857, nr.employed=5191.0, y='no'),\n",
       " Row(age=40, job='admin.', marital='married', education='basic.6y', default='no', housing='no', loan='no', contact='telephone', month='may', day_of_week='mon', duration=151, campaign=1, pdays=999, previous=0, poutcome='nonexistent', emp.var.rate=1.1, cons.price.idx=93.994, cons.conf.idx=-36.4, euribor3m=4.857, nr.employed=5191.0, y='no'),\n",
       " Row(age=56, job='services', marital='married', education='high.school', default='no', housing='no', loan='yes', contact='telephone', month='may', day_of_week='mon', duration=307, campaign=1, pdays=999, previous=0, poutcome='nonexistent', emp.var.rate=1.1, cons.price.idx=93.994, cons.conf.idx=-36.4, euribor3m=4.857, nr.employed=5191.0, y='no')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254e1307",
   "metadata": {},
   "source": [
    "Problem Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3cb94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.core.discovery import Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ef65989",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = Problem(target=\"y\", type=\"classification\", desired_result=\"yes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e54819b",
   "metadata": {},
   "source": [
    "Schema Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c82ff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.core.discovery import SchemaChecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afa73465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "string ['string', 'char', 'varchar', 'bool', 'int']\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'categorical': [{'col_name': 'job',\n",
       "   'description': {'count_distinct': 12, 'count': 41188, 'null_count': 0},\n",
       "   'value_descriptions': [{'job': 'management',\n",
       "     'count': 2924,\n",
       "     'null_count': 0},\n",
       "    {'job': 'retired', 'count': 1720, 'null_count': 0},\n",
       "    {'job': 'unknown', 'count': 330, 'null_count': 0},\n",
       "    {'job': 'self-employed', 'count': 1421, 'null_count': 0},\n",
       "    {'job': 'student', 'count': 875, 'null_count': 0},\n",
       "    {'job': 'blue-collar', 'count': 9254, 'null_count': 0},\n",
       "    {'job': 'entrepreneur', 'count': 1456, 'null_count': 0},\n",
       "    {'job': 'admin.', 'count': 10422, 'null_count': 0},\n",
       "    {'job': 'technician', 'count': 6743, 'null_count': 0},\n",
       "    {'job': 'services', 'count': 3969, 'null_count': 0},\n",
       "    {'job': 'housemaid', 'count': 1060, 'null_count': 0},\n",
       "    {'job': 'unemployed', 'count': 1014, 'null_count': 0}]},\n",
       "  {'col_name': 'marital',\n",
       "   'description': {'count_distinct': 4, 'count': 41188, 'null_count': 0},\n",
       "   'value_descriptions': [{'marital': 'unknown', 'count': 80, 'null_count': 0},\n",
       "    {'marital': 'divorced', 'count': 4612, 'null_count': 0},\n",
       "    {'marital': 'married', 'count': 24928, 'null_count': 0},\n",
       "    {'marital': 'single', 'count': 11568, 'null_count': 0}]},\n",
       "  {'col_name': 'education',\n",
       "   'description': {'count_distinct': 8, 'count': 41188, 'null_count': 0},\n",
       "   'value_descriptions': [{'education': 'high.school',\n",
       "     'count': 9515,\n",
       "     'null_count': 0},\n",
       "    {'education': 'unknown', 'count': 1731, 'null_count': 0},\n",
       "    {'education': 'basic.6y', 'count': 2292, 'null_count': 0},\n",
       "    {'education': 'professional.course', 'count': 5243, 'null_count': 0},\n",
       "    {'education': 'university.degree', 'count': 12168, 'null_count': 0},\n",
       "    {'education': 'illiterate', 'count': 18, 'null_count': 0},\n",
       "    {'education': 'basic.4y', 'count': 4176, 'null_count': 0},\n",
       "    {'education': 'basic.9y', 'count': 6045, 'null_count': 0}]},\n",
       "  {'col_name': 'default',\n",
       "   'description': {'count_distinct': 3, 'count': 41188, 'null_count': 0},\n",
       "   'value_descriptions': [{'default': 'unknown',\n",
       "     'count': 8597,\n",
       "     'null_count': 0},\n",
       "    {'default': 'no', 'count': 32588, 'null_count': 0},\n",
       "    {'default': 'yes', 'count': 3, 'null_count': 0}]},\n",
       "  {'col_name': 'housing',\n",
       "   'description': {'count_distinct': 3, 'count': 41188, 'null_count': 0},\n",
       "   'value_descriptions': [{'housing': 'unknown',\n",
       "     'count': 990,\n",
       "     'null_count': 0},\n",
       "    {'housing': 'no', 'count': 18622, 'null_count': 0},\n",
       "    {'housing': 'yes', 'count': 21576, 'null_count': 0}]},\n",
       "  {'col_name': 'loan',\n",
       "   'description': {'count_distinct': 3, 'count': 41188, 'null_count': 0},\n",
       "   'value_descriptions': [{'loan': 'unknown', 'count': 990, 'null_count': 0},\n",
       "    {'loan': 'no', 'count': 33950, 'null_count': 0},\n",
       "    {'loan': 'yes', 'count': 6248, 'null_count': 0}]},\n",
       "  {'col_name': 'contact',\n",
       "   'description': {'count_distinct': 2, 'count': 41188, 'null_count': 0},\n",
       "   'value_descriptions': [{'contact': 'cellular',\n",
       "     'count': 26144,\n",
       "     'null_count': 0},\n",
       "    {'contact': 'telephone', 'count': 15044, 'null_count': 0}]},\n",
       "  {'col_name': 'month',\n",
       "   'description': {'count_distinct': 10, 'count': 41188, 'null_count': 0},\n",
       "   'value_descriptions': [{'month': 'jun', 'count': 5318, 'null_count': 0},\n",
       "    {'month': 'aug', 'count': 6178, 'null_count': 0},\n",
       "    {'month': 'may', 'count': 13769, 'null_count': 0},\n",
       "    {'month': 'mar', 'count': 546, 'null_count': 0},\n",
       "    {'month': 'oct', 'count': 718, 'null_count': 0},\n",
       "    {'month': 'jul', 'count': 7174, 'null_count': 0},\n",
       "    {'month': 'nov', 'count': 4101, 'null_count': 0},\n",
       "    {'month': 'apr', 'count': 2632, 'null_count': 0},\n",
       "    {'month': 'dec', 'count': 182, 'null_count': 0},\n",
       "    {'month': 'sep', 'count': 570, 'null_count': 0}]},\n",
       "  {'col_name': 'day_of_week',\n",
       "   'description': {'count_distinct': 5, 'count': 41188, 'null_count': 0},\n",
       "   'value_descriptions': [{'day_of_week': 'fri',\n",
       "     'count': 7827,\n",
       "     'null_count': 0},\n",
       "    {'day_of_week': 'thu', 'count': 8623, 'null_count': 0},\n",
       "    {'day_of_week': 'tue', 'count': 8090, 'null_count': 0},\n",
       "    {'day_of_week': 'wed', 'count': 8134, 'null_count': 0},\n",
       "    {'day_of_week': 'mon', 'count': 8514, 'null_count': 0}]},\n",
       "  {'col_name': 'poutcome',\n",
       "   'description': {'count_distinct': 3, 'count': 41188, 'null_count': 0},\n",
       "   'value_descriptions': [{'poutcome': 'success',\n",
       "     'count': 1373,\n",
       "     'null_count': 0},\n",
       "    {'poutcome': 'failure', 'count': 4252, 'null_count': 0},\n",
       "    {'poutcome': 'nonexistent', 'count': 35563, 'null_count': 0}]},\n",
       "  {'col_name': 'y',\n",
       "   'description': {'count_distinct': 2, 'count': 41188, 'null_count': 0},\n",
       "   'value_descriptions': [{'y': 'no', 'count': 36548, 'null_count': 0},\n",
       "    {'y': 'yes', 'count': 4640, 'null_count': 0}]}],\n",
       " 'numerical': [{'col_name': 'age',\n",
       "   'description': {'count_distinct': 78,\n",
       "    'count': 41188,\n",
       "    'null_count': 0,\n",
       "    'mean': 40.02406040594348,\n",
       "    'std': 10.421249980934045,\n",
       "    'min': 17,\n",
       "    'median': 38.0,\n",
       "    'max': 98}},\n",
       "  {'col_name': 'duration',\n",
       "   'description': {'count_distinct': 1544,\n",
       "    'count': 41188,\n",
       "    'null_count': 0,\n",
       "    'mean': 258.2850101971448,\n",
       "    'std': 259.2792488364647,\n",
       "    'min': 0,\n",
       "    'median': 180.0,\n",
       "    'max': 4918}},\n",
       "  {'col_name': 'campaign',\n",
       "   'description': {'count_distinct': 42,\n",
       "    'count': 41188,\n",
       "    'null_count': 0,\n",
       "    'mean': 2.567592502670681,\n",
       "    'std': 2.770013542902328,\n",
       "    'min': 1,\n",
       "    'median': 2.0,\n",
       "    'max': 56}},\n",
       "  {'col_name': 'pdays',\n",
       "   'description': {'count_distinct': 27,\n",
       "    'count': 41188,\n",
       "    'null_count': 0,\n",
       "    'mean': 962.4754540157328,\n",
       "    'std': 186.91090734474184,\n",
       "    'min': 0,\n",
       "    'median': 999.0,\n",
       "    'max': 999}},\n",
       "  {'col_name': 'previous',\n",
       "   'description': {'count_distinct': 8,\n",
       "    'count': 41188,\n",
       "    'null_count': 0,\n",
       "    'mean': 0.17296299893172767,\n",
       "    'std': 0.4949010798392897,\n",
       "    'min': 0,\n",
       "    'median': 0.0,\n",
       "    'max': 7}},\n",
       "  {'col_name': 'emp_var_rate',\n",
       "   'description': {'count_distinct': 10,\n",
       "    'count': 41188,\n",
       "    'null_count': 0,\n",
       "    'mean': 0.08188550063139827,\n",
       "    'std': 1.5709597405170257,\n",
       "    'min': -3.4,\n",
       "    'median': 1.1,\n",
       "    'max': 1.4}},\n",
       "  {'col_name': 'cons_price_idx',\n",
       "   'description': {'count_distinct': 26,\n",
       "    'count': 41188,\n",
       "    'null_count': 0,\n",
       "    'mean': 93.57566436826146,\n",
       "    'std': 0.5788400489541256,\n",
       "    'min': 92.201,\n",
       "    'median': 93.749,\n",
       "    'max': 94.767}},\n",
       "  {'col_name': 'cons_conf_idx',\n",
       "   'description': {'count_distinct': 26,\n",
       "    'count': 41188,\n",
       "    'null_count': 0,\n",
       "    'mean': -40.50260027192499,\n",
       "    'std': 4.628197856174542,\n",
       "    'min': -50.8,\n",
       "    'median': -41.8,\n",
       "    'max': -26.9}},\n",
       "  {'col_name': 'euribor3m',\n",
       "   'description': {'count_distinct': 316,\n",
       "    'count': 41188,\n",
       "    'null_count': 0,\n",
       "    'mean': 3.6212908128580947,\n",
       "    'std': 1.7344474048512672,\n",
       "    'min': 0.634,\n",
       "    'median': 4.857,\n",
       "    'max': 5.045}},\n",
       "  {'col_name': 'nr_employed',\n",
       "   'description': {'count_distinct': 11,\n",
       "    'count': 41188,\n",
       "    'null_count': 0,\n",
       "    'mean': 5167.035910944933,\n",
       "    'std': 72.25152766826106,\n",
       "    'min': 4963.6,\n",
       "    'median': 5191.0,\n",
       "    'max': 5228.1}}],\n",
       " 'boolean': []}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_checker = SchemaChecks(dataframe=df, problem=problem)\n",
    "\n",
    "schema_checker.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9486d1c1",
   "metadata": {},
   "source": [
    "Auto Feature Generation and Pre-processing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facf3198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.core.features.process import PreProcessVariables\n",
    "from backend.core.features.auto_feature_generator import AutoFeatureGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f51781e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_gen = AutoFeatureGenerator(\n",
    "    schema_checks=schema_checker,\n",
    "    problem=problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2372a6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating numerical features...\n",
      "Generating interaction features...\n",
      "Generating binning features...\n",
      "Generating datetime features...\n",
      "Total features generated: 228\n"
     ]
    }
   ],
   "source": [
    "df_with_features = feature_gen.generate_all_features(\n",
    "        include_numerical=True,\n",
    "        include_interactions=True,  # Set to True for interactions\n",
    "        include_binning=True,\n",
    "        include_datetime=True,\n",
    "        include_string=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa58beec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/15 08:12:01 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------+-------+-------+----+---------+-----+-----------+--------+--------+-----+--------+-----------+------------+--------------+-------------+---------+-----------+---+------------------+-----------------+----------+--------+------------------+------------------+---------------+-------------+------------------+-------------+---------------+-------------+-----------------+------------------+------------+------------+------------+-------------+---------------+-------------+------------------+------------------+-------------------+------------------+------------------+-------------------+---------------------+-------------------+-----------------+------------------+--------------------+-------------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+------------------+----------------+-----------------+-------------------+----------------+----------------+-----------------+----------------+----------------+----------------+--------------+--------------------+-------------+-------------+-----------------+----------------+----------------+----------------+---------------------+--------------------+--------------------+--------------------+-----------------------+----------------------+----------------------+----------------------+----------------------+---------------------+---------------------+---------------------+------------------+------------------+-----------------+-----------------+--------------------+--------------------+-------------------+-------------------+----------------------+---------------------+---------------------+---------------------+-------------------+-------------------+------------------+------------------+----------------------+---------------------+---------------------+---------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------------------------+---------------------------+---------------------------+---------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+-------------------+--------------------+------------------+------------------+----------------------+---------------------+---------------------+---------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------------------------+---------------------------+---------------------------+---------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+-------------------+------------------+------------------+------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+------------------------+-----------------------+-----------------------+-----------------------+--------------------+-------------------+-------------------+-------------------+----------------------+---------------------+---------------------+---------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------------------------+---------------------------+---------------------------+---------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+--------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+------------------------------+------------------------------+------------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------------+----------------------------+----------------------------+----------------------------+---------------------------------+--------------------------------+--------------------------------+--------------------------------+-----------------------------+----------------------------+----------------------------+----------------------------+-------------------------------+------------------------------+------------------------------+------------------------------+----------------------------+---------------------------+---------------------------+---------------------------+------------------------------+-----------------------------+-----------------------------+-----------------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------+---------------+---------------+-------------------+---------------------+--------------------+----------------+------------------+\n",
      "|age|      job|marital|  education|default|housing|loan|  contact|month|day_of_week|duration|campaign|pdays|previous|   poutcome|emp_var_rate|cons_price_idx|cons_conf_idx|euribor3m|nr_employed|  y|           age_log|         age_sqrt|age_square|age_cube|      duration_log|     duration_sqrt|duration_square|duration_cube|      campaign_log|campaign_sqrt|campaign_square|campaign_cube|        pdays_log|        pdays_sqrt|pdays_square|  pdays_cube|previous_log|previous_sqrt|previous_square|previous_cube|  emp_var_rate_log| emp_var_rate_sqrt|emp_var_rate_square| emp_var_rate_cube|cons_price_idx_log|cons_price_idx_sqrt|cons_price_idx_square|cons_price_idx_cube|cons_conf_idx_log|cons_conf_idx_sqrt|cons_conf_idx_square| cons_conf_idx_cube|     euribor3m_log|   euribor3m_sqrt|  euribor3m_square|    euribor3m_cube|  nr_employed_log| nr_employed_sqrt|nr_employed_square|nr_employed_cube|age_mult_duration|   age_div_duration|age_add_duration|age_sub_duration|age_mult_campaign|age_div_campaign|age_add_campaign|age_sub_campaign|age_mult_pdays|       age_div_pdays|age_add_pdays|age_sub_pdays|age_mult_previous|age_div_previous|age_add_previous|age_sub_previous|age_mult_emp_var_rate|age_div_emp_var_rate|age_add_emp_var_rate|age_sub_emp_var_rate|age_mult_cons_price_idx|age_div_cons_price_idx|age_add_cons_price_idx|age_sub_cons_price_idx|age_mult_cons_conf_idx|age_div_cons_conf_idx|age_add_cons_conf_idx|age_sub_cons_conf_idx|age_mult_euribor3m| age_div_euribor3m|age_add_euribor3m|age_sub_euribor3m|age_mult_nr_employed| age_div_nr_employed|age_add_nr_employed|age_sub_nr_employed|duration_mult_campaign|duration_div_campaign|duration_add_campaign|duration_sub_campaign|duration_mult_pdays| duration_div_pdays|duration_add_pdays|duration_sub_pdays|duration_mult_previous|duration_div_previous|duration_add_previous|duration_sub_previous|duration_mult_emp_var_rate|duration_div_emp_var_rate|duration_add_emp_var_rate|duration_sub_emp_var_rate|duration_mult_cons_price_idx|duration_div_cons_price_idx|duration_add_cons_price_idx|duration_sub_cons_price_idx|duration_mult_cons_conf_idx|duration_div_cons_conf_idx|duration_add_cons_conf_idx|duration_sub_cons_conf_idx|duration_mult_euribor3m|duration_div_euribor3m|duration_add_euribor3m|duration_sub_euribor3m|duration_mult_nr_employed|duration_div_nr_employed|duration_add_nr_employed|duration_sub_nr_employed|campaign_mult_pdays|  campaign_div_pdays|campaign_add_pdays|campaign_sub_pdays|campaign_mult_previous|campaign_div_previous|campaign_add_previous|campaign_sub_previous|campaign_mult_emp_var_rate|campaign_div_emp_var_rate|campaign_add_emp_var_rate|campaign_sub_emp_var_rate|campaign_mult_cons_price_idx|campaign_div_cons_price_idx|campaign_add_cons_price_idx|campaign_sub_cons_price_idx|campaign_mult_cons_conf_idx|campaign_div_cons_conf_idx|campaign_add_cons_conf_idx|campaign_sub_cons_conf_idx|campaign_mult_euribor3m|campaign_div_euribor3m|campaign_add_euribor3m|campaign_sub_euribor3m|campaign_mult_nr_employed|campaign_div_nr_employed|campaign_add_nr_employed|campaign_sub_nr_employed|pdays_mult_previous|pdays_div_previous|pdays_add_previous|pdays_sub_previous|pdays_mult_emp_var_rate|pdays_div_emp_var_rate|pdays_add_emp_var_rate|pdays_sub_emp_var_rate|pdays_mult_cons_price_idx|pdays_div_cons_price_idx|pdays_add_cons_price_idx|pdays_sub_cons_price_idx|pdays_mult_cons_conf_idx|pdays_div_cons_conf_idx|pdays_add_cons_conf_idx|pdays_sub_cons_conf_idx|pdays_mult_euribor3m|pdays_div_euribor3m|pdays_add_euribor3m|pdays_sub_euribor3m|pdays_mult_nr_employed|pdays_div_nr_employed|pdays_add_nr_employed|pdays_sub_nr_employed|previous_mult_emp_var_rate|previous_div_emp_var_rate|previous_add_emp_var_rate|previous_sub_emp_var_rate|previous_mult_cons_price_idx|previous_div_cons_price_idx|previous_add_cons_price_idx|previous_sub_cons_price_idx|previous_mult_cons_conf_idx|previous_div_cons_conf_idx|previous_add_cons_conf_idx|previous_sub_cons_conf_idx|previous_mult_euribor3m|previous_div_euribor3m|previous_add_euribor3m|previous_sub_euribor3m|previous_mult_nr_employed|previous_div_nr_employed|previous_add_nr_employed|previous_sub_nr_employed|emp_var_rate_mult_cons_price_idx|emp_var_rate_div_cons_price_idx|emp_var_rate_add_cons_price_idx|emp_var_rate_sub_cons_price_idx|emp_var_rate_mult_cons_conf_idx|emp_var_rate_div_cons_conf_idx|emp_var_rate_add_cons_conf_idx|emp_var_rate_sub_cons_conf_idx|emp_var_rate_mult_euribor3m|emp_var_rate_div_euribor3m|emp_var_rate_add_euribor3m|emp_var_rate_sub_euribor3m|emp_var_rate_mult_nr_employed|emp_var_rate_div_nr_employed|emp_var_rate_add_nr_employed|emp_var_rate_sub_nr_employed|cons_price_idx_mult_cons_conf_idx|cons_price_idx_div_cons_conf_idx|cons_price_idx_add_cons_conf_idx|cons_price_idx_sub_cons_conf_idx|cons_price_idx_mult_euribor3m|cons_price_idx_div_euribor3m|cons_price_idx_add_euribor3m|cons_price_idx_sub_euribor3m|cons_price_idx_mult_nr_employed|cons_price_idx_div_nr_employed|cons_price_idx_add_nr_employed|cons_price_idx_sub_nr_employed|cons_conf_idx_mult_euribor3m|cons_conf_idx_div_euribor3m|cons_conf_idx_add_euribor3m|cons_conf_idx_sub_euribor3m|cons_conf_idx_mult_nr_employed|cons_conf_idx_div_nr_employed|cons_conf_idx_add_nr_employed|cons_conf_idx_sub_nr_employed|euribor3m_mult_nr_employed|euribor3m_div_nr_employed|euribor3m_add_nr_employed|euribor3m_sub_nr_employed|age_binned|duration_binned|campaign_binned|emp_var_rate_binned|cons_price_idx_binned|cons_conf_idx_binned|euribor3m_binned|nr_employed_binned|\n",
      "+---+---------+-------+-----------+-------+-------+----+---------+-----+-----------+--------+--------+-----+--------+-----------+------------+--------------+-------------+---------+-----------+---+------------------+-----------------+----------+--------+------------------+------------------+---------------+-------------+------------------+-------------+---------------+-------------+-----------------+------------------+------------+------------+------------+-------------+---------------+-------------+------------------+------------------+-------------------+------------------+------------------+-------------------+---------------------+-------------------+-----------------+------------------+--------------------+-------------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+------------------+----------------+-----------------+-------------------+----------------+----------------+-----------------+----------------+----------------+----------------+--------------+--------------------+-------------+-------------+-----------------+----------------+----------------+----------------+---------------------+--------------------+--------------------+--------------------+-----------------------+----------------------+----------------------+----------------------+----------------------+---------------------+---------------------+---------------------+------------------+------------------+-----------------+-----------------+--------------------+--------------------+-------------------+-------------------+----------------------+---------------------+---------------------+---------------------+-------------------+-------------------+------------------+------------------+----------------------+---------------------+---------------------+---------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------------------------+---------------------------+---------------------------+---------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+-------------------+--------------------+------------------+------------------+----------------------+---------------------+---------------------+---------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------------------------+---------------------------+---------------------------+---------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+-------------------+------------------+------------------+------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+------------------------+-----------------------+-----------------------+-----------------------+--------------------+-------------------+-------------------+-------------------+----------------------+---------------------+---------------------+---------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------------------------+---------------------------+---------------------------+---------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+--------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+------------------------------+------------------------------+------------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------------+----------------------------+----------------------------+----------------------------+---------------------------------+--------------------------------+--------------------------------+--------------------------------+-----------------------------+----------------------------+----------------------------+----------------------------+-------------------------------+------------------------------+------------------------------+------------------------------+----------------------------+---------------------------+---------------------------+---------------------------+------------------------------+-----------------------------+-----------------------------+-----------------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------+---------------+---------------+-------------------+---------------------+--------------------+----------------+------------------+\n",
      "| 56|housemaid|married|   basic.4y|     no|     no|  no|telephone|  may|        mon|     261|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|     5191.0| no|  4.04305126783455|7.483314773547883|    3136.0|175616.0| 5.568344503761097| 16.15549442140351|        68121.0|  1.7779581E7|0.6931471805599453|          1.0|            1.0|          1.0|6.907755278982137|31.606961258558215|    998001.0|9.97002999E8|         0.0|          0.0|            0.0|          0.0|0.7419373447293773|1.0488088481701516| 1.2100000000000002|1.3310000000000004|  4.55381373171126|  9.695050283520969|          8834.872036|   830424.962151784|              0.0|               0.0|  1324.9599999999998|-48228.543999999994|1.7676375271076452|2.203860249652868|23.590449000000003|114.57881079300002|8.554874258383926|72.04859471218019|       2.6946481E7|1.39879182871E11|            14616|0.21455938697318008|             317|            -205|               56|            56.0|              57|              55|         55944|0.056056056056056056|         1055|         -943|                0|             0.0|              56|              56|    61.60000000000001|   50.90909090909091|                57.1|                54.9|               5263.664|    0.5957827095346512|               149.994|               -37.994|   -2038.3999999999999|  -1.5384615384615385|                 19.6|                 92.4|           271.992|11.529750875025735|           60.857|           51.143|            290696.0|0.010787902138316317|             5247.0|            -5135.0|                   261|                261.0|                  262|                  260|             260739|0.26126126126126126|              1260|              -738|                     0|                  0.0|                  261|                  261|                     287.1|       237.27272727272725|                    262.1|                    259.9|                   24532.434|          2.776772985509713|                    354.994|                    167.006|                    -9500.4|        -7.170329670329671|                     224.6|                     297.4|     1267.6770000000001|     53.73687461395923|               265.857|               256.143|                1354851.0|     0.05027932960893855|                  5452.0|                 -4930.0|                999|0.001001001001001001|              1000|              -998|                     0|                  0.0|                    1|                    1|                       1.1|       0.9090909090909091|                      2.1|     -0.10000000000000009|                      93.994|       0.010638976955975913|                     94.994|                    -92.994|                      -36.4|      -0.02747252747252...|                     -35.4|                      37.4|                  4.857|   0.20588840848260243|                 5.857|                -3.857|                   5191.0|    1.926411096127913...|                  5192.0|                 -5190.0|                  0|               0.0|               999|               999|                 1098.9|     908.1818181818181|                1000.1|                 997.9|                93900.006|      10.628337979019937|                1092.994|                 905.006|                -36363.6|    -27.445054945054945|                  962.6|                 1035.4|            4852.143| 205.68252007411982|           1003.857|            994.143|             5185809.0|  0.19244846850317857|               6190.0|              -4192.0|                       0.0|                      0.0|                      1.1|                     -1.1|                         0.0|                        0.0|                     93.994|                    -93.994|                       -0.0|                      -0.0|                     -36.4|                      36.4|                    0.0|                   0.0|                 4.857|                -4.857|                      0.0|                     0.0|                  5191.0|                 -5191.0|              103.39340000000001|           0.011702874651573505|                         95.094|                        -92.894|                         -40.04|          -0.03021978021978...|                         -35.3|                          37.5|          5.342700000000001|        0.2264772493308627|         5.957000000000001|                    -3.757|                       5710.1|        2.119052205740705...|                      5192.1|                     -5189.9|              -3421.3815999999997|             -2.5822527472527472|                          57.594|                         130.394|                   456.528858|           19.35227506691373|                      98.851|                      89.137|                     487922.854|           0.01810710845694471|                      5284.994|                     -5097.006|                   -176.7948|         -7.494338068766728|                    -31.543|                    -41.257|                     -188952.4|         -0.00701213638990...|                       5154.6|                      -5227.4|                 25212.687|     9.356578693893277E-4|                 5195.857|                -5186.143|       4.0|            3.0|            0.0|                3.0|                  4.0|                 4.0|             2.0|               2.0|\n",
      "| 57| services|married|high.school|unknown|     no|  no|telephone|  may|        mon|     149|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|     5191.0| no| 4.060443010546419| 7.54983443527075|    3249.0|185193.0|5.0106352940962555|12.206555615733702|        22201.0|    3307949.0|0.6931471805599453|          1.0|            1.0|          1.0|6.907755278982137|31.606961258558215|    998001.0|9.97002999E8|         0.0|          0.0|            0.0|          0.0|0.7419373447293773|1.0488088481701516| 1.2100000000000002|1.3310000000000004|  4.55381373171126|  9.695050283520969|          8834.872036|   830424.962151784|              0.0|               0.0|  1324.9599999999998|-48228.543999999994|1.7676375271076452|2.203860249652868|23.590449000000003|114.57881079300002|8.554874258383926|72.04859471218019|       2.6946481E7|1.39879182871E11|             8493| 0.3825503355704698|             206|             -92|               57|            57.0|              58|              56|         56943|0.057057057057057055|         1056|         -942|                0|             0.0|              57|              57|                 62.7|   51.81818181818181|                58.1|                55.9|               5357.658|    0.6064216864906271|               150.994|               -36.994|   -2074.7999999999997|   -1.565934065934066|                 20.6|                 93.4|           276.849|11.735639283508338|           61.857|           52.143|            295887.0|0.010980543247929108|             5248.0|            -5134.0|                   149|                149.0|                  150|                  148|             148851|0.14914914914914915|              1148|              -850|                     0|                  0.0|                  149|                  149|                     163.9|       135.45454545454544|                    150.1|                    147.9|                   14005.106|          1.585207566440411|                    242.994|                     55.006|         -5423.599999999999|        -4.093406593406594|                     112.6|                     185.4|                723.693|     30.67737286390776|               153.857|               144.143|                 773459.0|    0.028703525332305913|                  5340.0|                 -5042.0|                999|0.001001001001001001|              1000|              -998|                     0|                  0.0|                    1|                    1|                       1.1|       0.9090909090909091|                      2.1|     -0.10000000000000009|                      93.994|       0.010638976955975913|                     94.994|                    -92.994|                      -36.4|      -0.02747252747252...|                     -35.4|                      37.4|                  4.857|   0.20588840848260243|                 5.857|                -3.857|                   5191.0|    1.926411096127913...|                  5192.0|                 -5190.0|                  0|               0.0|               999|               999|                 1098.9|     908.1818181818181|                1000.1|                 997.9|                93900.006|      10.628337979019937|                1092.994|                 905.006|                -36363.6|    -27.445054945054945|                  962.6|                 1035.4|            4852.143| 205.68252007411982|           1003.857|            994.143|             5185809.0|  0.19244846850317857|               6190.0|              -4192.0|                       0.0|                      0.0|                      1.1|                     -1.1|                         0.0|                        0.0|                     93.994|                    -93.994|                       -0.0|                      -0.0|                     -36.4|                      36.4|                    0.0|                   0.0|                 4.857|                -4.857|                      0.0|                     0.0|                  5191.0|                 -5191.0|              103.39340000000001|           0.011702874651573505|                         95.094|                        -92.894|                         -40.04|          -0.03021978021978...|                         -35.3|                          37.5|          5.342700000000001|        0.2264772493308627|         5.957000000000001|                    -3.757|                       5710.1|        2.119052205740705...|                      5192.1|                     -5189.9|              -3421.3815999999997|             -2.5822527472527472|                          57.594|                         130.394|                   456.528858|           19.35227506691373|                      98.851|                      89.137|                     487922.854|           0.01810710845694471|                      5284.994|                     -5097.006|                   -176.7948|         -7.494338068766728|                    -31.543|                    -41.257|                     -188952.4|         -0.00701213638990...|                       5154.6|                      -5227.4|                 25212.687|     9.356578693893277E-4|                 5195.857|                -5186.143|       4.0|            2.0|            0.0|                3.0|                  4.0|                 4.0|             2.0|               2.0|\n",
      "| 37| services|married|high.school|     no|    yes|  no|telephone|  may|        mon|     226|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|     5191.0| no|3.6375861597263857|6.082762530298219|    1369.0| 50653.0| 5.424950017481403|15.033296378372908|        51076.0|  1.1543176E7|0.6931471805599453|          1.0|            1.0|          1.0|6.907755278982137|31.606961258558215|    998001.0|9.97002999E8|         0.0|          0.0|            0.0|          0.0|0.7419373447293773|1.0488088481701516| 1.2100000000000002|1.3310000000000004|  4.55381373171126|  9.695050283520969|          8834.872036|   830424.962151784|              0.0|               0.0|  1324.9599999999998|-48228.543999999994|1.7676375271076452|2.203860249652868|23.590449000000003|114.57881079300002|8.554874258383926|72.04859471218019|       2.6946481E7|1.39879182871E11|             8362|0.16371681415929204|             263|            -189|               37|            37.0|              38|              36|         36963|0.037037037037037035|         1036|         -962|                0|             0.0|              37|              37|                 40.7|   33.63636363636363|                38.1|                35.9|               3477.778|    0.3936421473711088|               130.994|               -56.994|               -1346.8|  -1.0164835164835164|   0.6000000000000014|                 73.4|           179.709|  7.61787111385629|           41.857|           32.143|            192067.0| 0.00712772105567328|             5228.0|            -5154.0|                   226|                226.0|                  227|                  225|             225774|0.22622622622622623|              1225|              -773|                     0|                  0.0|                  226|                  226|        248.60000000000002|       205.45454545454544|                    227.1|                    224.9|                   21242.644|         2.4044087920505564|                    319.994|                    132.006|                    -8226.4|        -6.208791208791209|                     189.6|                     262.4|               1097.682|     46.53078031706815|               230.857|               221.143|                1173166.0|     0.04353689077249085|                  5417.0|                 -4965.0|                999|0.001001001001001001|              1000|              -998|                     0|                  0.0|                    1|                    1|                       1.1|       0.9090909090909091|                      2.1|     -0.10000000000000009|                      93.994|       0.010638976955975913|                     94.994|                    -92.994|                      -36.4|      -0.02747252747252...|                     -35.4|                      37.4|                  4.857|   0.20588840848260243|                 5.857|                -3.857|                   5191.0|    1.926411096127913...|                  5192.0|                 -5190.0|                  0|               0.0|               999|               999|                 1098.9|     908.1818181818181|                1000.1|                 997.9|                93900.006|      10.628337979019937|                1092.994|                 905.006|                -36363.6|    -27.445054945054945|                  962.6|                 1035.4|            4852.143| 205.68252007411982|           1003.857|            994.143|             5185809.0|  0.19244846850317857|               6190.0|              -4192.0|                       0.0|                      0.0|                      1.1|                     -1.1|                         0.0|                        0.0|                     93.994|                    -93.994|                       -0.0|                      -0.0|                     -36.4|                      36.4|                    0.0|                   0.0|                 4.857|                -4.857|                      0.0|                     0.0|                  5191.0|                 -5191.0|              103.39340000000001|           0.011702874651573505|                         95.094|                        -92.894|                         -40.04|          -0.03021978021978...|                         -35.3|                          37.5|          5.342700000000001|        0.2264772493308627|         5.957000000000001|                    -3.757|                       5710.1|        2.119052205740705...|                      5192.1|                     -5189.9|              -3421.3815999999997|             -2.5822527472527472|                          57.594|                         130.394|                   456.528858|           19.35227506691373|                      98.851|                      89.137|                     487922.854|           0.01810710845694471|                      5284.994|                     -5097.006|                   -176.7948|         -7.494338068766728|                    -31.543|                    -41.257|                     -188952.4|         -0.00701213638990...|                       5154.6|                      -5227.4|                 25212.687|     9.356578693893277E-4|                 5195.857|                -5186.143|       2.0|            3.0|            0.0|                3.0|                  4.0|                 4.0|             2.0|               2.0|\n",
      "| 40|   admin.|married|   basic.6y|     no|     no|  no|telephone|  may|        mon|     151|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|     5191.0| no| 3.713572066704308|6.324555320336759|    1600.0| 64000.0|5.0238805208462765|12.288205727444508|        22801.0|    3442951.0|0.6931471805599453|          1.0|            1.0|          1.0|6.907755278982137|31.606961258558215|    998001.0|9.97002999E8|         0.0|          0.0|            0.0|          0.0|0.7419373447293773|1.0488088481701516| 1.2100000000000002|1.3310000000000004|  4.55381373171126|  9.695050283520969|          8834.872036|   830424.962151784|              0.0|               0.0|  1324.9599999999998|-48228.543999999994|1.7676375271076452|2.203860249652868|23.590449000000003|114.57881079300002|8.554874258383926|72.04859471218019|       2.6946481E7|1.39879182871E11|             6040|0.26490066225165565|             191|            -111|               40|            40.0|              41|              39|         39960| 0.04004004004004004|         1039|         -959|                0|             0.0|              40|              40|                 44.0|   36.36363636363636|                41.1|                38.9|                3759.76|   0.42555907823903655|               133.994|               -53.994|               -1456.0|   -1.098901098901099|   3.6000000000000014|                 76.4|            194.28| 8.235536339304097|           44.857|           35.143|            207640.0|0.007705644384511...|             5231.0|            -5151.0|                   151|                151.0|                  152|                  150|             150849|0.15115115115115116|              1150|              -848|                     0|                  0.0|                  151|                  151|        166.10000000000002|       137.27272727272725|                    152.1|                    149.9|                   14193.094|          1.606485520352363|                    244.994|                     57.006|                    -5496.4|        -4.148351648351649|                     114.6|                     187.4|                733.407|    31.089149680872964|               155.857|               146.143|                 783841.0|    0.029088807551531495|                  5342.0|                 -5040.0|                999|0.001001001001001001|              1000|              -998|                     0|                  0.0|                    1|                    1|                       1.1|       0.9090909090909091|                      2.1|     -0.10000000000000009|                      93.994|       0.010638976955975913|                     94.994|                    -92.994|                      -36.4|      -0.02747252747252...|                     -35.4|                      37.4|                  4.857|   0.20588840848260243|                 5.857|                -3.857|                   5191.0|    1.926411096127913...|                  5192.0|                 -5190.0|                  0|               0.0|               999|               999|                 1098.9|     908.1818181818181|                1000.1|                 997.9|                93900.006|      10.628337979019937|                1092.994|                 905.006|                -36363.6|    -27.445054945054945|                  962.6|                 1035.4|            4852.143| 205.68252007411982|           1003.857|            994.143|             5185809.0|  0.19244846850317857|               6190.0|              -4192.0|                       0.0|                      0.0|                      1.1|                     -1.1|                         0.0|                        0.0|                     93.994|                    -93.994|                       -0.0|                      -0.0|                     -36.4|                      36.4|                    0.0|                   0.0|                 4.857|                -4.857|                      0.0|                     0.0|                  5191.0|                 -5191.0|              103.39340000000001|           0.011702874651573505|                         95.094|                        -92.894|                         -40.04|          -0.03021978021978...|                         -35.3|                          37.5|          5.342700000000001|        0.2264772493308627|         5.957000000000001|                    -3.757|                       5710.1|        2.119052205740705...|                      5192.1|                     -5189.9|              -3421.3815999999997|             -2.5822527472527472|                          57.594|                         130.394|                   456.528858|           19.35227506691373|                      98.851|                      89.137|                     487922.854|           0.01810710845694471|                      5284.994|                     -5097.006|                   -176.7948|         -7.494338068766728|                    -31.543|                    -41.257|                     -188952.4|         -0.00701213638990...|                       5154.6|                      -5227.4|                 25212.687|     9.356578693893277E-4|                 5195.857|                -5186.143|       2.0|            2.0|            0.0|                3.0|                  4.0|                 4.0|             2.0|               2.0|\n",
      "| 56| services|married|high.school|     no|     no| yes|telephone|  may|        mon|     307|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|     5191.0| no|  4.04305126783455|7.483314773547883|    3136.0|175616.0| 5.730099782973575| 17.52141546793523|        94249.0|  2.8934443E7|0.6931471805599453|          1.0|            1.0|          1.0|6.907755278982137|31.606961258558215|    998001.0|9.97002999E8|         0.0|          0.0|            0.0|          0.0|0.7419373447293773|1.0488088481701516| 1.2100000000000002|1.3310000000000004|  4.55381373171126|  9.695050283520969|          8834.872036|   830424.962151784|              0.0|               0.0|  1324.9599999999998|-48228.543999999994|1.7676375271076452|2.203860249652868|23.590449000000003|114.57881079300002|8.554874258383926|72.04859471218019|       2.6946481E7|1.39879182871E11|            17192|0.18241042345276873|             363|            -251|               56|            56.0|              57|              55|         55944|0.056056056056056056|         1055|         -943|                0|             0.0|              56|              56|    61.60000000000001|   50.90909090909091|                57.1|                54.9|               5263.664|    0.5957827095346512|               149.994|               -37.994|   -2038.3999999999999|  -1.5384615384615385|                 19.6|                 92.4|           271.992|11.529750875025735|           60.857|           51.143|            290696.0|0.010787902138316317|             5247.0|            -5135.0|                   307|                307.0|                  308|                  306|             306693| 0.3073073073073073|              1306|              -692|                     0|                  0.0|                  307|                  307|        337.70000000000005|       279.09090909090907|                    308.1|                    305.9|                   28856.158|         3.2661659254846054|                    400.994|                    213.006|                   -11174.8|        -8.434065934065934|                     270.6|                     343.4|     1491.0990000000002|    63.207741404158945|               311.857|               302.143|                1593637.0|     0.05914082065112695|                  5498.0|                 -4884.0|                999|0.001001001001001001|              1000|              -998|                     0|                  0.0|                    1|                    1|                       1.1|       0.9090909090909091|                      2.1|     -0.10000000000000009|                      93.994|       0.010638976955975913|                     94.994|                    -92.994|                      -36.4|      -0.02747252747252...|                     -35.4|                      37.4|                  4.857|   0.20588840848260243|                 5.857|                -3.857|                   5191.0|    1.926411096127913...|                  5192.0|                 -5190.0|                  0|               0.0|               999|               999|                 1098.9|     908.1818181818181|                1000.1|                 997.9|                93900.006|      10.628337979019937|                1092.994|                 905.006|                -36363.6|    -27.445054945054945|                  962.6|                 1035.4|            4852.143| 205.68252007411982|           1003.857|            994.143|             5185809.0|  0.19244846850317857|               6190.0|              -4192.0|                       0.0|                      0.0|                      1.1|                     -1.1|                         0.0|                        0.0|                     93.994|                    -93.994|                       -0.0|                      -0.0|                     -36.4|                      36.4|                    0.0|                   0.0|                 4.857|                -4.857|                      0.0|                     0.0|                  5191.0|                 -5191.0|              103.39340000000001|           0.011702874651573505|                         95.094|                        -92.894|                         -40.04|          -0.03021978021978...|                         -35.3|                          37.5|          5.342700000000001|        0.2264772493308627|         5.957000000000001|                    -3.757|                       5710.1|        2.119052205740705...|                      5192.1|                     -5189.9|              -3421.3815999999997|             -2.5822527472527472|                          57.594|                         130.394|                   456.528858|           19.35227506691373|                      98.851|                      89.137|                     487922.854|           0.01810710845694471|                      5284.994|                     -5097.006|                   -176.7948|         -7.494338068766728|                    -31.543|                    -41.257|                     -188952.4|         -0.00701213638990...|                       5154.6|                      -5227.4|                 25212.687|     9.356578693893277E-4|                 5195.857|                -5186.143|       4.0|            3.0|            0.0|                3.0|                  4.0|                 4.0|             2.0|               2.0|\n",
      "+---+---------+-------+-----------+-------+-------+----+---------+-----+-----------+--------+--------+-----+--------+-----------+------------+--------------+-------------+---------+-----------+---+------------------+-----------------+----------+--------+------------------+------------------+---------------+-------------+------------------+-------------+---------------+-------------+-----------------+------------------+------------+------------+------------+-------------+---------------+-------------+------------------+------------------+-------------------+------------------+------------------+-------------------+---------------------+-------------------+-----------------+------------------+--------------------+-------------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+------------------+----------------+-----------------+-------------------+----------------+----------------+-----------------+----------------+----------------+----------------+--------------+--------------------+-------------+-------------+-----------------+----------------+----------------+----------------+---------------------+--------------------+--------------------+--------------------+-----------------------+----------------------+----------------------+----------------------+----------------------+---------------------+---------------------+---------------------+------------------+------------------+-----------------+-----------------+--------------------+--------------------+-------------------+-------------------+----------------------+---------------------+---------------------+---------------------+-------------------+-------------------+------------------+------------------+----------------------+---------------------+---------------------+---------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------------------------+---------------------------+---------------------------+---------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+-------------------+--------------------+------------------+------------------+----------------------+---------------------+---------------------+---------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------------------------+---------------------------+---------------------------+---------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+-------------------+------------------+------------------+------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+------------------------+-----------------------+-----------------------+-----------------------+--------------------+-------------------+-------------------+-------------------+----------------------+---------------------+---------------------+---------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------------------------+---------------------------+---------------------------+---------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+--------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+------------------------------+------------------------------+------------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------------+----------------------------+----------------------------+----------------------------+---------------------------------+--------------------------------+--------------------------------+--------------------------------+-----------------------------+----------------------------+----------------------------+----------------------------+-------------------------------+------------------------------+------------------------------+------------------------------+----------------------------+---------------------------+---------------------------+---------------------------+------------------------------+-----------------------------+-----------------------------+-----------------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------+---------------+---------------+-------------------+---------------------+--------------------+----------------+------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_with_features.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f419938f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'default',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'month',\n",
       " 'day_of_week',\n",
       " 'duration',\n",
       " 'campaign',\n",
       " 'pdays',\n",
       " 'previous',\n",
       " 'poutcome',\n",
       " 'emp_var_rate',\n",
       " 'cons_price_idx',\n",
       " 'cons_conf_idx',\n",
       " 'euribor3m',\n",
       " 'nr_employed',\n",
       " 'y',\n",
       " 'age_log',\n",
       " 'age_sqrt',\n",
       " 'age_square',\n",
       " 'age_cube',\n",
       " 'duration_log',\n",
       " 'duration_sqrt',\n",
       " 'duration_square',\n",
       " 'duration_cube',\n",
       " 'campaign_log',\n",
       " 'campaign_sqrt',\n",
       " 'campaign_square',\n",
       " 'campaign_cube',\n",
       " 'pdays_log',\n",
       " 'pdays_sqrt',\n",
       " 'pdays_square',\n",
       " 'pdays_cube',\n",
       " 'previous_log',\n",
       " 'previous_sqrt',\n",
       " 'previous_square',\n",
       " 'previous_cube',\n",
       " 'emp_var_rate_log',\n",
       " 'emp_var_rate_sqrt',\n",
       " 'emp_var_rate_square',\n",
       " 'emp_var_rate_cube',\n",
       " 'cons_price_idx_log',\n",
       " 'cons_price_idx_sqrt',\n",
       " 'cons_price_idx_square',\n",
       " 'cons_price_idx_cube',\n",
       " 'cons_conf_idx_log',\n",
       " 'cons_conf_idx_sqrt',\n",
       " 'cons_conf_idx_square',\n",
       " 'cons_conf_idx_cube',\n",
       " 'euribor3m_log',\n",
       " 'euribor3m_sqrt',\n",
       " 'euribor3m_square',\n",
       " 'euribor3m_cube',\n",
       " 'nr_employed_log',\n",
       " 'nr_employed_sqrt',\n",
       " 'nr_employed_square',\n",
       " 'nr_employed_cube',\n",
       " 'age_mult_duration',\n",
       " 'age_div_duration',\n",
       " 'age_add_duration',\n",
       " 'age_sub_duration',\n",
       " 'age_mult_campaign',\n",
       " 'age_div_campaign',\n",
       " 'age_add_campaign',\n",
       " 'age_sub_campaign',\n",
       " 'age_mult_pdays',\n",
       " 'age_div_pdays',\n",
       " 'age_add_pdays',\n",
       " 'age_sub_pdays',\n",
       " 'age_mult_previous',\n",
       " 'age_div_previous',\n",
       " 'age_add_previous',\n",
       " 'age_sub_previous',\n",
       " 'age_mult_emp_var_rate',\n",
       " 'age_div_emp_var_rate',\n",
       " 'age_add_emp_var_rate',\n",
       " 'age_sub_emp_var_rate',\n",
       " 'age_mult_cons_price_idx',\n",
       " 'age_div_cons_price_idx',\n",
       " 'age_add_cons_price_idx',\n",
       " 'age_sub_cons_price_idx',\n",
       " 'age_mult_cons_conf_idx',\n",
       " 'age_div_cons_conf_idx',\n",
       " 'age_add_cons_conf_idx',\n",
       " 'age_sub_cons_conf_idx',\n",
       " 'age_mult_euribor3m',\n",
       " 'age_div_euribor3m',\n",
       " 'age_add_euribor3m',\n",
       " 'age_sub_euribor3m',\n",
       " 'age_mult_nr_employed',\n",
       " 'age_div_nr_employed',\n",
       " 'age_add_nr_employed',\n",
       " 'age_sub_nr_employed',\n",
       " 'duration_mult_campaign',\n",
       " 'duration_div_campaign',\n",
       " 'duration_add_campaign',\n",
       " 'duration_sub_campaign',\n",
       " 'duration_mult_pdays',\n",
       " 'duration_div_pdays',\n",
       " 'duration_add_pdays',\n",
       " 'duration_sub_pdays',\n",
       " 'duration_mult_previous',\n",
       " 'duration_div_previous',\n",
       " 'duration_add_previous',\n",
       " 'duration_sub_previous',\n",
       " 'duration_mult_emp_var_rate',\n",
       " 'duration_div_emp_var_rate',\n",
       " 'duration_add_emp_var_rate',\n",
       " 'duration_sub_emp_var_rate',\n",
       " 'duration_mult_cons_price_idx',\n",
       " 'duration_div_cons_price_idx',\n",
       " 'duration_add_cons_price_idx',\n",
       " 'duration_sub_cons_price_idx',\n",
       " 'duration_mult_cons_conf_idx',\n",
       " 'duration_div_cons_conf_idx',\n",
       " 'duration_add_cons_conf_idx',\n",
       " 'duration_sub_cons_conf_idx',\n",
       " 'duration_mult_euribor3m',\n",
       " 'duration_div_euribor3m',\n",
       " 'duration_add_euribor3m',\n",
       " 'duration_sub_euribor3m',\n",
       " 'duration_mult_nr_employed',\n",
       " 'duration_div_nr_employed',\n",
       " 'duration_add_nr_employed',\n",
       " 'duration_sub_nr_employed',\n",
       " 'campaign_mult_pdays',\n",
       " 'campaign_div_pdays',\n",
       " 'campaign_add_pdays',\n",
       " 'campaign_sub_pdays',\n",
       " 'campaign_mult_previous',\n",
       " 'campaign_div_previous',\n",
       " 'campaign_add_previous',\n",
       " 'campaign_sub_previous',\n",
       " 'campaign_mult_emp_var_rate',\n",
       " 'campaign_div_emp_var_rate',\n",
       " 'campaign_add_emp_var_rate',\n",
       " 'campaign_sub_emp_var_rate',\n",
       " 'campaign_mult_cons_price_idx',\n",
       " 'campaign_div_cons_price_idx',\n",
       " 'campaign_add_cons_price_idx',\n",
       " 'campaign_sub_cons_price_idx',\n",
       " 'campaign_mult_cons_conf_idx',\n",
       " 'campaign_div_cons_conf_idx',\n",
       " 'campaign_add_cons_conf_idx',\n",
       " 'campaign_sub_cons_conf_idx',\n",
       " 'campaign_mult_euribor3m',\n",
       " 'campaign_div_euribor3m',\n",
       " 'campaign_add_euribor3m',\n",
       " 'campaign_sub_euribor3m',\n",
       " 'campaign_mult_nr_employed',\n",
       " 'campaign_div_nr_employed',\n",
       " 'campaign_add_nr_employed',\n",
       " 'campaign_sub_nr_employed',\n",
       " 'pdays_mult_previous',\n",
       " 'pdays_div_previous',\n",
       " 'pdays_add_previous',\n",
       " 'pdays_sub_previous',\n",
       " 'pdays_mult_emp_var_rate',\n",
       " 'pdays_div_emp_var_rate',\n",
       " 'pdays_add_emp_var_rate',\n",
       " 'pdays_sub_emp_var_rate',\n",
       " 'pdays_mult_cons_price_idx',\n",
       " 'pdays_div_cons_price_idx',\n",
       " 'pdays_add_cons_price_idx',\n",
       " 'pdays_sub_cons_price_idx',\n",
       " 'pdays_mult_cons_conf_idx',\n",
       " 'pdays_div_cons_conf_idx',\n",
       " 'pdays_add_cons_conf_idx',\n",
       " 'pdays_sub_cons_conf_idx',\n",
       " 'pdays_mult_euribor3m',\n",
       " 'pdays_div_euribor3m',\n",
       " 'pdays_add_euribor3m',\n",
       " 'pdays_sub_euribor3m',\n",
       " 'pdays_mult_nr_employed',\n",
       " 'pdays_div_nr_employed',\n",
       " 'pdays_add_nr_employed',\n",
       " 'pdays_sub_nr_employed',\n",
       " 'previous_mult_emp_var_rate',\n",
       " 'previous_div_emp_var_rate',\n",
       " 'previous_add_emp_var_rate',\n",
       " 'previous_sub_emp_var_rate',\n",
       " 'previous_mult_cons_price_idx',\n",
       " 'previous_div_cons_price_idx',\n",
       " 'previous_add_cons_price_idx',\n",
       " 'previous_sub_cons_price_idx',\n",
       " 'previous_mult_cons_conf_idx',\n",
       " 'previous_div_cons_conf_idx',\n",
       " 'previous_add_cons_conf_idx',\n",
       " 'previous_sub_cons_conf_idx',\n",
       " 'previous_mult_euribor3m',\n",
       " 'previous_div_euribor3m',\n",
       " 'previous_add_euribor3m',\n",
       " 'previous_sub_euribor3m',\n",
       " 'previous_mult_nr_employed',\n",
       " 'previous_div_nr_employed',\n",
       " 'previous_add_nr_employed',\n",
       " 'previous_sub_nr_employed',\n",
       " 'emp_var_rate_mult_cons_price_idx',\n",
       " 'emp_var_rate_div_cons_price_idx',\n",
       " 'emp_var_rate_add_cons_price_idx',\n",
       " 'emp_var_rate_sub_cons_price_idx',\n",
       " 'emp_var_rate_mult_cons_conf_idx',\n",
       " 'emp_var_rate_div_cons_conf_idx',\n",
       " 'emp_var_rate_add_cons_conf_idx',\n",
       " 'emp_var_rate_sub_cons_conf_idx',\n",
       " 'emp_var_rate_mult_euribor3m',\n",
       " 'emp_var_rate_div_euribor3m',\n",
       " 'emp_var_rate_add_euribor3m',\n",
       " 'emp_var_rate_sub_euribor3m',\n",
       " 'emp_var_rate_mult_nr_employed',\n",
       " 'emp_var_rate_div_nr_employed',\n",
       " 'emp_var_rate_add_nr_employed',\n",
       " 'emp_var_rate_sub_nr_employed',\n",
       " 'cons_price_idx_mult_cons_conf_idx',\n",
       " 'cons_price_idx_div_cons_conf_idx',\n",
       " 'cons_price_idx_add_cons_conf_idx',\n",
       " 'cons_price_idx_sub_cons_conf_idx',\n",
       " 'cons_price_idx_mult_euribor3m',\n",
       " 'cons_price_idx_div_euribor3m',\n",
       " 'cons_price_idx_add_euribor3m',\n",
       " 'cons_price_idx_sub_euribor3m',\n",
       " 'cons_price_idx_mult_nr_employed',\n",
       " 'cons_price_idx_div_nr_employed',\n",
       " 'cons_price_idx_add_nr_employed',\n",
       " 'cons_price_idx_sub_nr_employed',\n",
       " 'cons_conf_idx_mult_euribor3m',\n",
       " 'cons_conf_idx_div_euribor3m',\n",
       " 'cons_conf_idx_add_euribor3m',\n",
       " 'cons_conf_idx_sub_euribor3m',\n",
       " 'cons_conf_idx_mult_nr_employed',\n",
       " 'cons_conf_idx_div_nr_employed',\n",
       " 'cons_conf_idx_add_nr_employed',\n",
       " 'cons_conf_idx_sub_nr_employed',\n",
       " 'euribor3m_mult_nr_employed',\n",
       " 'euribor3m_div_nr_employed',\n",
       " 'euribor3m_add_nr_employed',\n",
       " 'euribor3m_sub_nr_employed',\n",
       " 'age_binned',\n",
       " 'duration_binned',\n",
       " 'campaign_binned',\n",
       " 'emp_var_rate_binned',\n",
       " 'cons_price_idx_binned',\n",
       " 'cons_conf_idx_binned',\n",
       " 'euribor3m_binned',\n",
       " 'nr_employed_binned']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25220c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 249)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns), len(df_with_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "233a7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process_variables = PreProcessVariables(dataframe=df_with_features, problem=problem, schema_checks=schema_checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "597aa684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['job_admin.', 'job_blue-collar', 'job_technician', 'job_services', 'job_management', 'job_retired', 'job_entrepreneur', 'job_self-employed', 'job_housemaid', 'job_unemployed', 'job_student', 'job_unknown', 'marital_married', 'marital_single', 'marital_divorced', 'marital_unknown', 'education_university.degree', 'education_high.school', 'education_basic.9y', 'education_professional.course', 'education_basic.4y', 'education_basic.6y', 'education_unknown', 'education_illiterate', 'default_no', 'default_unknown', 'default_yes', 'housing_yes', 'housing_no', 'housing_unknown', 'loan_no', 'loan_yes', 'loan_unknown', 'contact_cellular', 'contact_telephone', 'month_may', 'month_jul', 'month_aug', 'month_jun', 'month_nov', 'month_apr', 'month_oct', 'month_sep', 'month_mar', 'month_dec', 'day_of_week_thu', 'day_of_week_mon', 'day_of_week_wed', 'day_of_week_tue', 'day_of_week_fri', 'poutcome_nonexistent', 'poutcome_failure', 'poutcome_success']\n"
     ]
    }
   ],
   "source": [
    "transformed_df, feature_names, feature_output_col, feature_map = pre_process_variables.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d01f9a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------+-------+-------+----+---------+-----+-----------+--------+--------+-----+--------+-----------+------------+--------------+-------------+---------+-----------+---+------------------+-----------------+----------+--------+------------------+------------------+---------------+-------------+------------------+-------------+---------------+-------------+-----------------+------------------+------------+------------+------------+-------------+---------------+-------------+------------------+------------------+-------------------+------------------+------------------+-------------------+---------------------+-------------------+-----------------+------------------+--------------------+-------------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+------------------+----------------+-----------------+-------------------+----------------+----------------+-----------------+----------------+----------------+----------------+--------------+--------------------+-------------+-------------+-----------------+----------------+----------------+----------------+---------------------+--------------------+--------------------+--------------------+-----------------------+----------------------+----------------------+----------------------+----------------------+---------------------+---------------------+---------------------+------------------+------------------+-----------------+-----------------+--------------------+--------------------+-------------------+-------------------+----------------------+---------------------+---------------------+---------------------+-------------------+-------------------+------------------+------------------+----------------------+---------------------+---------------------+---------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------------------------+---------------------------+---------------------------+---------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+-------------------+--------------------+------------------+------------------+----------------------+---------------------+---------------------+---------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------------------------+---------------------------+---------------------------+---------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+-------------------+------------------+------------------+------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+------------------------+-----------------------+-----------------------+-----------------------+--------------------+-------------------+-------------------+-------------------+----------------------+---------------------+---------------------+---------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------------------------+---------------------------+---------------------------+---------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+--------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+------------------------------+------------------------------+------------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------------+----------------------------+----------------------------+----------------------------+---------------------------------+--------------------------------+--------------------------------+--------------------------------+-----------------------------+----------------------------+----------------------------+----------------------------+-------------------------------+------------------------------+------------------------------+------------------------------+----------------------------+---------------------------+---------------------------+---------------------------+------------------------------+-----------------------------+-----------------------------+-----------------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------+---------------+---------------+-------------------+---------------------+--------------------+----------------+------------------+---------+-------------+---------------+-------------+-------------+----------+-------------+-----------+-----------------+--------------+--------------+---------------+-----------------+---------------+---------------+-------------+---------------+-------------+-------------------+----------------+--------------------+\n",
      "|age|      job|marital|  education|default|housing|loan|  contact|month|day_of_week|duration|campaign|pdays|previous|   poutcome|emp_var_rate|cons_price_idx|cons_conf_idx|euribor3m|nr_employed|  y|           age_log|         age_sqrt|age_square|age_cube|      duration_log|     duration_sqrt|duration_square|duration_cube|      campaign_log|campaign_sqrt|campaign_square|campaign_cube|        pdays_log|        pdays_sqrt|pdays_square|  pdays_cube|previous_log|previous_sqrt|previous_square|previous_cube|  emp_var_rate_log| emp_var_rate_sqrt|emp_var_rate_square| emp_var_rate_cube|cons_price_idx_log|cons_price_idx_sqrt|cons_price_idx_square|cons_price_idx_cube|cons_conf_idx_log|cons_conf_idx_sqrt|cons_conf_idx_square| cons_conf_idx_cube|     euribor3m_log|   euribor3m_sqrt|  euribor3m_square|    euribor3m_cube|  nr_employed_log| nr_employed_sqrt|nr_employed_square|nr_employed_cube|age_mult_duration|   age_div_duration|age_add_duration|age_sub_duration|age_mult_campaign|age_div_campaign|age_add_campaign|age_sub_campaign|age_mult_pdays|       age_div_pdays|age_add_pdays|age_sub_pdays|age_mult_previous|age_div_previous|age_add_previous|age_sub_previous|age_mult_emp_var_rate|age_div_emp_var_rate|age_add_emp_var_rate|age_sub_emp_var_rate|age_mult_cons_price_idx|age_div_cons_price_idx|age_add_cons_price_idx|age_sub_cons_price_idx|age_mult_cons_conf_idx|age_div_cons_conf_idx|age_add_cons_conf_idx|age_sub_cons_conf_idx|age_mult_euribor3m| age_div_euribor3m|age_add_euribor3m|age_sub_euribor3m|age_mult_nr_employed| age_div_nr_employed|age_add_nr_employed|age_sub_nr_employed|duration_mult_campaign|duration_div_campaign|duration_add_campaign|duration_sub_campaign|duration_mult_pdays| duration_div_pdays|duration_add_pdays|duration_sub_pdays|duration_mult_previous|duration_div_previous|duration_add_previous|duration_sub_previous|duration_mult_emp_var_rate|duration_div_emp_var_rate|duration_add_emp_var_rate|duration_sub_emp_var_rate|duration_mult_cons_price_idx|duration_div_cons_price_idx|duration_add_cons_price_idx|duration_sub_cons_price_idx|duration_mult_cons_conf_idx|duration_div_cons_conf_idx|duration_add_cons_conf_idx|duration_sub_cons_conf_idx|duration_mult_euribor3m|duration_div_euribor3m|duration_add_euribor3m|duration_sub_euribor3m|duration_mult_nr_employed|duration_div_nr_employed|duration_add_nr_employed|duration_sub_nr_employed|campaign_mult_pdays|  campaign_div_pdays|campaign_add_pdays|campaign_sub_pdays|campaign_mult_previous|campaign_div_previous|campaign_add_previous|campaign_sub_previous|campaign_mult_emp_var_rate|campaign_div_emp_var_rate|campaign_add_emp_var_rate|campaign_sub_emp_var_rate|campaign_mult_cons_price_idx|campaign_div_cons_price_idx|campaign_add_cons_price_idx|campaign_sub_cons_price_idx|campaign_mult_cons_conf_idx|campaign_div_cons_conf_idx|campaign_add_cons_conf_idx|campaign_sub_cons_conf_idx|campaign_mult_euribor3m|campaign_div_euribor3m|campaign_add_euribor3m|campaign_sub_euribor3m|campaign_mult_nr_employed|campaign_div_nr_employed|campaign_add_nr_employed|campaign_sub_nr_employed|pdays_mult_previous|pdays_div_previous|pdays_add_previous|pdays_sub_previous|pdays_mult_emp_var_rate|pdays_div_emp_var_rate|pdays_add_emp_var_rate|pdays_sub_emp_var_rate|pdays_mult_cons_price_idx|pdays_div_cons_price_idx|pdays_add_cons_price_idx|pdays_sub_cons_price_idx|pdays_mult_cons_conf_idx|pdays_div_cons_conf_idx|pdays_add_cons_conf_idx|pdays_sub_cons_conf_idx|pdays_mult_euribor3m|pdays_div_euribor3m|pdays_add_euribor3m|pdays_sub_euribor3m|pdays_mult_nr_employed|pdays_div_nr_employed|pdays_add_nr_employed|pdays_sub_nr_employed|previous_mult_emp_var_rate|previous_div_emp_var_rate|previous_add_emp_var_rate|previous_sub_emp_var_rate|previous_mult_cons_price_idx|previous_div_cons_price_idx|previous_add_cons_price_idx|previous_sub_cons_price_idx|previous_mult_cons_conf_idx|previous_div_cons_conf_idx|previous_add_cons_conf_idx|previous_sub_cons_conf_idx|previous_mult_euribor3m|previous_div_euribor3m|previous_add_euribor3m|previous_sub_euribor3m|previous_mult_nr_employed|previous_div_nr_employed|previous_add_nr_employed|previous_sub_nr_employed|emp_var_rate_mult_cons_price_idx|emp_var_rate_div_cons_price_idx|emp_var_rate_add_cons_price_idx|emp_var_rate_sub_cons_price_idx|emp_var_rate_mult_cons_conf_idx|emp_var_rate_div_cons_conf_idx|emp_var_rate_add_cons_conf_idx|emp_var_rate_sub_cons_conf_idx|emp_var_rate_mult_euribor3m|emp_var_rate_div_euribor3m|emp_var_rate_add_euribor3m|emp_var_rate_sub_euribor3m|emp_var_rate_mult_nr_employed|emp_var_rate_div_nr_employed|emp_var_rate_add_nr_employed|emp_var_rate_sub_nr_employed|cons_price_idx_mult_cons_conf_idx|cons_price_idx_div_cons_conf_idx|cons_price_idx_add_cons_conf_idx|cons_price_idx_sub_cons_conf_idx|cons_price_idx_mult_euribor3m|cons_price_idx_div_euribor3m|cons_price_idx_add_euribor3m|cons_price_idx_sub_euribor3m|cons_price_idx_mult_nr_employed|cons_price_idx_div_nr_employed|cons_price_idx_add_nr_employed|cons_price_idx_sub_nr_employed|cons_conf_idx_mult_euribor3m|cons_conf_idx_div_euribor3m|cons_conf_idx_add_euribor3m|cons_conf_idx_sub_euribor3m|cons_conf_idx_mult_nr_employed|cons_conf_idx_div_nr_employed|cons_conf_idx_add_nr_employed|cons_conf_idx_sub_nr_employed|euribor3m_mult_nr_employed|euribor3m_div_nr_employed|euribor3m_add_nr_employed|euribor3m_sub_nr_employed|age_binned|duration_binned|campaign_binned|emp_var_rate_binned|cons_price_idx_binned|cons_conf_idx_binned|euribor3m_binned|nr_employed_binned|job_index|marital_index|education_index|default_index|housing_index|loan_index|contact_index|month_index|day_of_week_index|poutcome_index|   job_encoded|marital_encoded|education_encoded|default_encoded|housing_encoded| loan_encoded|contact_encoded|month_encoded|day_of_week_encoded|poutcome_encoded|            features|\n",
      "+---+---------+-------+-----------+-------+-------+----+---------+-----+-----------+--------+--------+-----+--------+-----------+------------+--------------+-------------+---------+-----------+---+------------------+-----------------+----------+--------+------------------+------------------+---------------+-------------+------------------+-------------+---------------+-------------+-----------------+------------------+------------+------------+------------+-------------+---------------+-------------+------------------+------------------+-------------------+------------------+------------------+-------------------+---------------------+-------------------+-----------------+------------------+--------------------+-------------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+------------------+----------------+-----------------+-------------------+----------------+----------------+-----------------+----------------+----------------+----------------+--------------+--------------------+-------------+-------------+-----------------+----------------+----------------+----------------+---------------------+--------------------+--------------------+--------------------+-----------------------+----------------------+----------------------+----------------------+----------------------+---------------------+---------------------+---------------------+------------------+------------------+-----------------+-----------------+--------------------+--------------------+-------------------+-------------------+----------------------+---------------------+---------------------+---------------------+-------------------+-------------------+------------------+------------------+----------------------+---------------------+---------------------+---------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------------------------+---------------------------+---------------------------+---------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+-------------------+--------------------+------------------+------------------+----------------------+---------------------+---------------------+---------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------------------------+---------------------------+---------------------------+---------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+-------------------+------------------+------------------+------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+------------------------+-----------------------+-----------------------+-----------------------+--------------------+-------------------+-------------------+-------------------+----------------------+---------------------+---------------------+---------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------------------------+---------------------------+---------------------------+---------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+--------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+------------------------------+------------------------------+------------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------------+----------------------------+----------------------------+----------------------------+---------------------------------+--------------------------------+--------------------------------+--------------------------------+-----------------------------+----------------------------+----------------------------+----------------------------+-------------------------------+------------------------------+------------------------------+------------------------------+----------------------------+---------------------------+---------------------------+---------------------------+------------------------------+-----------------------------+-----------------------------+-----------------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------+---------------+---------------+-------------------+---------------------+--------------------+----------------+------------------+---------+-------------+---------------+-------------+-------------+----------+-------------+-----------+-----------------+--------------+--------------+---------------+-----------------+---------------+---------------+-------------+---------------+-------------+-------------------+----------------+--------------------+\n",
      "| 56|housemaid|married|   basic.4y|     no|     no|  no|telephone|  may|        mon|     261|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|     5191.0|  0|  4.04305126783455|7.483314773547883|    3136.0|175616.0| 5.568344503761097| 16.15549442140351|        68121.0|  1.7779581E7|0.6931471805599453|          1.0|            1.0|          1.0|6.907755278982137|31.606961258558215|    998001.0|9.97002999E8|         0.0|          0.0|            0.0|          0.0|0.7419373447293773|1.0488088481701516| 1.2100000000000002|1.3310000000000004|  4.55381373171126|  9.695050283520969|          8834.872036|   830424.962151784|              0.0|               0.0|  1324.9599999999998|-48228.543999999994|1.7676375271076452|2.203860249652868|23.590449000000003|114.57881079300002|8.554874258383926|72.04859471218019|       2.6946481E7|1.39879182871E11|            14616|0.21455938697318008|             317|            -205|               56|            56.0|              57|              55|         55944|0.056056056056056056|         1055|         -943|                0|             0.0|              56|              56|    61.60000000000001|   50.90909090909091|                57.1|                54.9|               5263.664|    0.5957827095346512|               149.994|               -37.994|   -2038.3999999999999|  -1.5384615384615385|                 19.6|                 92.4|           271.992|11.529750875025735|           60.857|           51.143|            290696.0|0.010787902138316317|             5247.0|            -5135.0|                   261|                261.0|                  262|                  260|             260739|0.26126126126126126|              1260|              -738|                     0|                  0.0|                  261|                  261|                     287.1|       237.27272727272725|                    262.1|                    259.9|                   24532.434|          2.776772985509713|                    354.994|                    167.006|                    -9500.4|        -7.170329670329671|                     224.6|                     297.4|     1267.6770000000001|     53.73687461395923|               265.857|               256.143|                1354851.0|     0.05027932960893855|                  5452.0|                 -4930.0|                999|0.001001001001001001|              1000|              -998|                     0|                  0.0|                    1|                    1|                       1.1|       0.9090909090909091|                      2.1|     -0.10000000000000009|                      93.994|       0.010638976955975913|                     94.994|                    -92.994|                      -36.4|      -0.02747252747252...|                     -35.4|                      37.4|                  4.857|   0.20588840848260243|                 5.857|                -3.857|                   5191.0|    1.926411096127913...|                  5192.0|                 -5190.0|                  0|               0.0|               999|               999|                 1098.9|     908.1818181818181|                1000.1|                 997.9|                93900.006|      10.628337979019937|                1092.994|                 905.006|                -36363.6|    -27.445054945054945|                  962.6|                 1035.4|            4852.143| 205.68252007411982|           1003.857|            994.143|             5185809.0|  0.19244846850317857|               6190.0|              -4192.0|                       0.0|                      0.0|                      1.1|                     -1.1|                         0.0|                        0.0|                     93.994|                    -93.994|                       -0.0|                      -0.0|                     -36.4|                      36.4|                    0.0|                   0.0|                 4.857|                -4.857|                      0.0|                     0.0|                  5191.0|                 -5191.0|              103.39340000000001|           0.011702874651573505|                         95.094|                        -92.894|                         -40.04|          -0.03021978021978...|                         -35.3|                          37.5|          5.342700000000001|        0.2264772493308627|         5.957000000000001|                    -3.757|                       5710.1|        2.119052205740705...|                      5192.1|                     -5189.9|              -3421.3815999999997|             -2.5822527472527472|                          57.594|                         130.394|                   456.528858|           19.35227506691373|                      98.851|                      89.137|                     487922.854|           0.01810710845694471|                      5284.994|                     -5097.006|                   -176.7948|         -7.494338068766728|                    -31.543|                    -41.257|                     -188952.4|         -0.00701213638990...|                       5154.6|                      -5227.4|                 25212.687|     9.356578693893277E-4|                 5195.857|                -5186.143|       4.0|            3.0|            0.0|                3.0|                  4.0|                 4.0|             2.0|               2.0|      8.0|          0.0|            4.0|          0.0|          1.0|       0.0|          1.0|        0.0|              1.0|           0.0|(11,[8],[1.0])|  (3,[0],[1.0])|    (7,[4],[1.0])|  (2,[0],[1.0])|  (2,[1],[1.0])|(2,[0],[1.0])|      (1,[],[])|(9,[0],[1.0])|      (4,[1],[1.0])|   (2,[0],[1.0])|[0.0,0.0,0.0,0.0,...|\n",
      "| 57| services|married|high.school|unknown|     no|  no|telephone|  may|        mon|     149|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|     5191.0|  0| 4.060443010546419| 7.54983443527075|    3249.0|185193.0|5.0106352940962555|12.206555615733702|        22201.0|    3307949.0|0.6931471805599453|          1.0|            1.0|          1.0|6.907755278982137|31.606961258558215|    998001.0|9.97002999E8|         0.0|          0.0|            0.0|          0.0|0.7419373447293773|1.0488088481701516| 1.2100000000000002|1.3310000000000004|  4.55381373171126|  9.695050283520969|          8834.872036|   830424.962151784|              0.0|               0.0|  1324.9599999999998|-48228.543999999994|1.7676375271076452|2.203860249652868|23.590449000000003|114.57881079300002|8.554874258383926|72.04859471218019|       2.6946481E7|1.39879182871E11|             8493| 0.3825503355704698|             206|             -92|               57|            57.0|              58|              56|         56943|0.057057057057057055|         1056|         -942|                0|             0.0|              57|              57|                 62.7|   51.81818181818181|                58.1|                55.9|               5357.658|    0.6064216864906271|               150.994|               -36.994|   -2074.7999999999997|   -1.565934065934066|                 20.6|                 93.4|           276.849|11.735639283508338|           61.857|           52.143|            295887.0|0.010980543247929108|             5248.0|            -5134.0|                   149|                149.0|                  150|                  148|             148851|0.14914914914914915|              1148|              -850|                     0|                  0.0|                  149|                  149|                     163.9|       135.45454545454544|                    150.1|                    147.9|                   14005.106|          1.585207566440411|                    242.994|                     55.006|         -5423.599999999999|        -4.093406593406594|                     112.6|                     185.4|                723.693|     30.67737286390776|               153.857|               144.143|                 773459.0|    0.028703525332305913|                  5340.0|                 -5042.0|                999|0.001001001001001001|              1000|              -998|                     0|                  0.0|                    1|                    1|                       1.1|       0.9090909090909091|                      2.1|     -0.10000000000000009|                      93.994|       0.010638976955975913|                     94.994|                    -92.994|                      -36.4|      -0.02747252747252...|                     -35.4|                      37.4|                  4.857|   0.20588840848260243|                 5.857|                -3.857|                   5191.0|    1.926411096127913...|                  5192.0|                 -5190.0|                  0|               0.0|               999|               999|                 1098.9|     908.1818181818181|                1000.1|                 997.9|                93900.006|      10.628337979019937|                1092.994|                 905.006|                -36363.6|    -27.445054945054945|                  962.6|                 1035.4|            4852.143| 205.68252007411982|           1003.857|            994.143|             5185809.0|  0.19244846850317857|               6190.0|              -4192.0|                       0.0|                      0.0|                      1.1|                     -1.1|                         0.0|                        0.0|                     93.994|                    -93.994|                       -0.0|                      -0.0|                     -36.4|                      36.4|                    0.0|                   0.0|                 4.857|                -4.857|                      0.0|                     0.0|                  5191.0|                 -5191.0|              103.39340000000001|           0.011702874651573505|                         95.094|                        -92.894|                         -40.04|          -0.03021978021978...|                         -35.3|                          37.5|          5.342700000000001|        0.2264772493308627|         5.957000000000001|                    -3.757|                       5710.1|        2.119052205740705...|                      5192.1|                     -5189.9|              -3421.3815999999997|             -2.5822527472527472|                          57.594|                         130.394|                   456.528858|           19.35227506691373|                      98.851|                      89.137|                     487922.854|           0.01810710845694471|                      5284.994|                     -5097.006|                   -176.7948|         -7.494338068766728|                    -31.543|                    -41.257|                     -188952.4|         -0.00701213638990...|                       5154.6|                      -5227.4|                 25212.687|     9.356578693893277E-4|                 5195.857|                -5186.143|       4.0|            2.0|            0.0|                3.0|                  4.0|                 4.0|             2.0|               2.0|      3.0|          0.0|            1.0|          1.0|          1.0|       0.0|          1.0|        0.0|              1.0|           0.0|(11,[3],[1.0])|  (3,[0],[1.0])|    (7,[1],[1.0])|  (2,[1],[1.0])|  (2,[1],[1.0])|(2,[0],[1.0])|      (1,[],[])|(9,[0],[1.0])|      (4,[1],[1.0])|   (2,[0],[1.0])|[0.0,0.0,0.0,1.0,...|\n",
      "| 37| services|married|high.school|     no|    yes|  no|telephone|  may|        mon|     226|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|     5191.0|  0|3.6375861597263857|6.082762530298219|    1369.0| 50653.0| 5.424950017481403|15.033296378372908|        51076.0|  1.1543176E7|0.6931471805599453|          1.0|            1.0|          1.0|6.907755278982137|31.606961258558215|    998001.0|9.97002999E8|         0.0|          0.0|            0.0|          0.0|0.7419373447293773|1.0488088481701516| 1.2100000000000002|1.3310000000000004|  4.55381373171126|  9.695050283520969|          8834.872036|   830424.962151784|              0.0|               0.0|  1324.9599999999998|-48228.543999999994|1.7676375271076452|2.203860249652868|23.590449000000003|114.57881079300002|8.554874258383926|72.04859471218019|       2.6946481E7|1.39879182871E11|             8362|0.16371681415929204|             263|            -189|               37|            37.0|              38|              36|         36963|0.037037037037037035|         1036|         -962|                0|             0.0|              37|              37|                 40.7|   33.63636363636363|                38.1|                35.9|               3477.778|    0.3936421473711088|               130.994|               -56.994|               -1346.8|  -1.0164835164835164|   0.6000000000000014|                 73.4|           179.709|  7.61787111385629|           41.857|           32.143|            192067.0| 0.00712772105567328|             5228.0|            -5154.0|                   226|                226.0|                  227|                  225|             225774|0.22622622622622623|              1225|              -773|                     0|                  0.0|                  226|                  226|        248.60000000000002|       205.45454545454544|                    227.1|                    224.9|                   21242.644|         2.4044087920505564|                    319.994|                    132.006|                    -8226.4|        -6.208791208791209|                     189.6|                     262.4|               1097.682|     46.53078031706815|               230.857|               221.143|                1173166.0|     0.04353689077249085|                  5417.0|                 -4965.0|                999|0.001001001001001001|              1000|              -998|                     0|                  0.0|                    1|                    1|                       1.1|       0.9090909090909091|                      2.1|     -0.10000000000000009|                      93.994|       0.010638976955975913|                     94.994|                    -92.994|                      -36.4|      -0.02747252747252...|                     -35.4|                      37.4|                  4.857|   0.20588840848260243|                 5.857|                -3.857|                   5191.0|    1.926411096127913...|                  5192.0|                 -5190.0|                  0|               0.0|               999|               999|                 1098.9|     908.1818181818181|                1000.1|                 997.9|                93900.006|      10.628337979019937|                1092.994|                 905.006|                -36363.6|    -27.445054945054945|                  962.6|                 1035.4|            4852.143| 205.68252007411982|           1003.857|            994.143|             5185809.0|  0.19244846850317857|               6190.0|              -4192.0|                       0.0|                      0.0|                      1.1|                     -1.1|                         0.0|                        0.0|                     93.994|                    -93.994|                       -0.0|                      -0.0|                     -36.4|                      36.4|                    0.0|                   0.0|                 4.857|                -4.857|                      0.0|                     0.0|                  5191.0|                 -5191.0|              103.39340000000001|           0.011702874651573505|                         95.094|                        -92.894|                         -40.04|          -0.03021978021978...|                         -35.3|                          37.5|          5.342700000000001|        0.2264772493308627|         5.957000000000001|                    -3.757|                       5710.1|        2.119052205740705...|                      5192.1|                     -5189.9|              -3421.3815999999997|             -2.5822527472527472|                          57.594|                         130.394|                   456.528858|           19.35227506691373|                      98.851|                      89.137|                     487922.854|           0.01810710845694471|                      5284.994|                     -5097.006|                   -176.7948|         -7.494338068766728|                    -31.543|                    -41.257|                     -188952.4|         -0.00701213638990...|                       5154.6|                      -5227.4|                 25212.687|     9.356578693893277E-4|                 5195.857|                -5186.143|       2.0|            3.0|            0.0|                3.0|                  4.0|                 4.0|             2.0|               2.0|      3.0|          0.0|            1.0|          0.0|          0.0|       0.0|          1.0|        0.0|              1.0|           0.0|(11,[3],[1.0])|  (3,[0],[1.0])|    (7,[1],[1.0])|  (2,[0],[1.0])|  (2,[0],[1.0])|(2,[0],[1.0])|      (1,[],[])|(9,[0],[1.0])|      (4,[1],[1.0])|   (2,[0],[1.0])|[0.0,0.0,0.0,1.0,...|\n",
      "| 40|   admin.|married|   basic.6y|     no|     no|  no|telephone|  may|        mon|     151|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|     5191.0|  0| 3.713572066704308|6.324555320336759|    1600.0| 64000.0|5.0238805208462765|12.288205727444508|        22801.0|    3442951.0|0.6931471805599453|          1.0|            1.0|          1.0|6.907755278982137|31.606961258558215|    998001.0|9.97002999E8|         0.0|          0.0|            0.0|          0.0|0.7419373447293773|1.0488088481701516| 1.2100000000000002|1.3310000000000004|  4.55381373171126|  9.695050283520969|          8834.872036|   830424.962151784|              0.0|               0.0|  1324.9599999999998|-48228.543999999994|1.7676375271076452|2.203860249652868|23.590449000000003|114.57881079300002|8.554874258383926|72.04859471218019|       2.6946481E7|1.39879182871E11|             6040|0.26490066225165565|             191|            -111|               40|            40.0|              41|              39|         39960| 0.04004004004004004|         1039|         -959|                0|             0.0|              40|              40|                 44.0|   36.36363636363636|                41.1|                38.9|                3759.76|   0.42555907823903655|               133.994|               -53.994|               -1456.0|   -1.098901098901099|   3.6000000000000014|                 76.4|            194.28| 8.235536339304097|           44.857|           35.143|            207640.0|0.007705644384511...|             5231.0|            -5151.0|                   151|                151.0|                  152|                  150|             150849|0.15115115115115116|              1150|              -848|                     0|                  0.0|                  151|                  151|        166.10000000000002|       137.27272727272725|                    152.1|                    149.9|                   14193.094|          1.606485520352363|                    244.994|                     57.006|                    -5496.4|        -4.148351648351649|                     114.6|                     187.4|                733.407|    31.089149680872964|               155.857|               146.143|                 783841.0|    0.029088807551531495|                  5342.0|                 -5040.0|                999|0.001001001001001001|              1000|              -998|                     0|                  0.0|                    1|                    1|                       1.1|       0.9090909090909091|                      2.1|     -0.10000000000000009|                      93.994|       0.010638976955975913|                     94.994|                    -92.994|                      -36.4|      -0.02747252747252...|                     -35.4|                      37.4|                  4.857|   0.20588840848260243|                 5.857|                -3.857|                   5191.0|    1.926411096127913...|                  5192.0|                 -5190.0|                  0|               0.0|               999|               999|                 1098.9|     908.1818181818181|                1000.1|                 997.9|                93900.006|      10.628337979019937|                1092.994|                 905.006|                -36363.6|    -27.445054945054945|                  962.6|                 1035.4|            4852.143| 205.68252007411982|           1003.857|            994.143|             5185809.0|  0.19244846850317857|               6190.0|              -4192.0|                       0.0|                      0.0|                      1.1|                     -1.1|                         0.0|                        0.0|                     93.994|                    -93.994|                       -0.0|                      -0.0|                     -36.4|                      36.4|                    0.0|                   0.0|                 4.857|                -4.857|                      0.0|                     0.0|                  5191.0|                 -5191.0|              103.39340000000001|           0.011702874651573505|                         95.094|                        -92.894|                         -40.04|          -0.03021978021978...|                         -35.3|                          37.5|          5.342700000000001|        0.2264772493308627|         5.957000000000001|                    -3.757|                       5710.1|        2.119052205740705...|                      5192.1|                     -5189.9|              -3421.3815999999997|             -2.5822527472527472|                          57.594|                         130.394|                   456.528858|           19.35227506691373|                      98.851|                      89.137|                     487922.854|           0.01810710845694471|                      5284.994|                     -5097.006|                   -176.7948|         -7.494338068766728|                    -31.543|                    -41.257|                     -188952.4|         -0.00701213638990...|                       5154.6|                      -5227.4|                 25212.687|     9.356578693893277E-4|                 5195.857|                -5186.143|       2.0|            2.0|            0.0|                3.0|                  4.0|                 4.0|             2.0|               2.0|      0.0|          0.0|            5.0|          0.0|          1.0|       0.0|          1.0|        0.0|              1.0|           0.0|(11,[0],[1.0])|  (3,[0],[1.0])|    (7,[5],[1.0])|  (2,[0],[1.0])|  (2,[1],[1.0])|(2,[0],[1.0])|      (1,[],[])|(9,[0],[1.0])|      (4,[1],[1.0])|   (2,[0],[1.0])|[1.0,0.0,0.0,0.0,...|\n",
      "| 56| services|married|high.school|     no|     no| yes|telephone|  may|        mon|     307|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|     5191.0|  0|  4.04305126783455|7.483314773547883|    3136.0|175616.0| 5.730099782973575| 17.52141546793523|        94249.0|  2.8934443E7|0.6931471805599453|          1.0|            1.0|          1.0|6.907755278982137|31.606961258558215|    998001.0|9.97002999E8|         0.0|          0.0|            0.0|          0.0|0.7419373447293773|1.0488088481701516| 1.2100000000000002|1.3310000000000004|  4.55381373171126|  9.695050283520969|          8834.872036|   830424.962151784|              0.0|               0.0|  1324.9599999999998|-48228.543999999994|1.7676375271076452|2.203860249652868|23.590449000000003|114.57881079300002|8.554874258383926|72.04859471218019|       2.6946481E7|1.39879182871E11|            17192|0.18241042345276873|             363|            -251|               56|            56.0|              57|              55|         55944|0.056056056056056056|         1055|         -943|                0|             0.0|              56|              56|    61.60000000000001|   50.90909090909091|                57.1|                54.9|               5263.664|    0.5957827095346512|               149.994|               -37.994|   -2038.3999999999999|  -1.5384615384615385|                 19.6|                 92.4|           271.992|11.529750875025735|           60.857|           51.143|            290696.0|0.010787902138316317|             5247.0|            -5135.0|                   307|                307.0|                  308|                  306|             306693| 0.3073073073073073|              1306|              -692|                     0|                  0.0|                  307|                  307|        337.70000000000005|       279.09090909090907|                    308.1|                    305.9|                   28856.158|         3.2661659254846054|                    400.994|                    213.006|                   -11174.8|        -8.434065934065934|                     270.6|                     343.4|     1491.0990000000002|    63.207741404158945|               311.857|               302.143|                1593637.0|     0.05914082065112695|                  5498.0|                 -4884.0|                999|0.001001001001001001|              1000|              -998|                     0|                  0.0|                    1|                    1|                       1.1|       0.9090909090909091|                      2.1|     -0.10000000000000009|                      93.994|       0.010638976955975913|                     94.994|                    -92.994|                      -36.4|      -0.02747252747252...|                     -35.4|                      37.4|                  4.857|   0.20588840848260243|                 5.857|                -3.857|                   5191.0|    1.926411096127913...|                  5192.0|                 -5190.0|                  0|               0.0|               999|               999|                 1098.9|     908.1818181818181|                1000.1|                 997.9|                93900.006|      10.628337979019937|                1092.994|                 905.006|                -36363.6|    -27.445054945054945|                  962.6|                 1035.4|            4852.143| 205.68252007411982|           1003.857|            994.143|             5185809.0|  0.19244846850317857|               6190.0|              -4192.0|                       0.0|                      0.0|                      1.1|                     -1.1|                         0.0|                        0.0|                     93.994|                    -93.994|                       -0.0|                      -0.0|                     -36.4|                      36.4|                    0.0|                   0.0|                 4.857|                -4.857|                      0.0|                     0.0|                  5191.0|                 -5191.0|              103.39340000000001|           0.011702874651573505|                         95.094|                        -92.894|                         -40.04|          -0.03021978021978...|                         -35.3|                          37.5|          5.342700000000001|        0.2264772493308627|         5.957000000000001|                    -3.757|                       5710.1|        2.119052205740705...|                      5192.1|                     -5189.9|              -3421.3815999999997|             -2.5822527472527472|                          57.594|                         130.394|                   456.528858|           19.35227506691373|                      98.851|                      89.137|                     487922.854|           0.01810710845694471|                      5284.994|                     -5097.006|                   -176.7948|         -7.494338068766728|                    -31.543|                    -41.257|                     -188952.4|         -0.00701213638990...|                       5154.6|                      -5227.4|                 25212.687|     9.356578693893277E-4|                 5195.857|                -5186.143|       4.0|            3.0|            0.0|                3.0|                  4.0|                 4.0|             2.0|               2.0|      3.0|          0.0|            1.0|          0.0|          1.0|       1.0|          1.0|        0.0|              1.0|           0.0|(11,[3],[1.0])|  (3,[0],[1.0])|    (7,[1],[1.0])|  (2,[0],[1.0])|  (2,[1],[1.0])|(2,[1],[1.0])|      (1,[],[])|(9,[0],[1.0])|      (4,[1],[1.0])|   (2,[0],[1.0])|[0.0,0.0,0.0,1.0,...|\n",
      "+---+---------+-------+-----------+-------+-------+----+---------+-----+-----------+--------+--------+-----+--------+-----------+------------+--------------+-------------+---------+-----------+---+------------------+-----------------+----------+--------+------------------+------------------+---------------+-------------+------------------+-------------+---------------+-------------+-----------------+------------------+------------+------------+------------+-------------+---------------+-------------+------------------+------------------+-------------------+------------------+------------------+-------------------+---------------------+-------------------+-----------------+------------------+--------------------+-------------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+------------------+----------------+-----------------+-------------------+----------------+----------------+-----------------+----------------+----------------+----------------+--------------+--------------------+-------------+-------------+-----------------+----------------+----------------+----------------+---------------------+--------------------+--------------------+--------------------+-----------------------+----------------------+----------------------+----------------------+----------------------+---------------------+---------------------+---------------------+------------------+------------------+-----------------+-----------------+--------------------+--------------------+-------------------+-------------------+----------------------+---------------------+---------------------+---------------------+-------------------+-------------------+------------------+------------------+----------------------+---------------------+---------------------+---------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------------------------+---------------------------+---------------------------+---------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+-------------------+--------------------+------------------+------------------+----------------------+---------------------+---------------------+---------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------------------------+---------------------------+---------------------------+---------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+-------------------+------------------+------------------+------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+------------------------+-----------------------+-----------------------+-----------------------+--------------------+-------------------+-------------------+-------------------+----------------------+---------------------+---------------------+---------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------------------------+---------------------------+---------------------------+---------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------+----------------------+----------------------+----------------------+-------------------------+------------------------+------------------------+------------------------+--------------------------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+------------------------------+------------------------------+------------------------------+---------------------------+--------------------------+--------------------------+--------------------------+-----------------------------+----------------------------+----------------------------+----------------------------+---------------------------------+--------------------------------+--------------------------------+--------------------------------+-----------------------------+----------------------------+----------------------------+----------------------------+-------------------------------+------------------------------+------------------------------+------------------------------+----------------------------+---------------------------+---------------------------+---------------------------+------------------------------+-----------------------------+-----------------------------+-----------------------------+--------------------------+-------------------------+-------------------------+-------------------------+----------+---------------+---------------+-------------------+---------------------+--------------------+----------------+------------------+---------+-------------+---------------+-------------+-------------+----------+-------------+-----------+-----------------+--------------+--------------+---------------+-----------------+---------------+---------------+-------------+---------------+-------------+-------------------+----------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "transformed_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b260064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 249, 270)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns), len(df_with_features.columns), len(transformed_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7aaa6099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2794dd38",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb00454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.core.features.feature_selector import FeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86f5f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selector = FeatureSelector(\n",
    "    problem=problem,\n",
    "    transformed_df=transformed_df,\n",
    "    feature_names=feature_names,\n",
    "    feature_col=feature_output_col,\n",
    "    feature_idx_name_mapping=feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa750519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 08:12:11,363 INFO XGBoost-PySpark: _fit Running xgboost-3.1.3 on 1 workers with\n",
      "\tbooster params: {'objective': 'binary:logistic', 'device': 'cpu', 'eval_metric': 'logloss', 'learning_rate': 0.1, 'max_depth': 4, 'random_state': 42, 'num_round': 100, 'eta': 0.1, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2026-01-15 08:12:16,862 INFO XGBoost-PySpark: _train_booster Training on CPUs 1]\n",
      "[08:12:17] Task 0 got rank 0\n",
      "/Users/aays/Documents/aays/spark_beyond/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [08:12:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"num_round\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[08:12:18] [0]\ttraining-logloss:0.31523\n",
      "[08:12:18] [1]\ttraining-logloss:0.29081\n",
      "[08:12:18] [2]\ttraining-logloss:0.27289\n",
      "[08:12:18] [3]\ttraining-logloss:0.25869\n",
      "[08:12:18] [4]\ttraining-logloss:0.24728\n",
      "[08:12:18] [5]\ttraining-logloss:0.23768\n",
      "[08:12:18] [6]\ttraining-logloss:0.22951\n",
      "[08:12:18] [7]\ttraining-logloss:0.22248\n",
      "[08:12:18] [8]\ttraining-logloss:0.21654\n",
      "[08:12:18] [9]\ttraining-logloss:0.21132\n",
      "[08:12:18] [10]\ttraining-logloss:0.20678\n",
      "[08:12:18] [11]\ttraining-logloss:0.20275\n",
      "[08:12:18] [12]\ttraining-logloss:0.19924\n",
      "[08:12:18] [13]\ttraining-logloss:0.19624\n",
      "[08:12:18] [14]\ttraining-logloss:0.19337\n",
      "[08:12:18] [15]\ttraining-logloss:0.19094\n",
      "[08:12:18] [16]\ttraining-logloss:0.18858\n",
      "[08:12:18] [17]\ttraining-logloss:0.18659\n",
      "[08:12:18] [18]\ttraining-logloss:0.18487\n",
      "[08:12:18] [19]\ttraining-logloss:0.18322\n",
      "[08:12:18] [20]\ttraining-logloss:0.18180\n",
      "[08:12:18] [21]\ttraining-logloss:0.18044\n",
      "[08:12:18] [22]\ttraining-logloss:0.17924\n",
      "[08:12:18] [23]\ttraining-logloss:0.17811\n",
      "[08:12:18] [24]\ttraining-logloss:0.17715\n",
      "[08:12:18] [25]\ttraining-logloss:0.17625\n",
      "[08:12:18] [26]\ttraining-logloss:0.17540\n",
      "[08:12:18] [27]\ttraining-logloss:0.17466\n",
      "[08:12:18] [28]\ttraining-logloss:0.17395\n",
      "[08:12:18] [29]\ttraining-logloss:0.17332\n",
      "[08:12:18] [30]\ttraining-logloss:0.17273\n",
      "[08:12:18] [31]\ttraining-logloss:0.17219\n",
      "[08:12:18] [32]\ttraining-logloss:0.17173\n",
      "[08:12:18] [33]\ttraining-logloss:0.17126\n",
      "[08:12:18] [34]\ttraining-logloss:0.17084\n",
      "[08:12:18] [35]\ttraining-logloss:0.17040\n",
      "[08:12:18] [36]\ttraining-logloss:0.16994\n",
      "[08:12:18] [37]\ttraining-logloss:0.16958\n",
      "[08:12:18] [38]\ttraining-logloss:0.16922\n",
      "[08:12:19] [39]\ttraining-logloss:0.16888\n",
      "[08:12:19] [40]\ttraining-logloss:0.16854\n",
      "[08:12:19] [41]\ttraining-logloss:0.16825\n",
      "[08:12:19] [42]\ttraining-logloss:0.16797\n",
      "[08:12:19] [43]\ttraining-logloss:0.16757\n",
      "[08:12:19] [44]\ttraining-logloss:0.16728\n",
      "[08:12:19] [45]\ttraining-logloss:0.16690\n",
      "[08:12:19] [46]\ttraining-logloss:0.16665\n",
      "[08:12:19] [47]\ttraining-logloss:0.16643\n",
      "[08:12:19] [48]\ttraining-logloss:0.16615\n",
      "[08:12:19] [49]\ttraining-logloss:0.16592\n",
      "[08:12:19] [50]\ttraining-logloss:0.16569\n",
      "[08:12:19] [51]\ttraining-logloss:0.16545\n",
      "[08:12:19] [52]\ttraining-logloss:0.16523\n",
      "[08:12:19] [53]\ttraining-logloss:0.16493\n",
      "[08:12:19] [54]\ttraining-logloss:0.16466\n",
      "[08:12:19] [55]\ttraining-logloss:0.16446\n",
      "[08:12:19] [56]\ttraining-logloss:0.16424\n",
      "[08:12:19] [57]\ttraining-logloss:0.16399\n",
      "[08:12:19] [58]\ttraining-logloss:0.16379\n",
      "[08:12:19] [59]\ttraining-logloss:0.16353\n",
      "[08:12:19] [60]\ttraining-logloss:0.16340\n",
      "[08:12:19] [61]\ttraining-logloss:0.16312\n",
      "[08:12:19] [62]\ttraining-logloss:0.16291\n",
      "[08:12:19] [63]\ttraining-logloss:0.16265\n",
      "[08:12:19] [64]\ttraining-logloss:0.16224\n",
      "[08:12:19] [65]\ttraining-logloss:0.16213\n",
      "[08:12:19] [66]\ttraining-logloss:0.16203\n",
      "[08:12:19] [67]\ttraining-logloss:0.16169\n",
      "[08:12:19] [68]\ttraining-logloss:0.16150\n",
      "[08:12:19] [69]\ttraining-logloss:0.16140\n",
      "[08:12:19] [70]\ttraining-logloss:0.16114\n",
      "[08:12:19] [71]\ttraining-logloss:0.16096\n",
      "[08:12:19] [72]\ttraining-logloss:0.16056\n",
      "[08:12:19] [73]\ttraining-logloss:0.16037\n",
      "[08:12:19] [74]\ttraining-logloss:0.16022\n",
      "[08:12:19] [75]\ttraining-logloss:0.16003\n",
      "[08:12:19] [76]\ttraining-logloss:0.15992\n",
      "[08:12:19] [77]\ttraining-logloss:0.15984\n",
      "[08:12:19] [78]\ttraining-logloss:0.15966\n",
      "[08:12:19] [79]\ttraining-logloss:0.15950\n",
      "[08:12:19] [80]\ttraining-logloss:0.15940\n",
      "[08:12:19] [81]\ttraining-logloss:0.15925\n",
      "[08:12:19] [82]\ttraining-logloss:0.15913\n",
      "[08:12:19] [83]\ttraining-logloss:0.15890\n",
      "[08:12:19] [84]\ttraining-logloss:0.15871\n",
      "[08:12:19] [85]\ttraining-logloss:0.15861\n",
      "[08:12:19] [86]\ttraining-logloss:0.15833\n",
      "[08:12:19] [87]\ttraining-logloss:0.15807\n",
      "[08:12:19] [88]\ttraining-logloss:0.15782\n",
      "[08:12:19] [89]\ttraining-logloss:0.15776\n",
      "[08:12:19] [90]\ttraining-logloss:0.15766\n",
      "[08:12:19] [91]\ttraining-logloss:0.15752\n",
      "[08:12:19] [92]\ttraining-logloss:0.15740\n",
      "[08:12:19] [93]\ttraining-logloss:0.15727\n",
      "[08:12:19] [94]\ttraining-logloss:0.15722\n",
      "[08:12:19] [95]\ttraining-logloss:0.15716\n",
      "[08:12:19] [96]\ttraining-logloss:0.15699\n",
      "[08:12:19] [97]\ttraining-logloss:0.15678\n",
      "[08:12:19] [98]\ttraining-logloss:0.15667\n",
      "[08:12:19] [99]\ttraining-logloss:0.15645\n",
      "2026-01-15 08:12:20,791 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n"
     ]
    }
   ],
   "source": [
    "feature_selector.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c461a09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 08:12:23,397 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2026-01-15 08:12:25,539 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2026-01-15 08:12:27,416 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2026-01-15 08:12:29,328 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2026-01-15 08:12:31,290 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9275\n",
      "Precision: 0.9229\n",
      "Recall:    0.9275\n",
      "F1 Score:  0.9244\n",
      "AUC-ROC:   0.9606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.927525244867635,\n",
       " 'precision': 0.9228892346577022,\n",
       " 'recall': 0.9275252448676351,\n",
       " 'f1_score': 0.9243749120335091,\n",
       " 'auc_roc': 0.9606437069961044}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Evaluation\n",
    "feature_selector.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78734a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 08:12:34,866 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2026-01-15 08:12:36,859 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2026-01-15 08:12:38,671 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2026-01-15 08:12:40,818 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2026-01-15 08:12:42,853 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9196\n",
      "Precision: 0.9157\n",
      "Recall:    0.9196\n",
      "F1 Score:  0.9174\n",
      "AUC-ROC:   0.9503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9196200219218122,\n",
       " 'precision': 0.9157008573319453,\n",
       " 'recall': 0.9196200219218122,\n",
       " 'f1_score': 0.9173516213090067,\n",
       " 'auc_roc': 0.9502738079646209}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "\n",
    "feature_selector.evaluate(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2727b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature importance plot saved as 'sparkxgb_classification_importance.png'\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzsvQm8jeX6/387qSPVOQ2SUE51MjUnQyWKDCFCpDKEyBAqGTJmiiilFCmElBQKidKAzFOaKFPKLNRXJA3r/3pf53+v37OWtfZee7L35vN+vZ5jr2c9w/3ca+3O/tzXdX2uHKFQKOSEEEIIIYQQQgiR7vwj/S8phBBCCCGEEEIIiW4hhBBCCCGEECIDUaRbCCGEEEIIIYTIICS6hRBCCCGEEEKIDEKiWwghhBBCCCGEyCAkuoUQQgghhBBCiAxColsIIYQQQgghhMggJLqFEEIIIYQQQogMQqJbCCGEEEIIIYTIICS6hRBCCCHEcU+OHDnc448/nmn3v/nmm20LsmvXLnfnnXe6c845x8b37LPPuk8//dR+5t9jzX/+8x933333HfP7CnG8I9EthBAi29KwYUOXK1cu99133x313qBBg+wP15kzZ0bs//33393zzz/vypYt68466yx3yimnuPz587uaNWu6N954w/3111/hY7///nu7RnD717/+5a6++mo3fPjwiGMzixdffNG9+uqrCR8f/Tx+y5cvX4aM79ChQyZ0MkNAJALP/uCDD7rsyqJFi2x+f/75Z3ei8vnnn9t/Cy644AL3z3/+05199tnu1ltvdWPHjs0Sv6NJ8fDDD7s5c+a4xx57zE2YMMFVrVo1w++p74wQx56cmXBPIYQQIl0YOnSomzVrlmvVqpX7+OOPw/s3b97s+vbt6+rWretq1KgR3r9nzx532223uZUrV7oqVaq4Hj162B/oO3fudHPnznX33HOP27Bhg+vZs2fEfe6++25XrVo1+/mXX36xe7Zr185t2bLFDRkyJNNFd548eVIUnapUqZJr3LhxxL5TTz01w0R3nz597OfoKJ9IHwHF/PL5n3nmmSfclL7yyiv2+3/eeee5Ro0auUsvvdQdOHDAffTRR6558+Zux44drlu3bi4r8MEHHxy1j/9u1apVyz366KPhfYULF3a//fabLQge6+/Mt99+6/7xD8XkhEhvJLqFEEJkW/LmzeuefPJJ17JlSzdu3DjXpEkT29+mTRt38sknu2HDhkUczx/lq1evdlOmTHF16tSJeI9I04oVK+yPzmiuvfZai6R5uH7p0qXd66+/numiOzXwR33webIjf/75p/v7778zTJhkdQ4ePOhOO+00dyKzZMkSE9zXX3+9LYSdccYZ4fceeugh+33+6quvXFYh1nd19+7dRwlfRC8ZPJkBmQJCiPRHS1lCCCGyNffff7+78cYbLVK0d+9eN2nSJDd79mzXv39/V6BAgfBxixcvtjROBHq04PZcd9117t57700oJZnIWs6cOWNGni+77DL745W09bZt28ZM/X3rrbdciRIlLMJMpBoRvG3btohjiMA3bdrUFSxY0K53/vnnW1SMtHdff/n111+7efPmhdPE0yOazDiaNWtmz8h9eZ4xY8ZEHHPkyBHXq1cve4Z///vfJgBvuukm98knn4SPYZznnnuu/UxkzY/R19XGqnEFInA8W/A6nPfUU09Zzesll1xi4/rmm2/s/XXr1lldLFkLiBU+x+nTp6fq2X097eTJk23MfIcQc1yfLAfKExB0LPicfvrp9vmwL1bK+sSJE12RIkVsTMzT/Pnzj7ofi0BkX1C2wPUqVqxoYjII5QNck8+ZBR/uzXeCeezUqZMdc9FFF4Xn138/SK+uUKGCHc98FS9e3I0YMeKoMTDXZIR89tlnrlSpUjbeiy++2I0fP/6oY/kukxLNOVyTcZA18dNPP4WPYT569+7t/vvf/9oxpH137tz5qHlKK/47xTwHBbeH70FSGSBkqjCffEb8HlJXXa9evfD8ef744w+7F1F05objKE/58MMPE/5djf6++880FAq5F154IfzZQbya7qVLl1rGDWUx/L5deeWVEQuLX3zxhT0vnx3jpGSE32P+u+hJ7jsTq6Z706ZNNi/8fuXOnduVKVPGvffee3F/bwYMGGDzwBj4PpM9JMSJjiLdQgghsjX8offSSy+5a665xrVu3dotWLDA/thG7AaZMWOG/ZuaCC8p0l5U/N///Z97//33TdgTHQ/CH7T8cU49KWMhao7IWb58uVu4cKFF3/0f3PyBXrJkSTdw4EAzU+KPZ45BhPnIF+nxiGpS2fljmKgYf+j/8MMP9hoBynuIte7du9s5COXkOHz4cIRIAkQLYoGx8Ee1F46IZp6XVF2eHcHp54HUXlLvW7RoYSm9o0ePtrT9ZcuWWd075/L8zEXt2rXDix2IhdSAiGTsLJz42l3mh0UXxHHXrl1NjPCH/x133GEZDdw3NfC5IMS4JqIBHwA+P6KQ+/fvt88accxniXhhASIIAvnNN9907du3t7GyGEO9LnNz+eWX2zGMnYUKBDeilOvzXUaYcT7ZFEEQiMwp9yLSjVjHzwAvgmeeecYWb8AvdDD3LJjgV8ACEb8DXIMMgejfD56RhQU+ZzJGWGRBfLFYwDXg119/tfGuXbvWxBwZIHyPWODYunWr3Z9rcz8EPJ9TsWLF3JdffmnjY6zvvPOOSw/4nSSFvFy5cu7CCy9M1TX4vSTVukGDBiYSEZ7MGfPPgg4CE/is+T6wwMeiBN99ouirVq2yUo1EflejYdzUcJN9E6vcIxquxcIIYr5Dhw4mqPkc8KzgtT8Ggcx/W3if8YwaNcr+5bvK7zS/g0l9Z6Lhvwc33HCDzTffZRYcyCriM3777beP+v3CS4PfERZBWaQaPHiwLWSyYCDECU1ICCGEOA547LHHQvzf2kknnRRauXLlUe/Xrl3b3v/5558j9v/222+hPXv2hLf9+/eH39u8ebOdE2tr3bp16O+//w4fu3v37tApp5wSqly5cuivv/4K7x8+fLgdP2bMGHt95MiRUN68eUOXX3653dszc+ZMO65Xr172mnHwesiQIUk+92WXXRYqX758wvMU73nGjh1r7zdv3jx0/vnnh3766aeI8xo0aBD697//HTp06JC9/vPPP0O///57xDGM+bzzzgs1a9YsvI855fq9e/c+aiyMO9bYmzRpEipUqNBRn8O//vUvm+cgFStWDF1xxRWhw4cPh/fxudxwww2hSy+9NKH5aNu2bfj1J598Yvv4fPisPHfffXcoR44codtuuy3i/Ouvvz5irP6abCtWrAjv27JlSyhXrlz2PfTccccd9p3ZuHFjeN/27dtDZ5xxRqhcuXLhfXw2XK9s2bI270H4fvAecxSN/6yCVKlSJXTxxRdH7GP8XGP+/PnhfczzP//5z1DHjh3D+/huctzUqVOPuq7/XZgwYULoH//4R2jBggUR748cOdLOXbhwYSg9WLNmjV2vQ4cOCZ8T/T2MNT+LFy+248aPHx/ed9VVV4WqV68e97qJ/q7G+r5Hf/+C30H+BT7ziy66yD6n4H+fIPjfoFjP88Ybbxz12Sb1neEe/P55HnroITs2+HkeOHDAxvOf//wn/N86P+ZixYpF/Hdh2LBhtv/LL79Mcm6EON5RerkQQojjAh+xIaXbRxKDEJ0CosJBRo4caVEev5E2Gg0RO6JIbERPiRISkXzkkUfCx2DERso1keCgERFRYCKZPh2TCBlRMCKOwbrN6tWru6JFi4aPI8pKDShpm0RW0xPSXv3z+I0INRqA57v99tvtZ6KYfuN9IldE9+Ckk04K16gS3dy3b5/VWZNl4I9Jb4gmBiNy3BMjqvr161uk3Y+VdFrGu379+qNS9hOFyKPPTACizswJEd4g7P/xxx/t2YNQZ0yU2EM0lnmnxAFHbTaMtYjIkw7sIZKJoR+RYv+dDX6XmPdECZrj8dkxN+XLl7doKK+DkHpOFNvDPJN2zbEevhtXXXVVzOwBnxpN2QTRbb7Lwe8Pae4QLD9IC35uYqWVp2Z+SCHne0NKPJkmwe8wr4kW832Kd52M+l0Fsl8wh+S/LdH1337eo5/HZ7OQtQKp/Z2kVp7ofvC/i/w3lP8mkhngSzw8RNmDtev+OxX8HglxIqL0ciGEENkeRA81pIhtjJNIacSZPIj/45wUWWqQg0LOi/SOHTvGbDFELScp4x5SNH1PXUTYFVdcYfWhgFAJwh+giCr/frzjAKGC2AJSkjGJY0ykjPPHM+mliMG0tvcilTb4PB4WA6jZJSWVLRYc4yHN9Omnn7aaakSLh3TrjCD6uqREI4Rxm492nA+ON1jbnyjRKcv+O0N9cvR+Fh0QsaTeBr8zsQzsSNPFRR/4Odb3ANHKNfle+9Tu1Mwr5Qr8XuBnwL2CMN7g70GsFG1qh4MicuPGjfb7khQIU9Ke46UrB78/0fC7yeZhgSHedVjIAhZbUgsO4aSNU7bA4sz/As//I7goQScEFkz4/PhvBWUCpIX7MomM/F318w6xFhODsAhFeQu+FtHzHL3Ikij89yq6zMF/R/37wXFFf4/4DkFGLEYIkZ2Q6BZCCJHt8X2WqT0m+oyRD9HCYAQRQQuIcmqAPYgoL6T4AzG61jkeGATRqxtzLER3RkBki6gzdbBESBGWiASiu9SwpzcIPV/37p3go/FC47XXXrOaXyK1GDNh1oVIYnxeJCSHN5KKJl5v5ei2Zn681I8S2Y4FkcvUEC+iHG9/rOdIb1LS1o3PgO8o33ta6/EdZwGIyCW1vH7u0vu5uC6/D9wzFtGLFkEwyvPt5aBQoUJHmZoFP1fq1KkXTy3UXyO4+T0jM4FFCL6T1HgH54f6a+bz3XfftewEvAyYQ7JkqPPOjN/VWJDxQY06v494KhCR5jlYJIj+vDOKzPz9ECIrI9EthBAiWzNt2jQzcuKPYCK4RJ/5o5cUcES4h8gTJj84HQdFd2rx6cQ+ModAAMzTgmKflHNSQ31kOXicT7n1sM+/78GpmwgaG1FE/pgmuozojU4vTStEFckIQPTGioQHwUSJ55w6dWrEGIisBklqfCxyxEo79dkAyeHnmTTw5MZ7rImVioyBFeZcPnrLz7Fa1JE5QIlCUgI1ufnFNA23cH43gtHHtKR3811MrgUXx6xZs8YEf0q/m0SGg2nMSS0yMHf8/iBqyQhIZK5ifYdZXOL3KZiWHavbAKZ9pE6z8TuPEMdgzYvuRH5XUwvXBeY+3vecSDLGcixaBE39Yn0PU/K58N+jeN9R/74QInlU0y2EECLbQmopjrpEkoha+Zrufv36mbs49aUehDYuwaRNE7FKazTGu6FT4wr8MUwk8bnnnou4Do7epHZSsw3UPBMVJkoWbKHEAgFpuf440oERANF/fCOKg+fh1h1LJKQ2SkX6MLW7scSVT4v2x0LwWXEoJpU5iHeAjjVGnoc/3oPXRbCRFp0IzCNO09TX79ixI8nxHmuYh2AdLcKQ713lypVt7tj4mX3BaC5u0fR/R3z6FOqk8L26o+c31ufD95DIbmrhu8Hnw0JXNP4+RFtJ1X755ZdjpnPjup7UIgq/R35LbnGMBR7uS6p3MC3ds3LlSiuBiAdzFP07j0t9dKZFsOUWEEEm0u5/DxP9XU0tuMRTWsCCYvTn7Mcf6/MGzkn0OxMLWpThuB/8veYz5L+juLLjBSCESB5FuoUQQmRbqNvevn27RVuDaY1Eufljm5RPUit9PTcRJ16TEk27Jf6wJ9pKj12M0EgVZ380iCcfrULoE1FCmNJKB+EERC9pIUakiXvQUocIEa2iaA3mW5URlaX+k4gZpla03PItw/gjlh7IPipKtBARwx+2pNIidjiW9FcPZl20OaIvOUIAIRodQU8JZAMQDaWOE+Mu7k2tKHPAHPGzzxxg3jHVYqGAaD4LCRwfFEBEK9lH+yxqYokYUgPKRj08acikhtOqijpUrkEdc7SJWDzocYxAJaWZ8SLcmCNEAm2sEImZAc/HcwVbhkEwfZrPDBM7xo+xHp8xCwgINXwJEsGbtdEyju8F3y/SnPlesgjEzw888IB9Jghhvh+xFigSgbRlosP0bOaz4958H4im87mxAIUApmVbq1at7HuEcEbEsrjCfrJQWHhKD/j94/Nn7kij597U0vM7iqkZ42KO48F3mLZdpJXzHeU7w3c8WJsPvMfiDs/L9xczRObBl7Uk+ruaWsh64Hecz5LoOf/twHCPOcXgjTllgYboO98b/BXwMSAVnt/LRL8zXowHoWUe7cX47yLfZZ6f/7ZyXf4bGDSNFEIkQWbbpwshhBCpgXZMtAd78MEHY76/bNkya13Uvn37iP206Xr22Wet1RMtqHLmzBnKly9fqEaNGqGJEydGtGSK1TKM42m51KlTJ2udEw0twooWLRo6+eSTrX0WrcWi2/zAm2++GbrmmmusLdPZZ58duvfee0Nbt24Nv0/LLloJca3TTjvN2nWVLl06NHny5Ijr7Ny509oZ0WaK8SXXPixWi6Jodu3aZcdccMEF9hzMD625Ro0aFdGq6IknnrAWQzwDz0Lbs+h2X7Bo0aJQiRIlrD1WdNum1157zeaT966++urQnDlz4rYMi9eSiZZbjRs3tnEy3gIFCtjn+fbbbyf5nLHmw7c+euuttyKO8227li9fHrGfZ2E/rdGir8mz0bbMz49vARVk1apV1sbr9NNPD+XOnTt0yy232Hwlcm9Pv3797Jn5vgdbQU2fPj105ZVXWqsy2js9+eST1rouul0Ucx2rJVasFld79+613znux2dWsGBB+7yCLeZotca9aGfHs5911ln2+ffp0yf0yy+/hNIbWgTec889ofz589vnz/34vo4bNy6ifV/0d4/fy6ZNm4by5Mlj88/nsG7duqPaZvXv3z9UqlSp0Jlnnhk69dRT7XdywIAB4ZZyif6uprZlmOezzz4LVapUyX7XuQ+f7fPPPx9+n/9+0JKOcTKGevXqWQu6WC374n1nop/d/37deeeddl2+S8wFv+uxxhz9e+N/d31LQiFOVHLwP0mJciGEEEIIkTjUzJJtgdGeEEIIoZwQIYQQQgghhBAig5DoFkIIIYQQQgghMgiJbiGEEEIIIYQQIoOQe7kQQgghRDoiuxwhhBBBFOkWQgghhBBCCCEyCIluIYQQQgghhBAig1B6uRDHOX///bfbvn27O+OMM6yNjRBCCCGEECJ9yokOHDjg8ufP7/7xj/jxbIluIY5zENwXXHBBZg9DCCGEEEKI45Iff/zRFSxYMO77Et1CHOcQ4fb/MfjXv/6V2cMRQgghhBDiuOD//u//LLjl/96Oh0S3EMc5PqUcwS3RLYQQQgghRPqSXAmnjNSEEEIIIYQQQogMQqJbCCGEEEIIIYTIICS6hRBCCCGEEEKIDEKiWwghhBBCCCGEyCAkuoUQQgghhBBCiAxColsIIYQQQgghhMggJLqFEEIIIYQQQogMQqJbCCGEEEIIIYTIICS6hRBCCCGEEEKIDEKiWwghhBBCCCGEyCAkuoUQQgghhBBCiAxColsIIYQQQgghhMggJLqFEEIIIYQQQogMQqJbCCGEEEIIIYTIICS6hRBCCCGEEEKIDEKiWwghhBBCCCGEyCAkuoUQQgghhBBCiAxColsIIYQQQgghhMggJLqFEEIIIYQQQogMQqJbpIqbb77ZPfTQQ8fV7D3++OPu6quvzuxhCCGEEEIIIY4jcmb2AIQQx4baT85xOXPl1nQLIYQQQohszZye1V12QpFuIYQQQgghhBAig5DoFmlm//79rnHjxu6ss85yuXPndrfddptbv359+P29e/e6u+++2xUoUMDev+KKK9wbb7xxVLp6+/btXefOnd3ZZ5/t8uXLZ+neifD999+7HDlyuM8//zy87+eff7Z9n376qb3mX15/9NFH7rrrrrNx3HDDDe7bb7+Ne92NGze6iy++2D344IMuFAq5V1991Z155pluzpw5rlixYu700093VatWdTt27Aif8/fff7u+ffu6ggULun/+85+Wrj579uzw+3feeaddz0OKPuNat26dvT5y5Ig77bTT3Ny5c9M8L0IIIYQQQojMR6JbpJn77rvPrVixwk2fPt0tXrzYBGq1atXcH3/8Ye8fPnzYlShRwr333nvuq6++ci1btnSNGjVyy5Yti7jOuHHjTHAuXbrUDR482MTrhx9+mK6fUPfu3d3TTz9t482ZM6dr1qxZzOO++OILV7ZsWXfPPfe44cOHmzCGQ4cOuaeeespNmDDBzZ8/3/3www/u0UcfDZ83bNgwuz7HcI0qVaq4mjVrhhchypcvH14IgHnz5rk8efKE9y1fvtzmjQWB1M7L77//7v7v//4vYhNCCCGEEEJkDhLdIk0gJhHbr7zyirvpppvcVVdd5SZOnOi2bdvm3nnnHTuGCDfClKgvkeN27dpZhHjy5MkR17ryyitd79693aWXXmqRcyLSRKbTkwEDBpjwLV68uOvatatbtGiRLQoEYR8RZsbcv3//iPcQxCNHjrSxXXvttRa1Do4Rsd2lSxfXoEEDV6RIEffkk0/acz/77LP2Ptf95ptv3J49eyxDgJ87dOgQEZEvWbKkReJTOy8DBw50//73v8PbBRdckG7zJ4QQQgghhEgZEt0iTaxdu9YixqVLlw7vO+ecc0xw8h789ddfrl+/fpZWToo0admkaBMlDoK4DHL++ee73bt3p+snFLwH14fgPRhTpUqVXK9evVzHjh2POh8xfMkll8QcIxHl7du3uxtvvDHiHF77ubj88sttDohwL1iwwF1zzTWuRo0a9hr4F2Eeb8zR94zFY4895n755Zfw9uOPPyY4O0IIIYQQQoj0Ru7lIsMZMmSIpV0T7UV4kypNLTP1y0FOPvnkiNekdFMjnRz/+Mf/1o5Ia/f41PZogvfwKePBe5x77rkuf/78VnNO6vm//vWvZMcYvG9ycHy5cuUsok3NNwIbUU1KOKn3RNmD6eqpmReuyyaEEEIIIYTIfBTpFmkCQ7E///zT6o2DxmkYlJHCDQsXLnS1atVyDRs2tPRzUsy/++67dJt5hDIEDc2Cpmop4dRTT3UzZ850uXLlsnrsAwcOJHwuAh3BzvMG4bWfi2BdNxuim0UDhDiLE4jv6Ei5EEIIIYQQIvuiSLdIE9QZI6hbtGjhXnrpJXfGGWdYrTR13Oz3x7z99tsWxcXhfOjQoW7Xrl0RQjQtIJTLlCnjBg0a5C666CJLve7Ro0eqr0ckHtM3XNjZcB8nJT4IDuLUrHsncczkcEzv1KmT1V+Tgk4t99ixY20BgDp3D0L74Ycftgg5dd1+HxFu6rm5f0YwrUuVoyL3QgghhBBCiIxFolukGYQlZmDUJpMyTtR21qxZ4bRoBPCmTZsscoz7d8WKFd0dd9xh9cbpAS3DlixZYmnauKRTT47Ld+XKlVN9TUT2+++/b2OuXr26PU8i0N6L56IeHPHPwgJGcyw8eEixp/UYgpsFAy+6qX2PrudOT2o/OcflzPX/DNqEEEIIcXwwp2f1zB6CECIJcoRSUpAqRBr5z3/+Y/XcbOkFopsI9+rVqy26fCzwkW6fxu4j3d6xPRGozZ42bZotQKQGFjhOOeWUZI/D4A0X8wrdJkt0CyGEEMchEt1CZA7+72yCbklllKqmW0SAQRdR4v/+979mxnXhhRdamy348ssvXYUKFSw6i0M5/bZ//fXX8LkITwQkbbNw2OaYtm3bhk3NiOJu2bLFUqsRnN7IjBrwu+++21LScQcnEoyRWaLjQnADTuBcM9Fo8ZgxY9xll11m12O8tP/yIKDvv/9+qxfnF4jnXrNmTYoWF3ybMA8LAj4dPRa0GitcuLDNAXXvPXv2jDCE41yuQXs2npm6cyGEEEIIIUTWRunl4qh2Uy+//LJ75plnXNmyZc2cbN26de7gwYOWan399de75cuXW+o0ohSh+uqrr4bP/+STT0zA8u+GDRvcXXfdZUKRmu+pU6eakRpindce+mSTFo7oROBST92oUSOriy5VqpTVQzdt2tQEKJHdk046yfpc9+3b173++utu2bJldtzcuXNNRCcS/R0xYoR75JFHrA6cum1Wp4IGaPXq1bPFBVLMWb2iXp20eAzgaPmVEVAPz1xixsYCB3PEvs6dO4ePYU6nTJlic8k8xAIzNrbgCpwQQgghhBAic5DoFmFw6qa11/Dhw12TJk1sH8IX8Y0QRxyPHz8+bPTFcbfffrt78skn3XnnnWf7MEpjP4KwaNGiVg/90UcfmYBErLIfIZkvX77wfYlwB9tktWvXzvp4T5482cT0LbfcYhFsItv169eP+MSoG/cVEkTWg9dNiv79+1vdNbXoHkzM4LPPPjMhz8KCb71F9J7UcQzhWDTICILmb0TKmZNJkyZFiG5SyvkMvGN7LAYOHOj69OmTIWMUQgghhBBCpAyJbhFm7dq1FiElohvrPaLUQWdtWluR9k17MC+6iTQHI7BEvYnaJgUGYk888YSJ7G3btpmwZBykWcPWrVttHynoPpU8uqY7JSCmt2/fHvM5gTRy0uYR8UF+++03t3HjRpdRvPnmm+65556ze3B/WrFF14YUKlQoScHtsxWI4gcj3RdccEGGjVsIIYQQQggRH4luEcY7aacF71juIUKNME8K+lMTYacGmnpuhD1Gawjt9BpXkOSuh+BlsYA+2tHgOp4I9N6O9igM1mdHs3jxYnfvvfdahJo0flLaiXI//fTTEccl0k6M6LyP0AshhBBCCCEyFxmpiTC0tUKQkg4eTbFixSwCTG23hxpoxCUtuhKFemsi20G4Dj29GzZsaNF0TMSonU5kXP6aEH3deJDeTvp2vOtde+21bufOnS5nzpxm3Bbc8uTJk9A9iEZTDx+MNm/evDnu8fQwJ4rdvXt3d91119kzYzonhBBCCCGEyN4o0i3C4IaNmRk1xAhZ0scxLPv6668tCtu7d2+r9cZFm/3UXmN45lPLEwGxO3/+fNegQQOLxiJiEZjUSiM8qQkfOnSo27Vrl/W4Tm5czZs3d3nz5jVRPnv2bFewYEE7nkhxUvAMrVq1snMxUqOeHfHPM916661mGIcTO47pOIqTjo7BW+3atU0UB69DrXd0qzLczjFFo+ad6HivXr1iGp+RTs5xzZo1cz/88INFt6kt5160E0vPVmPTulRJspWBEEIIIYQQIv2R6BYR0KaKCC8iEaFJmjXilPpqzM0wHkMU8rpu3bomkFMCjuMPPPCAGbRRt00KNgZimzZtsrRqrotRGYISR/HkxmVf4pw5Tbxybd6/6aabYqaGB2HxAGM4XNoxLEP833nnnWFRO2vWLIs645qOwMeg7ccff7Sa8qDoTqqumsh2jRo1bAGgX79+MSPdLBpgNocwp5UabvDMC/t45qRajAkhhBBCCCGyPjlC0YWnQoiEI8w+0v35558fs1lLaaSb1HaEf4Vuk13OXP8zpxNCCCGOJ+b0rJ7ZQxBCnID83///dzbBwqQySlXTLbIdN998s6WBY7ZGOjrp7bQ0o96cyDQ129Rf02PbM2/ePGs/Rko7UfKuXbuaO3jwmu3bt7cUdlqbEdkORplJiwfSyxG9/rVnwoQJto9fOlLnSVdPhPvuuy9CPHMNDOWCkLquiLcQQgghhBDZE4lukS0ZN26cpYTTTxsB3rp1a1evXj13ww03uFWrVpkJWbVq1cztm5R1RPXq1autrprjR48ebb26o6/J8UuXLrVabtLVP/zwQ3tv+fLl9u/YsWPNIM2/Blp8Ee2eOXOmbQj8QYMGucyC9HRW3YKbEEIIIYQQInOQ6BbZElzOqQXHhI36aczTEOEtWrSwfZi1ASZlRJNxRP/mm2/cF198YbXTtOaiHVewndmVV15pZnGc37hxY6vd9g7nvjc2tddEwYO9srkG97n88sutnhxzuXjO6MeCgQMHWsTdb+rRLYQQQgghROYh0S2yJQhkD9Hrc845x3p8e8qUKWP/kk5O+69y5cqZmCbtHKdzHNDpx71169aY1wTS0Hfv3p3sWEgJJ6U9pedlFCxCUFfiNwzghBBCCCGEEJmD3MtFtuTkk0+OeE2ddXAfryEYyU7NNRM5P7XnxYK+59Hehn/88UeKrsFCA5sQQgghhBAi81GkWxz3FCtWzC1evDhCzNKTm+g0fb0TBXH9119/uYyEtHVqxj3UY8dqNSaEEEIIIYTIHijSLY572rRpY47gGKjRB/vbb7+12u1HHnnEIsvw/fffu6+//voo5/DoNHJqtUlNJ5KMc3p6U6FCBasPv/32261+nL7jpM+nB9O6VEmylYEQQgghhBAi/VGkWxz3FChQwM2aNcuczjFgo0UXhmcYsaUEjNdwM8eY7Jprrsmweuzy5cu7GjVquOrVq9tYL7nkkgy5lxBCCCGEECLjyRGKLiAV4jiHmutp06ZF9MemDzZtvz7//PNjOpa7777bItmvvfZaht2DFHVczCt0m+xy5sqdYfcRQojjgTk9q2f2EIQQQmQT/N/ZmBcnlVGqSLfINOidTcr3Qw89ZKna5513nnv55ZfdwYMHXdOmTa3mGrfx999/P3wOPbBLlSpl6d24hHft2tX9+eefEdds376969y5szv77LOtvReCOpgiDrVr1zbx7V97JkyYYPv45WnQoIE7cOBAhjwLY/7yyy/djBkzLAqPo3qRIkXcsGHDwtek7Rl15LivB+EeROqFEEIIIYQQWR+JbpGpjBs3zvprk/qNaG3durWrV6+eu+GGG9yqVatc5cqVre/1oUOH3LZt21y1atVcyZIl3Zo1a9yIESPc6NGjXf/+/Y+65mmnneaWLl3qBg8e7Pr27Wtp4bB8+XL7d+zYsWZY5l/Dxo0bLdo9c+ZM2xD4gwYNStOzIN5ff/11M2DbsmWLjZ+xUa9NizIWDt5++23rIU79drdu3dzkyZPterQ5o784CwFBJ/OJEye6Zs2apXnuhRBCCCGEEBmP0stFpkF0GDG6YMECe83PiNQ6deq48ePH2z6ivAhT3MeJCk+ZMsWtXbs23BLsxRdfdF26dLGUDkzRoq8JRMYxKPMCOl56+ZAhQ+x+vuc20XKizUuWLEn1s1SqVMmuC3v27LHFBEQ1NeFE1HPmjPQyxOiNMSDEgUUDjNUQ5TB16lTXpEkTOwbxHovff//dtmDaC3XoSi8XQojkUXq5EEKIRFF6ucgWEO31UNt8zjnnuCuuuCK8jzRt2L17t4nt66+/Piy4ASfxX3/91W3dujXmNQHRzvnJgQj2gjsl5yX1LIhs0srZypQpY++RGs9rBPcLL7zgSpQoYa3CTj/9dDdq1Cj3ww8/hK9z3333uQ0bNoSFPwK8fv36cQU3DBw40AS/3xDcQgghhBBCiMxB6eUiU6FmOQiCOrjPC+y///47TddM5PzUnpfaZ5k0aZJ79NFHXfPmzd0HH3xgJm7Ufx85ciR8Tt68ea19GOnwu3btsprw5FLLcUAn8u+3H3/8MeFnEEIIIYQQQqQv6tMtsg3FihWz9HIM972AXbhwoUWnCxYsmPB1EMKkf2c2jJ1IOH3Eg3Xl0dx///3mcs4z0j6M6H5SEElnE0IIIYQQQmQ+Et0i24A4ffbZZ82kjNrnb7/91vXu3ds98sgjVs/t8fXQHBsvjfyjjz4y8Yo4xW08M7j00kutdn3OnDnuoosuMsM0jN34OUiVKlWsBQGGcZjCpZZpXf53HSGEEEIIIcSxQ+nlIttQoEABa6+FO/hVV13lWrVqZanZPXr0SNF1nn76aXMzp9YZQ7PM4oEHHjDTuLvuusuVLl3a7d27NyLq7WFBgdpuovONGzfOlLEKIYQQQgghUofcy8VxB07iV199ddxId3aExQXcz6dPn55qV0W5lwtx4iAHbiGEECLjkXu5EM65/fv3W3SYFPLcuXO72267za1fvz48N0SXqZcmis77OKe/8cYbR4n49u3bWwuxs88+2+XLl89ajCUCpmc1atSI2EevbQzS6DHujdVwHCet/NRTT7Uovk+RxwgN8zRcy2lfxvukpWOsJoQQQgghhMj6KL1cHNeQlr1ixQqLENPrGxO2atWqmfCFw4cPW8uu9957z3311VeuZcuWrlGjRpbC7qHn9fPPP2+Rc45HyPfp08cEMG2+gi2+YpmgzZ492+3YsSO8b+bMme7QoUOWVg4Ibmq7R44c6b7++mv38MMPu4YNG7p58+a5WrVqmXs57cfmzp1rbdNGjBjh8uTJk6HzJoQQQgghhEgflF4ujtv08rZt27rChQuHXcJ9ZJta7nHjxrl69erFPJ/IdNGiRd1TTz1lr8uXL28iORgBr1u3rvXd7tSpkxmz0XM7Hpdddplr0qSJRcqhZs2aJqKJViPoiZ4jqOlBHhTr3PP111+34xHZY8aMSej5uSZbMO2FZ1Z6uRAnDkovF0IIIbJOerncy8VxC1FhxDAmZR7EbpEiRew9wJzsiSeecJMnT3bbtm2zHtkIVlLNPbQnK1WqlPvvf/8b3ofQJloe3BcPBPSoUaNMdPte2x9//LG9t2HDBhPXlSpVijiHcXiTt9atW5vIX7VqlatcubK74447wosIsSByTiReCCGEEEIIkflIdIsTmiFDhrhhw4ZZ6jj13Keddpp76KGHTPRG9/YOghCnFjsRqCnv2rWrpbcvWrTIardvuukme+/XX3+1f0lvp648iO+1TR36li1bzLkd1/WKFStaFN9H4qN57LHHrI1adKRbCCGEEEIIceyR6BbHLcWKFXN//vmnW7p0aUR6Of29ixcvbq9JPadumhpqQEh/99134ffTA6LrRKdJJ0d4N23aNPwe90FcUxdOGns8zj33XEtRZ0Owk9YeT3RzPS/YhRBCCCGEEJmLRLc4bsHlG0HdokUL99JLL7kzzjjDIs5ElNnvj8EpnAg0DudDhw61FPD0FN0+xZxacdLZEc4exvToo4+aeRqCv2zZslYTwmIAdSEc26tXLzN7ozac1HeM2FhQSCnTulRJstZECCGEEEIIkf7IvVwc1xBdRrAieDEqw72cNG2fLt6jRw937bXXuipVqpgBG+3AiErHgjZhGLSlhltvvdWdf/75dp/8+fNHvNevXz/Xs2dPq8VGTFetWtXSzUlDh1NOOcVSxq+88kpXrlw5d9JJJ7lJkyalahxCCCGEEEKIY4vcy4WI9YuRI4ebNm1ahABHdL/zzjvu888/T/GcUbtNhJ1FgDp16qS6/dnPP/9sY0iNq6Lcy4U4cZB7uRBCCJHxyL1ciCwAKeM//fSTe/rpp92ZZ55p7b+EEEIIIYQQJw5KLxdZGlK+27VrZ47i1Fyfd9557uWXX3YHDx40QzJqomnbRRsuz7x586zFF2ZipHRTx42hWvCa7du3txZe9MgmpZwodrAdGNSuXdsi3v61Z8KECbaP6DEp6zien3766Udt1GBjkMaY6bc9cuRIcxXPmzevy5Url9VvL1++POLaX3/9taXCU3vNs2GatnHjRhsfvcXfffddGxPbp59+moEzL4QQQgghhEgPJLpFlgexmSdPHrds2TIT4PStrlevnjmS+97VjRo1sn7X9NquVq2aK1mypFuzZo0bMWKEGz16tOvfv/9R10Qs42w+ePBg17dvX2vHBV4Ikwq+Y8eOCGGMACa9GzMzts2bN5vZGSnn0Ru144hz6sh//PFHN3v2bDdlyhS7N+NmsYAa73379tm1GTs12ywW0Md75cqVrlmzZrZggNla/fr1rd6bMbHF69WN2RqpLsFNCCGEEEIIkTmopltkaYhK4/i9YMECe83PRJipix4/frzt27lzp0W0acc1Y8YME7Zr1661aDC8+OKLrkuXLuYK/o9//OOoawKR8QoVKrhBgwYlWdNNX2/uRxQaiJbPnz/fLVmyJMnnIDJPpP7VV19199xzj+37448/TJQTxacFWLdu3cwgjZZm0X3BU1LTzTj79Olz1H7VdAtx4qCabiGEECLr1HQr0i2yPLh2e3Dupu/1FVdcEd5H+jbs3r3bxDYp315ww4033mhGZlu3bo15TUC0c35yIJK94E7JeUTIEdmMxYOwRuwzZiA6Tjp5LMGdEnA65xffb0TZhRBCCCGEEJmD+nSLLE+0CEVQB/d5gY1pWVqumcj5qT0vEU499dR0uQ7p6WxCCCGEEEKIzEeRbnFcQZ9r0sypo/YsXLjQotMFCxZM+DqIa1LQ04tLLrnE+m0zFg+Rb+rFixcvHo6+k/LO/lhwfnqOSQghhBBCCJHxKNItjivatGnjnn32WTNce/DBB60+unfv3uYaTj13oiDSH3jgAUsHJ2pMPXZawLQNAzhqt3FMv/DCC83ADfO35s2b2zGM9/nnn3cNGjSwFHHqQ6gVJwW9SJEilto+Z84ceyZS7Hk/Jano07pUSbLWRAghhBBCCJH+KNItjisKFChgruE4nV911VWuVatWJmp79OgR9xxSxHEDD4Ij+oEDB9wFF1zgrrnmmnQZGyZtdevWNaf1a6+91m3YsMFEtBf0CGlcy6k/L1++vCtRooS1R/PCukWLFia+r7vuOnfuuedGRM2FEEIIIYQQWRO5l4sTnnhO5biEY252vLgqyr1ciGOH3MOFEEKI45//k3u5yG7Qyou0cFpoEf3FlZxIL+22mjZtainf9LZ+//33w+fMmzfP0q9JAcdJvGvXrtbXOnjN9u3bW2sv0rrz5ctngtpDyjbUrl3bxLd/7ZkwYYLtQ7SS9k30OxHoyV22bFl35plnWgS7Ro0a5mDu+fTTT+1+tADzIPDZ9/3334f38fxE23Pnzm1jHDp0qF1TCCGEEEIIkT1QernIUowbN87lyZPH0sMR4NRB16tXz91www1u1apVlvZNeja10Nu2bXPVqlVzJUuWdGvWrHEjRoxwo0ePdv379z/qmtRUL1261Oqo+/bt6z788EN7DyMzGDt2rKWY+9eASCbaPXPmTNsQ+L6PdzQ//PCDO/3008MbUfMVK1a4I0eO2Fh///13E80pcTonfZz0+A4dOpggr1SpkhswYECy53EvVt2CmxBCCCGEECJzkJGayFJQh+3rrzETQ+Qiwqlnhl69epm4/uKLL9yMGTMsCjx8+HCLEBctWtRt377ddenSxY7zxmm4gmOmBpdeeqkd/9FHH5mIpTYaiB4TBQ+CQH711VfDfbkR+5wXS/jmz58/yVR0hDiR+G+++cZdfvnlCc0Fpmq33Xabe/TRR+114cKF3aJFi2wBICkGDhzo+vTpk9A9hBBCCCGEEBmLIt0iS4FA9px00kmWmn3FFVeE95FyDrt373Zr1651119/fbhPN+A2jhHZ1q1bY14TEL+cnxyklXvBndx5OXPmtNR3v9GyrGfPnhaZxzSNfT4inii4lJM6HyT6dSxYrPjll1/C248//pjwPYUQQgghhBDpiyLdIksR3QILQR3c5wV2StK0Y10zkfNTex7cfvvtrlChQlaTTRSc84hwk24OPgof7Ccerz93SqG+nU0IIYQQQgiR+SjSLbItxYoVc4sXL44QrtRBE50uWLBgwtdBXP/111/pNq69e/dalJo0+YoVK9o49+/fH3GMT2sPtiqLTk+nPViwxhyiXwshhBBCCCGyNop0i2S57777zGUbU7HkwJX7lltuMZGZGpdtap45L+jqHY82bdq4Z5991gzXHnzwQRO61G4/8sgj4UhyIpBGTq02qelEiH3f7NTC+aTFjxo1ylLSSSnHVT0I6ebUo+OkTo34d999555++ml7r2XLlu6DDz6w5ypXrpw5lhM5p4c3zu2kz+PwzrOnhGldqrh//etfaXo2IYQQQgghRMpQpFsky7Bhw8xQLKtRoEABN2vWLHM6x4ANp+/mzZuHjdgSBbGLmzki+JprrknzuBD8kyZNcitXrrSU8ocfftgNGTLkqOj6G2+84datW2c1508++WTYdf2pp56yf1kEGDlypIluno82ZFwrJQsKQgghhBBCiMwlRyiYmytEGklrpBtxTxQ3kUj3iQgu7pMnT7a+5YlGumkZRp/xCt0mu5y5cmf4GIXIKszpWT2zhyCEEEKI4xj/dzbmxUlllCpkJhJKL6fvtO8B3b59e5c3b16XK1cuV7Zs2Zh1xtRWE8HlmDJlyrivvvoqRTM9Z84cq4Wm1VbVqlUjap8xJaPXNnXbpINfffXVFgUOCn9Mz4LCnXpp9n3//ff2esuWLZayTSo4Pbwvu+wyi5p7GC/turg/jum0C/vpp5/C7998882W/s0CAdfgGEzTDh48aIKYunJSyEkH91A3TiT+oosucqeeeqrVbJNFEG+u4YknnrBxMkZ+oceMGXNUazMhhBBCCCFE1kWiW6SIzp07uylTprhx48a5VatWmbCsUqWK27dvX8RxnTp1srRtBDmmYQjHRN25Dx06ZCnWEyZMcPPnz7eaaN+rGhCqXJtj6NfN/WvWrOnWr1+f8HO0bdvWFhC4/pdffmnp3QhsQKxXqFDBUs1XrFhhgn7Xrl2ufv369j7jWbBggfX7fvHFF+06RPapxUYY0y+cuaFdGGKd5/GLBSwUvPXWW1a7Ti/xbt26WeQ6HohsFgOYO/qVszgQXICIBeNh1S24CSGEEEIIITIHiW6RMERxR4wYYfXJRIGLFy9u0V2itqNHj444FkOzSpUqWY9tBDqiddq0aQndB4FJLfN1111nPa4xScPozIPY7tKli2vQoIFFixHMRLtTYiyGcKZmmvFdfPHFrkaNGmZaBohpBDdRZgQ0PyN+P/nkEzM8owUYY2NDPCP8Ee65c+e2xYWOHTu6Sy+91EQ1Tua87+u4+/TpY+cR7b733nstKh5PdGOYRo9t6sNpNbZx40aL4v/5559JPtvAgQNN/PuNWnUhhBBCCCFE5iD3cpEwiD4EMWLVg5AsVaqUW7t2bcSx119/ffjns88+28Rx9DHxQLxecskl4dc4gO/evdt+Jmq7ffv2iDEAr9esWZPws5Ai37p1a3MJv/XWW13dunUtHR64DgLbR76j56Bw4cK20EDUmUi/h0j0DTfc4HLm/N+vFSnn4McOL7zwggl4RP9vv/1mYpoFg1hwL94vXbr0UXOZFI899pg5uHuYMwlvIYQQQgghMgdFukWWAyEfhFrslPj9eXfv4DnRqe3333+/27Rpk6V/E6Um+vz888+HI8xErKkDD26kr/toeLxxBvfx2qeVAxFr0uSp60bsc00i3Qjr9IQ6d4wcgpsQQgghhBAic5DoFglD9PmUU04xk7SgmKVum1TzIEuWLAn/TL0zadkYo6UVBCTp3cExAK/9GKghh2DtMwI3GqK/tBmbOnWqpYSTKg+ktH/99dfWv5tIdnDD0Cy1MEYi4fQXJ2Wd6xHNTmq+EfFLly49ai6FEEIIIYQQ2QOll58ApLWNlwfBSUo2JmmkOV944YVu8ODBZhRG9DYI7uLnnHOOpVh3797dUq9x5UbI4vjNllq4PzXjiFJSs8eOHWuieuLEifY+YhZB/fjjj5tLOW7f3377bcQ1uD916aSKMy+kk/tFAUzWEOB33323GcfxrBs2bLBI9SuvvOJOOumk8HVwQ6c+e/Xq1cmOmzrv8ePHmzM752AUx4IFP8eC9HbmledlLnGMZy5T26d7WpcqinoLIYQQQghxjJHoFili0KBBli5NWvaBAwcsLRsRSdusINRJ495NfTPCeMaMGRYlR2SmJVrs67HphUd0mnppItzTp083UQtEh9944w1bIKD1FzXhOJ7Xq1cvon0X4nrr1q0mRGlL9swzz9h7PpKOWRvPgBt4oUKF7JhowYu4J6LOokJyPPDAAybO77rrLks9R9QT9cZIjQg4ae6YpOFwzr/MHaZ1Pt2dNmQ8M88uhBBCCCGEyB7kCKWkWFackJFuxCHR3ddeey3hc1599VWLJgd7ZWcG9NNOqbP5sQTTNozoiGDfc889btu2bZbyXr16dXNpTw8wUsPFvEK3yS5nrtzpck0hsgNzelbP7CEIIYQQ4jjG/51NUCwpHyXVdGdDiDTTFoq0ZFy0r7rqKvf222+H36evs3fYRmyTAh2EtOtox2xEKanfQUixJlWbtGoiybTu8gwdOtTabRG1JtpLxJaIrBf5GITx5SOiy8Y9gXsEBTAu3rVq1bJUar6o9MKmvVj0WEnF5ly+1LQKI8qeKESNGTvnEpHu2bNnhMka1yZiTySZVHTEb9BxnMUK2ntRK86cElEnpR2YW54vWDNOPTgtyHgernnTTTfFrd1+8803zTWd9mLMdfny5S1lH5dznpE2bVwn+PnCO++8Y3OfknkQQgghhBBCHHskurMhCG5qg+lljcB7+OGHXcOGDd28efOsr3OdOnXC7tu4dHft2jXF96Afd7t27UwU49hNj+1geyzSrJ977jm7P324P/74Y6t/BlKlEdaIRVKv2XDtBgQ1aduIbEQjCwczZ860dG+ELY7ipF8HQbAiMjmOjeckzT1RGB+p2suWLbM0cxYMqM0OmsH169fPos7cByF93333hd9HpNOP+/3337e2Z8xNvHRyItXMFw7izMnKlStds2bN4vbWJnU9V65cEfsQ9ocPH7ZzmSMWGbzI9/D6zjvvNFEvhBBCCCGEyLqopjubgUh74okn3Ny5c8O9sC+++GL32WefuZdeesmiwRiMPf300/YePZ2pFX7yySdTdJ/+/fubUOZfT8WKFcM/B43QuCfHkRb94osvWu02UWUiwESOgyBWGzdubJFwxsyiACZm1F1jWLZz507rf03td8mSJcORfdLVvcCknvyjjz5yAwYMSOhZiMRTr814/HzwukWLFvY+otjDXLKYwL2J3LM4wMIDbuNEw/3zxoMINc9OdoBvH0bWQTyqVKliCxTUoBPl5/kxoQu6rzNHLGTw2vcsJ5uB70C87whbMO1FCCGEEEIIkTko0p3NwEUbt/BKlSqZIPQbkW8iwkRiS5cuHXGOF+eJgqjbvn17hMiOBsHH+wUKFDAxjBDeu3evjS0pqA0nTZuoOWIQQUz6Na8R3ZiiUXfOc3gQucGIrheeiVKmTJlwz2w/H/TcJroORJTJDMCNnfuQ4g2IbcCQDRFNmjvR/EWLFsW9F9kFPE90D+94YNSGWRoLFkTHEejVqlWz97xpGzXfLEQQsQdq6zF2C/YMj86EQPj7jTkWQgghhBBCZA4S3dkMXzf93nvvmcDzG+nP0XW/8UDMRfvnkWIdTG9OCtKvqVmmFnnKlCkmWonwwpEjR1x6Ey1gEdBEv9MDaqaJNpMKT8sxIuyk0gefhdZitB4jjd8vRvh0+WiSm7tYPPLII2Y4h8j/6aefrMbdR909RLuJ9vvUcjIFggsJQR577DGrp/cbJQdCCCGEEEKIzEGiO5tBJJiIKAKN6HBwI6JJr2lql4MsWbIk4jWRZtKYg8I7aARGtJfoMincsUBkI3pJYSeKTHQWMRqEFHMfSY4HY0UQBkUhiwcIUJ4zvVi6dOlR84EZGlH3devWWYSeGnEi1EWLFo0ZRWfOmjRpYlFm0sFHjRoV814sRCxYsCBiESMRENC0KkO0k2rOZ3nttdeG36dmH+FP6jtzxFjiwfeDRYTgJoQQQgghhMgcVNOdzUAQE2Ul6orwLVu2rEUz6SuNuCJNGTHcqVMni44ikH2ENNhGa8+ePeaSjRnX7NmzzSQsKM5wDedaefPmtUgvLtncA3M1BD6i8vnnn7e0bPZj6hYE0U5UHuGOu3ru3Llti+7ljQM6BmoIWczGcEEnvdvXT6cHLFAQTaZP9qpVq2zcvuadlHIWCNjH89LXG1M14JkQ6DVr1nQlSpSwFG9qpTFzY8EgFrikcy3Mz4g4k97NNUgRp56cKDr7Efse0st9D/CpU6faAgC9u1kU8NAHHYM8PldS0unlnVKmdflfRF8IIYQQQghx7FCkOxuCKMRRm9pdxB+CjXRznMARkaR848KN2EU4YrwWhHMwPCMlnGOIjEenSxNJRQhzHGKTdHLqoIFzcADHnO3yyy+3tGzGEgTjL0QsTuREiRH4saK77777rglK6pMR4aRU00YrPcG47bfffjPh27ZtW9ehQwfXsmVLe4+xsSiB8EUUI3ij+2MjyhHKRLEZJ2KYGu9YnHPOOeZazoIDiweIdVqv+RR5Fki+/fbbiHNY8CDKzkIDnyNzcscddxx17ebNm1vKe9D4TQghhBBCCJG1yRGKLu4V4gSEBQCi0EGxS7SfxYtg6n1mQj9xX1fOQkCiYFhHxL1Ct8kuZ67IbAMhjmfm9Kye2UMQQgghxHGM/zubwFpSGaWKdIssBanvpLDTkowI+HnnnWeRYgzPMA8jvZ70dqLDHvp2E8Wmlhlnc/qSB/tic8327dub8zgO6bQxQ1B7fAuw2rVrm/iObgmG2GUfv1CkjZNqn+izJHVfn/qOcRoO9Pyi0jaMXubw3Xff2XhWr15tzvRE4UmRJ0OBtnBCCCGEEEKIrI9Et8hy0BqLft6kvSPAadlVr149S1mnJpuaZlqUkaZNnTjiFmFK2vf+/fst7Z39vuWXv+Zpp51mpmqkutML+8MPP7T3cCz3ruD0wvavAbFLtJs6bjYEPuI3Jc8S777U5CO49+3bZ9dl/6ZNmywlHzCoI+WcdHgM3hDtpLmTzn/PPfek23wLIYQQQgghMg6JbpHloGa8R48e5jCOyMyVK5eJ8BYtWti+Xr16meM4ZnD33Xef1YHj6P3FF1+YERrRZNKvEake6rF79+5t51PjjZj17uzUdQP9wTnHv/bCmJpvatepu0bsx3N1j0VS9+XfL7/80r3++utW+01/dfqtI8C98MdkjnRyjOs4np8xx2N/PDB7I9UluAkhhBBCCCEyB4lukeVAqHqIXmNOhsu5h5RzIEJM6zPMzRC1vnUaddmko/NerGsCaeixWoNFQ1o5Ke0pPS+R+65du9Zag7F5aJWG+Oc9IJ2dvui+7RtRblqJEfmOB6Z2pML7LXh9IYQQQgghxLFFoltkObzTt4e65uA+XvsodFqumcj5qT0vvc4n8l6hQgWLhgP/JhXlBrIDMHPwW7APuhBCCCGEEOLYItEtsjW0P1u8eLELmvDTN5zodEp6WSOO//rrL3esx44gDopi0uR//vlni3h7ENm0UeM5qfkm+p0UGMphyhbchBBCCCGEEJlDzky6rxDpQps2bayfOIZrDz74oJmrUUP9yCOPuH/8I/E1JdLIqZm+8cYbTbTinJ7R0JectHlENc+A4zrPQ39var89derUMTM5tltuucXlz58/Vfeb1qWKBLgQQgghhBDHGEW6RbamQIECbtasWeZ0jgFbq1atXPPmzc2IzbNu3To3Y8aMJK/z9NNPm3s49c/XXHNNsvfFXI3a67RAqvm7775rAp+6dEQ4pnBEtYMQtb/99tvdmjVrkk0tF0IIIYQQQmQtcoSCeblCxIkC0zebLb3AHOyiiy6yVl9XX311QufgVE7qNS28UkJqz0tOdDMfXDerg3s5hmoVuk12OXPlzuzhCJEwc3pW12wJIYQQIsv/nY2PUlIlnYp0CyGEEEIIIYQQGYRE93EAbtiDBw+2dlnUI1944YVuwIAB9h59oHG/PvXUU631VsuWLd2vv/4aEQWmxdZTTz1l7aw4pm3bttYXGm6++Wa3ZcsW9/DDD1s6tHcOp0/23XffbenduXPnttrkN954I+FxEeUGUrm5JvdJCnpvjxs3ztKx/Tg+/fRTew8jsvr161u699lnn+1q1aplkfSk5ou2WoyBeSEt/e233w6/z3W5/nvvvWctv+gTXqZMGesB7uH5WdHiPWrHOT5nzpw2F6effrr74Ycf7D59+/Y1Qzeen4j+7Nmzw9dgjJw3depUq9XmXMaCYVqQzz77zHqEM1bS39u3b28t0YQQQgghhBBZH4nu4wBaRA0aNMj17NnT3K9pK0Uva4RZlSpVrGZ4+fLl7q233nJz5841w7Egn3zyidu4caP9i7AldZoNEISIRsTjjh07bIPDhw+7EiVKmDBFjCLmGzVqZLXVyY0L/HGMh2tyn6R49NFHTVhXrVo1PI4bbrjBFgd4RuqeFyxYYM7liF6OO3LkSMxrIbjHjx/vRo4c6b7++mtbUGjYsKGbN29exHGdOnWyWm/m7txzz7W6ar8YgcDH8Zw5mDJliqWuk4ZPXfbnn39uZmfDhg2z81nQ+OKLL2ycNWvWdOvXr4+4T/fu3e35OK9w4cK2mIGpGvC58Cx169a1a1DvjQiP/gyD/P7775bqEtyEEEIIIYQQmYNqurM5Bw4cMEE4fPhwd//990e89/LLL7suXbpYJPi0006zfZiOIR63b99uAphIN5FdxN1JJ51kxyBuid5OmjQpRTXdNWrUcEWLFjWRmdS40rOm+7XXXnP9+/d3a9euDUfhEduIYo6rXLlyxHkIUqLhiP3rr78+fB3GeOjQIVsYYD6IPPP8d911l72/b98+W3xgMYL54d+mTZu6DRs2uEsuucSOefHFF21xYufOnfaaLACyBrp16xa+T6lSpVzJkiXdCy+8EJ6DV155xczfgMWJyy67zJ6HuWRcfC4vvfRS+BqIbhzOWVQh0h4rK6BPnz5H7VdNt8huqKZbCCGEEMdDTbdahmVzEGcIyYoVK8Z8j3RlL7iBllikPdNay0edEXlecANp5qSlJwU9rZ944gk3efJkt23bNhO6jIMU6eTGlZ7g6I3wJdIdhEg8CwnRcCziulKlShH7GX+0a3lQlCPUixQpYs/l4Vm94Pbztnv37vAvIAsbzHcQXjPmIKSwB68BXAfRzbFEuCdOnBg+Bu9DPsPNmzdbr+9oyDCgZZqHsZCWLoQQQgghhDj2SHRnc6jzTSukSQchYoyoS4ohQ4ZY+jT9pannRtgTCfcp3ekxrkSgPp0U76Ao9RBpj3U8kBZPJDoIdddpnbfUNAMIXsdH6/38M94HHnjA6rijoUY+FjxHSp9FCCGEEEIIkTFIdGdzLr30UhO4H3300VFp3ERBSYMmDdlHu6l5JnWcqG2inHLKKRbZDsJ1MCyjFtqLxO+++84VL1482XH5a0L0dVM6jmuvvdbqnPPmzZtkSoeH8SFIMTojRTsplixZEha2+/fvt+eLFVmOBWOhrpt5Ct6H16SYJwrPR8o5ZnRCCCGEEEKI7IdEdzaHml7qtjt37myilPTlPXv2mEHYvffe63r37u2aNGlidb7sb9eunRme+dTyRKCme/78+a5BgwYmWPPkyWOiGsfvRYsWmVHb0KFD3a5du8KiO6lxUb+MSEaU4+ZNrTTHUw+R3DjmzJljqfG4rHM8z0jUnQUA7xSO2zrGbNyb10FIQ8e0DPM0FgrKli1rNRiIYYQyc+XhetwHozQi6Tw3Tu+JghEb808KOnXrY8eONbO0WFH5eDCHOKdjnMbiBYsniPAPP/zQ6uVTwrQuVRJamBBCCCGEEEKkHxLdxwG4g9OuqlevXlZHTF1wq1atrOYYkdqhQwcz7+I1LtgI5JSA+CTFGfFInTYp1D169HCbNm0yR26ui3s5ghQBm9y4gP3PPfecXZv3aYnlW4DFo0WLFnbMddddZ2nXuK3TaowFAcRpnTp1zMCNtHFqyeMJzH79+lnqOS7mPAOma0SUMTwjvZv3Aed15o46bhYFZsyYEY7QJwIp4cxHx44drUabBYnp06fbgkWiUO+NqzoO58wRc8/n4A3ehBBCCCGEEFkbuZcLEfyF+P9FNwsGpJQjyMkSwPmcKHVWAfFNqj2LF4m6Ksq9XGQ35F4uhBBCiOPBvVx9ukWWhAg2qfCYs5G+Tjo8LdCoT6dVF2ni1Dm///774XOICFMvTQo8UfWuXbuG+137axJ9Ju0cN/J8+fKZoA6mrwOCO9pVHCZMmGDH8ItFqj1R9UQghZ40dgQ86eq0Vgs6q9M6DLFPizJ6jxNVv/zyyyP6hhPh5xieF+M4npHWYUIIIYQQQoisjUS3yDKcfvrp4W3BggVWs0zva1La6S3eunVrV69ePROmq1atsh7c1KfTAoy2ZdWqVbM0etpsjRgxwo0ePdp6eAcZN26c1UUvXbrUDR482NLbqY+G5cuX27+kqsPHH38cPg+RTLR75syZtiGIST9PBBYKaOG1YsUKM5bDyK527dpHOcRTA04qOr3LaVfGM+/duzfiGBYSuC8p79GLAh7mi1W34CaEEEIIIYTIHFTTLbIMwfRtDNIQpW+88Ya9JipNJBgzM2q7gVpwxDV9rKm3phc1Qp2IMD2uqSNHQHMcQhcQqpibAbXVHI8Qpm+3bzGGcVl06y/GghO87weO2Oe8AQMGJPtc1NEHGTNmjN0LQzQi2h7M0vyxPBcRchYOiMx7WCSI7jEeDbXqffr0SXZcQgghhBBCiIxHkW6RZSBd3G84m5Mq7l8T/SY1m57gHu/AjkkZkV+iw77PNeCYjuHa1q1bw/uio8OkoXN+cpBW7gV3Ss6D9evXu7vvvttdfPHFVuvh09hpWxaE8Xuo1cYwjucKwr7keOyxx6yuxG8//vhjQuMUQgghhBBCpD+KdIssy8knnxzxGkEd3OcFdnSadkqvmcj5qT0PSBMvVKiQ1aTTu5vziHAfOXLEpRTfbz0pqPdmE0IIIYQQQmQ+inSL44JixYq5xYsXR6SF03ub6HR0r+7kxDWu4OkFNdn0FafFGm3MGCeu6LFYsmRJ+GcM4FauXGnHCyGEEEIIIbIvinSLJMHx++qrr3bPPvtslpipRYsWuaefftqM04L9xtu0aWNjxPGc2miELrXbGJj5eu5EIPWbWm1S04kW45yeKLiQX3TRRWaExpwB55MWP2rUKEtJJ6UcM7RY0Ld84sSJlo6O8KcneLNmzY46DifzW265JdzSLFGmdamSZCsDIYQQQgghRPqjSLfINpCWPXXqVDNHQ3S3bNky/F6BAgXcrFmz3LJly9xVV13lWrVq5Zo3b24R5pSAoMfNHFO2a665Js1jRvBjAEfUmpTyhx9+2A0ZMiTmsddee60JbqLciP/p06ebcVw0uLfv2LHDWpcJIYQQQgghsjY5QtE2zUJk0Uj3V199ZUZqmzZtsohyViNWpDsl55F+zuIBbc3i8ccffxxVX54ctAxDoFfoNtnlzJU7RecKkZnM6VldH4AQQgghsiz+72zMi5PKKFWkW0T0k27cuLE5hZMKTdQ3yIQJE8w9mzppWnjdc889YQdv1m5wGX/qqaeOagOG6diGDRuSnWlSr2vVqmX350tbv359t2vXLnuPdl3euRwXcK6JWI0HX/yTTjrJemP7KPnZZ59t7cA8r732mkW0Pbh8c09StjmWsUTf45VXXrE661y5cllbMvqIx4MUcdLDOS7aqTwWpLWPHz/enu2+++6zffxM+7CaNWuaiRotykgvZ//PP/+c7DWFEEIIIYQQmYtEtwjTqVMnN2/ePPfuu++6Dz74wMTdqlWrIqKs/fr1c2vWrHHvvPOOCdKgOERgjh07NmJGeV2uXDkT5EmBKEbk7tu3z8ZAijcR7bvuusve59+5c+faz6SQk14dFMzRsOJEtJlngC+//NLGSBSaNmLAfcqXLx9+tipVqtiCwoIFC8yEDfFftWrVsMs49db0/Eb40srriSeecN27d7fab44tXrx4uPUXApn9jJXrXXjhhcl+00gbR/TzbMOGDQvvf/zxx13t2rXtGWLVeEfz+++/26pbcBNCCCGEEEJkDhLdwkCIjh492iLVpDkTVSbNmfpiD4Lvtttus0gzEWOMv95///2wiEWAY2CG0PRC9vXXX09IKBLlRVRyfIkSJVzp0qUt6oswXr58ufXtxpAMzj33XIu0E8lOLjXei27+rVSpkkWpP/vss/A+L7rffPNNE/5Esnl2jmPBgAi1vwbGbET/69SpY+ng/EuN9mWXXWYRfWrKgfMQ/NSEM37GmxTUb5MpwHE8J88WrNcmo6Bp06Y274mI94EDB9r5fktqcUIIIYQQQgiRsUh0C2Pjxo0W0UXsekixLlKkSPg1ZmD0nEb4ERH2gtWnTtODunr16m7MmDH2esaMGRZ1rVevXrKzTOQYcRgUiESOSfXmvdTA+BDYpHkjfhHhXohv377dUt55DUTvec1zEbVm4/kPHz5sc0PqPf9izubfZyPajakbkXzEs88YQMDPnz8/vFCQFkjpTwmPPfaYpdf7jbR5IYQQQgghROaglmEiIRCdpF+zkWZNVBaxzWuffg3333+/a9SokXvmmWcs4ktaeO7cmWPeRVr7gQMHLEUeAYxAJoo8aNAgczhnkeDSSy+1Y4nWE2Hn2aLhWX00/+WXX45YmIDoiHu1atWsXpy+4RUqVEjzc5CqnhJIa2cTQgghhBBCZD4S3cK45JJLzBV76dKl4RRm+kB/9913FjFet26d27t3rwlWH432JmXRghORiPnX7NmzTewmAuncRGTZ/PW/+eYbMwvztdIphSj5lVde6YYPH27PhqFZ3rx5bSFg5syZ4Ui9b9dFijnvx3IeJE0bkU6d+b333pvkfVu3bm3twTA/e++99yLuI4QQQgghhDixkOgWBqnSpE6TGk1KNOITkzD6TANC/JRTTnHPP/+89cCmfRematEQ9aW2mxRnosiYiiXCrbfearXUCFrak1FL3qZNGxOsKU2vDkL6OGO+88477TUp4wh8BPYLL7wQPo770j8bM7e+ffu6ggULui1btlhf8Jw5c7qPP/7Y9enTx7Vv394EOAZrpM6z8MDixCOPPBJx33bt2llae40aNazuvWzZspn+TZvWpUqSrQyEEEIIIYQQ6Y9qurMZCNo77rgjQ66N6LzpppusbhsRjFAk5dqnWNO266233rLIMxHv6PZgHsQ7KeeYfyUKzuK4pp911lmWFs79MQ5DHKcFRDvi19duAz9H7yMFnqg8iwsYpCHMeQ5quh999FEzeiN1HqM10uZZIODazEl0z3DvuP7QQw+ZUCf6v2jRojQ9hx831xRCCCGEEEJkH3KEsE0W2Up0k3JNy66sCi2ycEAnVfy8885zJxK09+Kzwc08vUF044pOJkBKoGUY0fkK3Sa7nLkyp75eiNQwp2d1TZwQQgghsiz+72zMi5PKKFWkO51F0YMPPmgbk58nTx7Xs2dPawcFpCE3btzYorlEVmm/tX79+gjBhqgKgsDyrti8TxsvIsJEhtl8O6utW7e6u+++29KnqakmJZv6bA811tRtkyKOI/mECRMi7sO1XnrpJUuHZmxEejEC8w7fXJM+0jh4B2Es1EPnypXLIr4dO3a0XtY4licnuLknkWN6UHNP0tGnT58ecQyu46VKlTJjsPPPP9917do1oo0ZYyPlu3PnzvbsGKUxT0FYpCBKTbSeXwbMzXArhz179tg5mKx5iEozT0S3Y30uzDljYk6oG7/xxhstFZ2oN5Ftru0/H/YlN4bgPfhc+Lz5/jRo0MCM4PxiC3NB/25/bfqkCyGEEEIIIbI2Et3pDKKYGmB6VSOQhg4dasLSCydqgBGWCFrEOKnH9LNOBNKc69evb/XEO3bssA0hjLM2qc60ruLaiDlEKG2rYNq0aa5Dhw4miKnFfuCBByz1+5NPPom4PjXaLAoQpcV0jP7QHEt9NuNmvCwoBCPaHM+1MT2jbprnpVf34MGDI66NK3iw1RYbtGzZ0vpwf/HFFzYX1Fbv27fP3uN52FeyZEl7JhYO6CXev39/e5/+2IyBmm0WJ0gFZ2ED4Ys497AAsHv3bqutpu0ZiwRE4rkPIpgWZ4henhGRi/s6z8kx0SD4Se9nvhkznyPPgAgmrZw5Zlz+8/Gp5qTtI8D5rLgG40ZkI9w5HljQIEqOyRsbIps0fuC7RH18ixYtwtdW/20hhBBCCCGyPjJSS2cQQrTLQoQRUf7yyy/tNRFZBPHChQtNKHshyvEIrUR6WSNUTz31VDPwIjrrQcwRsUW8Eu0F+kZ7qL1G8GNMBph+LVmyxPbfcsst4eMQ4oh66NKli4k8IvW0BQPEdbBO24vbJk2ahGvCacWF4C9QoEDE2HHyjm61RWQbp2+OL1SokEWbn3vuOVuwYGHhxRdftPnBfZz5ZCGA/tqMjWj6rFmzbLwsLrzxxhvh69atWzfcxow+3VwP0e3baPHczPnbb79tghlhj5hF8JMhgBAeOHBg3BQS0kfICCBzAMgKCH5GLLoEPx/GQHs1Fg6CrbwQ9dwXkU+dOM/BZ0mvcGA/0fYBAwZY5JvoOxkBwWvHgu8HW3DMQgghhBBCiMxBojudKVOmjAlED8L16aeftkgwYiwoPHEJR5ivXbs2TfckMn3NNdeEBXc0XB9xGYSUaKKnQWiv5fGp4RiGBfcRTUbEkSKNiGQRAVHowaCMYw4dOhTRnxsh6cVkEBYjENyA2OW6CGQ/buYvOJ+Mm2gx6fScxyIEkeLgIgPp2aRzA2PkeOY6yG+//RaRKo8Qp80XRnFEw+P1uWaOWcBgIaJSpUpm+IbwJ/U9Hn4M0YsOjIHIun9+xh2cI67p5yIlsGDAgogQQgghhBAi85HozkLQniva1y6R1HOEZ3pAL2uPF7qx9vm0dYQk4g6372io8U7pPf09/PVTM+7oazBGxKuvfQ9CPbYHAU4UnfOolQ4uNkRDVJo6cvqQ467eo0cP9+GHH9qCSywSHUN6zAVQDhBsYcYiiVLRhRBCCCGEyBwkutOZoHkZkMZNGjVttqjl5X2fXr53716rf+Y9oL54586dJry9wI12wSbFmGhydISaunFqlGNFu0l/JiLt08CB1/6+qYXaaMYfjDKnJ4x7ypQpEfPBuIkG00c70TEyp2QZeEO6aEhFb9iwodVfk3mA4RllAfQqjweZBWwIXKLxr7/+uonuWJ9PImNIhFjXjgVR+niReiGEEEIIIcSxRaI7naF2lygjBmSrVq0yky/SyxHetWrVshpeXMIRjtRDU/vMfp9qTW02JmSYkhFJxfwraD+PaJszZ46JXVKmqfXFtZx6aAy+SC0mqrp69WqXP39+E4SdOnWyFGhEIunQM2bMcFOnTnVz585N07NSV01tM72tGS+RelKpMWvzZmcpgecn5dpDDToGae3atTNjM565d+/eNr/cKxF4XuaAuWFeCxcubBHt9957z1zTqeHu3r271WmTVcAiCcc0a9bMzMyi2bx5sxs1apTVqDO/jAkHegzl/OfDMSyWsDDA55zIGBKBa7NoQySe2nEWWBKdB5jWpUqSrQyEEEIIIYQQ6Y/cy9MZxBfCkZZSbdu2NfMxX09NWnKJEiVMqCLCiOBiBubTionsYh72wgsvmCEZBmA4lgdBtBONRagRGSfySwT0gw8+sMgspmCkRuN6fdJJJ9k5iD3qt6lbpv4Z0c9YELlpgbpmhCn3xmGcSC+mcb5GOa2wIMH8MA/MR6tWrVzz5s0tnTtRiJBzjXLlypkJHIKXVly0+KJGnZRvhD2tuph73Of5GXdx3NKjoU593bp1ZtbGtfhs+ZxZZAH2YwKHQR2fDwZvyY0hUfgu8JmSocC1WeARQgghhBBCZG1yhKKLiEWqQcTSBgoRJzR/WQVqusmIqNBtssuZ6/+Z2wmR0czpWV2TLIQQQojj/u9ssmaTyihVpFtkKTAOo4UYqdO0xqJ/tofILqn4pFbzpSZlfteuXeH3cRUnqh/koYceiojo0yaMTADM50jPJ/X74MGDMc/nPAzT4o0HiHqXLVvWjOOIQJOyT2SblmTJQZo4x5LqT2ScKDoRfXp/B6GunQwF6rRJMadcQQghhBBCCJE9kOgWGQI9yBHHsTYEZDxI76Z1GLXL1D/37dvXnMER4whuzOLmzZtn+zZt2mTmZ4myY8cOq3+nXpt2ZKSW47yeVLJHvPEApmaIdMQy71PrTX14SuEcUsepAyf1nDFiuge0L2NxgXR0zN0Q/fROp5+3EEIIIYQQIusjI7V0JFZLqBMVjMai+1LHa40V7cSOWRpgPjd8+HD30Ucf2WtEJyZlvv3V+PHjTcAvX77casoTEd2IWYS2rztPqjVYUuOhRzfim1ZjfO5EwYGe5byXEhDc1av/Lw2XFmw804YNG1zRokXd0KFDXcWKFU1oA6Kcnu9DhgyxyHwsfv/9d9uCaS9CCCGEEEKIzEGRbpEh4NpNK7FYW1JGa4jcIDix79692yLTiO1gv2nSuelzzXuJQOo2AhahXa9ePffyyy+7/fv3J3lOvPEAzuWMxwtuwEAvpQTvwfXB34Nnu/HGGyOO5zWO6fHah+FgT22J39SjWwghhBBCiMxDoltkKaKj4NQ8k1qeCLTPik4Vpw2YB+dvotO0YUOw084NJ3ii5xkxnkQJ3sP3I0/LPegdjpmD33788cd0GacQQgghhBAi5Uh0i2wB7dQQj0EBSZr1zz//bAIaaKNFCnkQ6qSDIGqJFJPGTS9z2q1NmzYtVWNCsDOeoJkbqe7p/dy0hQvCa9LMfUu4aDBcw2guuAkhhBBCCCEyB4lukS3AZZy08HvvvdetWrXKenfTE718+fLWsxwqVKjgVqxYYbXepF9Ti/3VV1+Fr4HZ2RNPPGHH4ISOa/iePXtM2KYGarcvueQS16RJE/fFF1+YGPY9xH3EOq107NjRasj79evnvvvuOzN2o648un+7EEIIIYQQImsiIzWRLUDE/vTTT5YuXq5cOUslr1q1qqWIe6pUqWKGY7T4Onz4sLmUI8wxYAMivvPnz7djuB6CmfZbt912W6rGxPk4jS9YsMCM3C6++GIzOLv99tuthVhqeP311yNeX3vttW7y5MmuV69eJryp+cZBPZ6JWlJM61JFUW8hhBBCCCGOMTlCSfVLEiILQVSa9l206AKEM6nh0b25k4Ne1/TvZkvP8QDRbvp24z6OKE8ptAJjXKTNpxe4l2OoVqHbZJcz1/8bqxDJMafn/1z1hRBCCCFE/L+z8VFKqqRTkW6R5Tly5IjVXlOznZVgPIh+eo/TTgyh3aFDB6sZT43gFkIIIYQQQhx/qKZbpImbb77ZtWvXzqKzZ511ljvvvPOsFdfBgwdd06ZNw63DcAwH2lw1b97cXXTRRe7UU081M7Jhw4ZFXJPUaaLX9LzOnz+/HeMj1M8++2z4Z6hdu7ZFvP1r+mbXqlXLxoEYJu177ty5qXo2kkAef/xxd+GFF5o5GWNp3759+H3u+fbbb7u2bdtaT21qvH2bLqLfefLksTRzxuE3XpMajwnaLbfcYjXajD+pyPa7775raeacSwo7JnD0GxdCCCGEEEJkfSS6RZpBOCIwMTdDgLdu3dr6YN9www1mela5cmXXqFEjd+jQIWuFVbBgQffWW2+Z+zi1yt26dbO65SCYh9EHmxZfM2fOPOqe3iV87Nix5ljuX//666+uWrVqdj7u5NR9U2ONcVpKmTJlinvmmWfcSy+9ZMZs77zzjpm5BUHUY3BGDTngZt6wYUMzVqtbt67LmTOn+/TTT81FfcaMGfb81Jp/8skn7oEHHnDdu3dPcgzUi1OXTgSd+WIspKCzIBGP33//3VJdgpsQQgghhBAic5DoFmnmqquuMtduUqzpEU1EFhHeokUL24ew3rt3rwlRelITqcVxnGg3buRExKNFN7XSr7zyirvssstsi8anmp955pkuX7584deMBTF7+eWX270xHyPVe/r06Sl+LoQ618Y5nWh3qVKl7JmSgig95mpE94cOHWoRfwzgeD1nzhyL2vNcmME1aNAgWUM05qpr167mkE6Um2g6z4T4jsfAgQPDEXe2Cy64IMXPLoQQQgghhEgfJLpFmrnyyivDP5M2fc4550REhEn1ht27d9u/L7zwgitRooQJZVKuR40adVQkmvOp404pRLppp0UbMAQ511+7dm2qIt1E63/77TcTu4ht6reTS+sOzgULBxgq+Ocmck9kPAhCPinWrFljbuXBFHXGQnSfzIFYsPCBmYPfgr3NhRBCCCGEEMcWGamJNEP0Ogg1ysF9vmc1qdWTJk0yUUyrruuvv95qvmmzRQ/tIAjW1MC1SUl/6qmnLLpM3fidd95pZmwphQgxQpmacK7Zpk0bG+u8efOOeuak5oLnTi0sIhDtrlOnzlHvxWtLRv05mxBCCCGEECLzkegWxxRaalHrjYD1YH6WGhC4GLNFX5+UbQzWvGj9/vvvUz1eRDs14WzeMI2+3xibpRRSy2fNmhWxz9eix4P7IPxZQBBCCCGEEEJkP7KV6MaQCsfn/fv3W+pwZpJevZ6zAqQpY3RGNPfAgQMZOr9nn322+/jjj92LL75otdITJkww4Ul9d2o+AwzTaNFFZBf3dOq4p06daiKZKHPPnj0t0owJGc+Ukv7XGJYh6kuXLm1u5K+99pqJ8EKFCrnUQK05dd5dunQxB3fM1bhHMBsgGurha9SoYTXlROxxPifl/KuvvnL9+/dP0f2ndamSZP9AIYQQQgghRPqjmu5kQBTFEqAIxZYtW7rjxX0cl+xFixZZrTDmWxkFgrN+/fpWd4yYxWAtGPVOCaSos1BAGvg111xj+xC1iG+i6QjvKlWqpCoqDXzutD9D1FOrTZo5DuTUrKcGFhZoMcaiANcbMWJE2L08Xjo448e9/YMPPrB68DJlypijemqFvxBCCCGEEOLYkiNEM+JsQmZEuhHdRLNTEiHNKlDHnIgZGXXQLCJQq3y8khU/R371cCJH2Gek2Rktw1hIqdBtssuZK3eG3Uccf8zpWT2zhyCEEEIIkWXxf2djXpxURmmmRrpJ+6W9ERFA0nZp90Qk0EP9a+HChe09xHZ0be7jjz/urr766oh9zz77rKUdBxkzZoy1nSKaeP7557sHH3ww/B6RUZyyMe4iYkrUlTpgL/JpZ8Ukkv7Lxj2Be3AvD+7YtWrVMndpJpxo7q5du44aK+nUnMuHQ8so0rkT4eabb7Zxs3EuLblInQ6umXBdRBx9nRmDj8TTb9o/P8cQIQ5el9fz58+35+O17/WMGC9QoIDNDVFp5sOzZcsWiyQTVeZ9ru/rlVkUoRUY7uR8dqR8008b+Ay5D6nVHsQ+Lt7+86FFVtAlnDG1b9/ede7c2dLTaePlP4dEPsdE2bp1q7X74h5ch7ZmQYM3ItO0H2Mhg/psPktPrOdC4LPPzxv/8nrYsGHW0oya9MGDB1svcb7fmMrxueHsvmLFivB1PvvsM3fTTTfZXPJszAWtyIQQQgghhBBZn0wV3Qju8ePHu5EjR7qvv/7aPfzww65hw4Ymwoj84diMsEPI3H///SbGUgpCCQMsBCgGWPRrDppSUSP73HPP2f1Js6beGHEHpCgjrBFCpF2zIURjLR4guPft22djJ+V506ZN7q677oo4DsOwd955x9KF2Th20KBBCT8L48uZM6dbtmyZCTeEJj2fg+DazeLF6tWrTZSvXLnSFgAQ+Dw/YpX9vpaYVGdaUOEkzvPxGhD3ixcvNrdx+mvTPgtxuH79enufOUWYI9a57pNPPmkLDsD1qaF+//33rV0XnwGLBLHYtm2bq1atmqVOU6vMsaNHjz6qXplnRwgjghGqtNFinhP5HOMxceLEcBsurk3dNP3CaROWP39+O987j9MurEOHDq5jx45WT019Ngsyn3zyiUspfIe+++47V7BgQdeuXTubZ34m24DPi++5d0HnO8O8161b1z6HN99800R4cOEoGj4XVt2CmxBCCCGEEOIEM1JDGDzxxBNWJ4vgA/ohIyheeukli8gSVfRRWSKLXtylBMQbQgnB5An2Sg4aoXFPjm/VqpUZfRHRJKpMdJLoajww82JsmzdvtkgksJhA9Bch5e+HgEPsEtEEzMs4d8CAAQk9C9emnpfx+PngNaLZU6FCBXteDxHnihUrmhAGMgcQxLS+wuWbqC4mYTyrf0ai9kSm+Rfx6YXi7NmzbT+fG+8hBH0/bj47D+9RY02k2M9rPJhnnmv48OH2XLiDb9++3Wq/MRFDTAM10L1797afiZxzPHNXqVKlZD/HeNSsWdMi+MDiAgsgRKMpXUD0BuumWcxgvnz9+SOPPOKWLFli+4lSpwSyOVik8dC3vFOnTvbs/vmCC1N8hv75eI/FhfLly9sCRay2YZxDmzEhhBBCCCHECRzp3rBhg7lmI5p8tJENsUp0jwipF0QeL84TZffu3SbgEJ3xQPTzPmnUiGGEMOZejC1RGCvC0QtuKF68uIk33guKQS+4gVRqxpgomGgFXa6ZDyLPwbZZXugGx4YRWBBeR58XBDHPewj04GdDZN639yLFGWHLtRDDRGE9rVu3NhFLOj3RYgza4sH4eI7gc3FNUsNJ9/YguoNEz11qPkeOI+uBje8Jad3MH6+jjcrizWPw802U6M8IAU8mB27uCP9gCzWi/yzUBD8HzNVYwGGRJxaY1FES4beMrBcXQgghhBBCZFHR7ett33vvPUsf9xtR2GBdd1IQBY32gfvjjz/CP1MDmxTU4dKOCUFH3TOpvUQdvQlZeuNThj0ITZ++nF6QJp0en81JJ51k8xH8bBCYpLUDIpEUesQtIh0h+fzzz9t7t912m9V8Uy7gFz1ipeWn19ylx+eY3HclOXxEPvh9DH4Xk/qMSPknLb569eqWFs+CDens/rMglT34OSDEWTQhEyQW1MZTEhHchBBCCCGEECeY6EZYIA5IRfbRRr8RMS5WrJjVLgchnTcIRl07d+6MEDpBIysimb6XcywQZwg3UtiJIhPZRSQGIe06XkTYw1iJJgYjiiweYKTFc6YXQVMvPx+kGyOQkxrbwoULI/bxmmeNdx6p4TwzkeTozyaYZs/nRAo3deCktOPCHfxsmjRpYr2tqYsfNWpU3PFR0xz8DBkfnx11zomQyOeYHAh2vjvU5adkHv3ny/MCdfGxvovJwZhZpKA1GF4G3niOdmd8l6I/B7ZEnOmFEEIIIYQQJ2hNN6KK6CdCA8FUtmxZS4VFyBCZQ8whoqh1JaqKsPLmX0FX6z179pix1p133mk1x5h3BSN7RBG5Vt68eS0Ci1s498DACuFCNJIILYZt7MfULQiinWgjwh2DMuqf2YKQFkxtM7W3CEyct6n9pe42OpU4LbBAQSoykc9Vq1bZuINO5LFADFNTjqs5xm4IXOqhk6p1RgDyLLigc31EOPPMHCBOichSY8x8cixu5RiKIUyBWmxStalpp3Yf0zj/XjTME3PG54E52Lfffmvp6jynjx4nRyKfYzQs6PB8PBMp6biWU6t+xx13WE006euY0VHTTvo730Nq2Pl+EY2mXzeLDaS1+0g5gp/0cNz4WbDo0aNHxD1jmeZh2sa1+f5yHin1+ABwL6C2nesyN/weECVHhGMix+eYEqZ1qaKotxBCCCGEEMeaUCby999/h5599tlQkSJFQieffHLo3HPPDVWpUiU0b948e3/GjBmh//73v6F//vOfoZtuuik0ZswYwqGh/fv3h68xYsSI0AUXXBA67bTTQo0bNw4NGDAgVKhQoYj7jBw5MnyP888/P9SuXbvwe0OHDrV9p556qt17/PjxR92jVatWoXPOOcf29+7d2/Zxj2eeeSZ8zJYtW0I1a9a0cZxxxhmhevXqhXbu3Bl+n/OuuuqqiHFxfvRY41G+fPlQmzZtbCz/+te/QmeddVaoW7duNoee6DF53n777VDx4sXt+S+88MLQkCFDIt7v0KGDXT/IkSNHQr169Qr95z//Cc9b7dq1Q1988YW9/+CDD4YuueQS+2z43Bo1ahT66aef7L1+/fqFihUrZnN69tlnh2rVqhXatGmTvbd582abx9WrV4fv9emnn4ZKliwZOuWUU0L58uULdenSJfTHH39EPDtjDMI1mzRpkvDnOHbs2NC///3v8PGffPKJvc94PN9//32obt26Nr+8x/MtXbo0/H61atVsjMxH4cKF7R5Bvvnmm9D1119vY7j66qtDH3zwgV2He/nvc/R36/fffw81aNDAvsNcO3/+/Da3v/32W/iYZcuWhSpVqhQ6/fTT7ft15ZVX2vc8UX755Re7L/8KIYQQQggh0odE/87Owf8cc6UvUgxRfYzJgr3BRcZBzTh11US+g1kTtHxLSdp4VoCWYbjwV+g22eXMFZmlIY5/5vSsntlDEEIIIYQ4LvF/Z5OxnZSPUqb26RYikcUGUs9JZz/rrLPceeedZ7XjBw8etD7Z3oGctG8PLuulSpUyzwDSxOl7Tcp/8Jq4r+OsTss06tQR1B7f4qx27domvqNbnk2YMMH28QtG/3NKFhKBlmNBEc81ohdRWFgJjoX704udsVDWQA0/veaFEEIIIYQQ2QOJ7iwAtdrBllDRG++fyIwbN87lyZPH6rAR4LQkq1evnrvhhhustr1y5crmok57sG3btrlq1apZHTsu3/SyHj16tLU3i74m9dGY0+EJ0LdvX6uTBmqqATMzjNH8a6CdF9Fu6tTZEPixarXTE3pu169f39qy8WzU28czfAPq6Fl1C25CCCGEEEKIE8xITfw/MOtKKmWZ9z/99NMTdsowsPOmZPSgRuQiwlu0aBE2bkNcI0oxOMNVHZMxosRFixY1J3MMyTjOm7NhCIdhGxA95nhM1egb753I6bMedGsHTP8w9PP91hH7nDdgwIAMe34i5Bi9AWZvzz33nC1AVK1aNebxGMEh1IUQQgghhBCZj0R3FiBnzpyWIi1ig0D20ObsnHPOMbd4DynngGM4vcRxG0dwe2688UZzoMcZ/MILLzzqmkAaOucnBynhXnCn5Ly0EBwr0XnqRZK6JwsTuL97iHSzECGEEEIIIYQ49kh0iyzPySefHPEaQR3c5wU2Uei0XDOR81N7XiyIukf7GNL6LK33pJadTQghhBBCCJH5qKZbHFfQD5xe5EExS99uotMFCxZM+DoI3b/++stlJKSxUzMejEhv3rw5Q+8phBBCCCGEOLYo0n2Ck9JWZJiIPfrooyYOMTVLrxZmsVp0pYY2bdrYmBjbgw8+6L799lur3Sbd2tdzx4MUdMaxevVqSyOnVpvUdKLGOKenNxUqVLD68Ntvv93qx6k5J30+o5jWpUqSrQyEEEIIIYQQ6Y8i3SJFPPDAA+7OO+90P/74o+vXr1+GzN73339v4jc1/bALFCjgZs2aZUZjGLC1atXKNW/ePGzElihPP/20uZlTC33NNde4jIDa6/Lly7saNWq46tWr24LDJZdckiH3EkIIIYQQQmQOOULRRaXihCIlkW4iwaRpf/zxx+6WW25J13EEI92I7osuusgizoztWJHR98WBnEj2a6+95o4lpK3TU7xCt8kuZ67cx/TeIu3M6Vld0yiEEEIIkQXxf2f/8ssvSWaUKtJ9AnHw4EHXuHFj6/2N6zbR3Oj+zqSOEy3GJbt06dLhVmX86127SYtGJLNv7969JiY5J3fu3OYq/sYbb0Rcl1TtaFGPqH388cdjjhPhC0SYuQ8LA8nBMQ899FDEPgQ87baC46DlVrNmzexZcDIfNWpU3GtS082xtB3zvdIZzyuvvOJq165tz0u7senTp0ecR+/uUqVKWVo689y5c2drZ0atOaKbVHJfL040n2t27do1fP7999/vGjZsaD+Tfs7xc+bMsXp1PjtahQVrwYUQQgghhBBZF4nuE4hOnTqZIHz33XfdBx98YKJ51apV4fepgUYYTpo0yURivXr1TOCtX7/e3XDDDVYfDVOmTDHRx77Dhw+7EiVKuPfee8999dVXrmXLlta7mvTu1OLPnTt3rt1n6tSpLr1goeG6666zaDb1361btw4/V/QCBM+PKF6wYEG41RjQA7t+/fo2R9WqVXP33nuv/YwgRoizAMD1Edj79+93Q4YMsVT3yy67zPXt29cdOHDA3gc+D3qOB/uwsy+40HDo0CH31FNPuQkTJrj58+fbAgCLI0IIIYQQQoisj0T3CQKp4aNHjzbxVrFiRYtIjxs3zv3555/2PkJu7Nix7q233nI33XST1RYj7MqWLWv7TznlFJc3b1479uyzz3b58uWzfUS4OY7I9cUXX2wGZgj1yZMnp8nVG+jHzX24X3qBSEZs0xe9S5cuJng/+eSTo+aKGus9e/bYe348HqLnRPe5BpFzjqfGHYHOe8zDN998Y0KchQgi+gjyGTNmuEKFCtlcBTMIHn74YRPhXGfbtm1uw4YNVusdbCM2cuRIWyy49tprbXEEk7d4sGBAqktwE0IIIYQQQmQOEt0nCBs3bnRHjhyxlHEPYrZIkSL285dffmkpz4ULFzaB6DeirpwbD87BUA0Rz/U4h1Ron46d1bjyyivDP5PWjajfvXt3xDEIalLxyQagRiOpa5CGT/0GafaI8J07d7py5cpZ2jmv2UhzR1Bv3brVzkFQI7axUyCKXqdOHUsd/+yzz2y+8+fPb+d7iJ4HDdZIWY8ec5CBAwfauP2GGZwQQgghhBAic1DLMGEgCkmHXrly5VFtqxDS8SB1etiwYVazjfBGhFJbjcD30Kor2q+P6G16kug96L8dBOH9999/HxUNx+yMVHvq11NzjaQgdXzMmDFuzZo1di1qxtmHECcdPRjljne/pPwPcUWnRZqHSLeEtxBCCCGEEJmDIt0nCERKEW9Lly4N70Pgfffdd2HTMqLWRFB9hNZvRIPjsXDhQlerVi0z/qJumdRqf00P6dlB4y9EIH2+40HaOnizsUSIvgfnktqdGqjzHjRokKtZs6ZFnlMCEWvEelAUM0cYtxUsWNBek75PXfczzzwTFthedLMlYhyXFBi4EX0PbkIIIYQQQojMQZHuEwSi1fSrxkyNWmnqs7t3724RYiCtHEMw3M0xG0OEU9NM7TDp1NQ4x4I06LffftstWrTInXXWWW7o0KFu165drnjx4uFjiBbjwn377bebE3evXr2OiqYHYWynnnqqmz17tgnVXLlyxUzzDsI9iO5i6MYCA+P4+eefUz1f1KYj3Omh/f7771tteyJQL07Un/OpvcakrXfv3jY2P9fME3M6ceJEN3z4cNtHSjrmbETnoyPd6cW0LlUkwIUQQgghhDjGSHSfQJAKTho54pfIa8eOHa2nnAfDtP79+9t+DL0wGStTpowJz3j06NHDbdq0yVWpUsVqj3Evp4Y5eF3SnYlscx3EMzXgSUW6c+bM6Z577jlz+kagExkOunvHgtZepGuzaMD5mJOltpc4pmVLliwxYzTSxkk3ZwEAt/bkwFhu1qxZtrhB5J86dxY7mKcgCGuu76PaHMdCBQsWvs5eCCGEEEIIkf3JEUqqOFSI4xzqo6dNm2YLBR7cxt955x0TxccDpPOz2FGh22SXM1fuzB7OCcecnrGzRIQQQgghxPHxdzYBx6RKOlXTLUQ2JWhWJ4QQQgghhMiaSHSLLAFp1tRB43xOzfN5553nXn75ZWvd1bRpU4tIUxNNfbdvZ0bdN7XhGK/RRqtr167hvuP+mu3bt3edO3cO9xYniu35z3/+Y//Wrl3bru9feyZMmGD7WL1q0KCBmZ+lx7OQ2o9BHbXiHurHSUO/6KKL7LlIMccVPgg9wInIDxgwwNqKKQ1dCCGEEEKIrI9Et8gyjBs3zurIly1bZqIVF/F69epZLfWHH35o/bOpG8cdnBprhDL7OH7EiBFu9OjRVpMefU3amOHaPnjwYKsT51qwfPnycC07zuf+NdCbnBTzmTNn2oaLOY7m6fEsq1atcpUrV3aNGjVyhw4dsuOpHcc07q233nLffPON1bJ369bNTZ48OeK6GNthzsYzMK5Y/P7775bqEtyEEEIIIYQQmYNqukWWgOgw0d4FCxbYa34mwlynTh03fvx427dz506LaCO6Z8yY4aZMmeLWrl1r4htefPFF16VLF6upICoefU0oVaqUOZ17AR2vphvTOe5HVBqIls+fP98M1tL7WTCriwXu5xyHO7yPdLPY8MMPP4TbqsWC8ffp0+eo/arpzhxU0y2EEEIIcXyimm6R7aCNloe0cVqbXXHFFeF9pGkDvcQR29dff31YcMONN95o7uxbt26NeU1A6HJ+cpBW7gV3Ss5LzbN4XnjhBVeiRAnrOU76/KhRo0xgB+EaSQlu7xbPwoPffvzxx4THLYQQQgghhEhf1DJMZBlOPvnkiNcI6uA+L7BJxU7LNRM5P7XnpfZZJk2a5B599FHrkc5iAoKfaDtp8UFIlU+Of/7zn7YJIYQQQgghMh+JbpEtKVasmKWX0/HOC9iFCxeaWKU2OlEQwqR/ZzaMnXrvNm3aRNSVCyGEEEIIIbI3Et0iW4I4ffbZZ82kjNpnzMV69+7tHnnkEavnThTSyDEnIzWd6DBu46SoI3iJKiPKf/7552Sv8+qrr5pbuT+W2u+rr7464V7fl156qdV7z5kzxxzMcU7H2I2f04tpXaok2T9QCCGEEEIIkf5IdIt0AZMvBCeO38eCAgUKuFmzZrlOnTq5q666ylqC0XKrR48eKboO6dwIdVp6cc3vv//ezM1oPfbFF1+YAVoi3HXXXa5atWqpfBrnHnjgAbd69Wq7jndlZ2Eh2FYsrdR+co7LmSt3ul3vREFGaEIIIYQQIi3IvVxkS9Gdkdx5550W5abtV2rBQZy5SDTSHYsjR44ka5qWEldFuZenDoluIYQQQggRC7mXi4gWVqRgsyG+6B/ds2dPq4eG/fv3u8aNG1tqNX2wb7vtNrd+/foIAUmqdBBSu0nN9u8jUN99912L0rJ9+umn9h5O4kRtiUQjZK+77roIczD6a19yySUmLosUKWJp1UG41ksvveRq1KhhY6OWm0j0hg0b7Lm4JrXQ0fXPjOXaa691uXLlchdffLG10CJ6nRw8E7XipHpzbxYTYOjQoeYczv0uuOACi0KThh5MLz/zzDPjXpexkn4ehDZl/vr+3v369bPPgjTwli1b2v7PPvvM3XTTTe7UU0+1e7dv394dPHgw2WcRQgghhBBCZD6JF7+KbA2iOGfOnG7ZsmVu2LBhJiJfeeUVew/ht2LFCjd9+nQTtIhxUqX/+OOPhK6N63b9+vVd1apV3Y4dO2xDCCNKy5cv77Zt22bXXrNmjfW79o7d9Mfu0KGD69ixo/vqq68sxbpp06buk08+ibi+F6JEjYsWLeruueceO5bWWIyb8bKg4KE/Nsdz7W+++cZEO6J4wIAByT4LddQ8B8/DczBXQJ34c8895z744AP3008/uZEjR9oiBa292BgP7bmiW3yllKeeesrS5Uk1Z2GExQTGU7duXUt3f/PNN02EB583mt9//91W3YKbEEIIIYQQInNQTfcJAhHSZ555xqK3RJS//PJLe00EFkHs3bNh4sSJdjzp0fXq1Uv22ohOorCIvXz58oX3I3T37NljQpZIN/z3v/+NEJgIfu/YTW01BmTsv+WWW8LHIcQRwdClSxdrqYUgrVKliu1DXHOMh6h2165dXZMmTew1kW6EO4Ifs7WkoEc2hmo8T/BZfJSaaDlzR60112IRA4iOI+rz58/v0kKFChVsEcJz//33u3vvvTd8fwzXEP8sZpAlQCQ/moEDB9ocCCGEEEIIITIfRbpPEMqUKRNurQUIV1LIiQQTAS9dunT4vXPOOceE+dq1a9N0TyLT11xzTVhwR8P1cQ0Pwuvo+1555ZXhn8877zz7l1Tv4L7Dhw+HI7pE1Pv27RuOQrO1aNHCIteHDh1K1bPMnTvXVaxY0RUqVMieCQFPWj4im4UExkA0nLlMC6TfB+FZWLwIPguLDWQLbN68OeY1yAAg6u63H3/8MU1jEkIIIYQQQqQeRbpFsiAmff23J5HUc6LF6QFtuzx+4SDWPp+2Tlo7kd46deocda1YkeHkwNGcmvLWrVtbNJtFBFK8cUvH7Ixa8/SaQ2rGg/AspK5Txx3NhRdeGPNeROrZhBBCCCGEEJmPRPcJQtC8DEjjJlW5ePHiljLN+z69fO/evdb3mvd8yvXOnTtNNHqBG+3KjRHaX3/9dVSEmrrxffv2xYx2Y4pGWrtPAwde+/umFgzUGH8wlT0trFy50gQ97cV8D/DJkyen6BrMIZF2D3NFHXswjT7es5CNkF7PIoQQQgghhDi2SHSfIGDwRc00UdNVq1a5559/3kQkwrtWrVqWfo3h2BlnnGH10PSsZj9Q901t9uDBg62d1uzZs62mGYftoPP2nDlzTOySno5L+kcffWTiEpdu6ozPP/98MwgjJZv0dnpsU6tNujb3bdSokYlazksLvXr1ssg0kWDGyzVJ00bk9u/fP8lzeQ7GUqJEifA+BC9Raebs9ttvt4UBjNRSWqvN/L/33nvm1o6RHS3WkoMadkoDME6jvptIOCL8ww8/dMOHD0/RGKZ1qRLxmQkhhBBCCCEyHtV0nyDg5v3bb7+5UqVKubZt25r5mG9JNXbsWBOZCFXEMBHtWbNmhVO4iUi/+OKL7oUXXjBnbczDcCwPgminDpyaZKK6CFNE6qJFi1zevHnNDZ067EGDBrmTTjrJzkGM4w7uDdWAeyDy0wI1zzNnzjSn8ZIlS5poxTSOeuzUwDMjkp988kl3+eWXm9EciwgpoVmzZhbR53PABA1zt+Si3D5bYN68ee67776ztmEsULCokFbDNiGEEEIIIcSxIUcoutBUHHcgYumzTW/trAp9vRGhmJMl1e86oyHSjVN4dE/t7AwGc2QeVOg22eXMlXz9+fHGnJ7VM3sIQgghhBDiOMT/nY15cVIZpYp0iwyD6DXRbKCdGGZgRL0xMytbtqy1EouGCDnRXY4hQk1KeCI8/vjjtrAQhEUGRHT0eIisk+pOGjxR/6RM4ahJZxHAp7yzgMFz4F5OnTptxbh3dCo/qfk4jfPLRwr9rl277D1+IYn0018cqBXnOjyr57XXXrOWbd7EjTr6qVOn2qIEpm1E3umnLoQQQgghhMj6SHSLYwIilV7W48aNs5py6qRJA8dkLQh13tSaI8hJU6eGOhGn9EQh5dy31Dp48KClzftWXJdddlnEsdSwU9/OObQL8/AM1FZjPscxtCejxtqLaAQ3z0VaOPs3bdrk7rrrLnuflTAWB4jsAz2/EdXUuuNUDpxHCnqQ7t27W0o/BnaFCxd2d999txngxYIFDlbdgpsQQgghhBAic5DoPgFA4GVmajnidsSIEW7IkCHutttuM3fyl19+2VqKjR49OuLY3r17u0qVKln9N+KWCPG0adPSbSwIeaLnX3zxhf3LeLgfYpY69qCBGXOGAKYOPgiReMaJCR012tSx+0g4/yKkX3/9dauTp//5+PHj7To+sk+03Itu/uX+1M3ThszvixbdCO7q1aub4KYd2pYtW9yGDRtiPiP15oh7v/mouRBCCCGEEOLYI9EtMpyNGzdatPrGG28M78OkDTG7du3aiGMxcvOQdo05W/QxaQEjNK5JpJ0N4Xzo0CH72RutEWlnUQARHB399qI7CKnqu3fvtp8ZKyI3KHRZZCBF3T8Hgppr4+yOGEeEeyG+fft2E9PRZnLBe3I/8PeMxkfy/fbjjz+mYcaEEEIIIYQQaUGiWxwX0BYs2hMwVlq6d2T3kNpNSngQXMIRxPF6cSdyjaQoV66cO3DggKXZz58/P0J0I8JxJmcxIN49fa/0ePf85z//abXkwU0IIYQQQgiROUh0iwyHvtSnnHKKmaQFBTHp1kSBgyxZsiT8M07mtMoi9TqRtPGdO3dGCG9SxlMDEXj6kD/xxBNmupYSGCuR5WB0mb7a9OT2z0rUm8g1fbYR00WLFjUhTl03rc6iU8uFEEIIIYQQ2ZecmT0Acfzh2255MB1r3bq1maSRMn7hhReaARlp3c2bN484F1MyXMXPO+88E79Ebb0DelIQKd6zZ49d984773SzZ8824ZySKC8u5KR3ww033GA13tR858yZM+EWYrfeeqvVo997771WE47ZWZs2bUxIU/sdHC99zBkrMC8I9jfffNN6lWcE07pUUdRbCCGEEEKI7BrpJpInBBDBbtmyZUQ6NCK2bt26rlGjRu7aa6+1uuU5c+a4s846K2LSBg0a5Dp06GAmZKR4t2jRwqLkyYFgxYkcwUpLrWXLlpn5WFqgrdl7773nevToYQI5EXjWd999156L6DUi/OKLLzYxHQQRzvMFa7f5OXqfEEIIIYQQInuTIxRdCJsATz75pEUzfRsk+hDTDoqexUQHET3ixOPIkSMRApm2VvSknjhxojmQJxKxjhUxTzTKnFaIdL/zzjupTkvPqtAyDBfzCt0mu5y5crsTjTk9q2f2EIQQQgghxHGI/zsb8+KkMmxTFekeOXJk2J2ZPsRspPKSiksKsch6ED1t166dCViisKRv49BNO6+mTZu6M844wxy8+RyBiCup3xdddJG19sLxe9iwYRHXvO+++0xIDxgwwMy/OMaLZfpbL1682CLFULt2bYsC8553NKefNeOgR3bJkiXd3LlzU/Vs33//vV07KJbJvGBfsDUXr2npRZp37ty5Lfr+7bffxr0uYyRK/eCDD1qt+Kuvvmr12EToiawz7qpVq7odO3aEz8HcjBT5ggULWmo8PblJdfeQTs71PHwejGvdunXhhQvS8f1c8Lm1b9/e+pyTgs7CFosDQgghhBBCiOxBqkQ3hlVedGP8RKS7cuXKJgx8L2KR9aDvdZ48eSz1GgFOnXW9evVMfOKkzWdI+je11ohHhONbb71lRmC9evVy3bp1O8rRGxGLcGXhhe+CF45Dhw61dlvcC8aOHWvi1H8/fv31V1etWjU7HwMxxOvtt9/ufvjhh5hjZ0EHkRtrS0kNdPfu3a0l2IoVK6xWu1mzZjGPo4836eX33HOPGZ55x3DmBnO1CRMmmPM44w2msbMwwfU5hmtUqVLF1axZ061fvz6cVu4XAgC3cj4Tv4/5wWSOzyT4uSHEly5dajXriHrmWwghhBBCCHGcim4ipd6dmSgedatANJAIqciakPZPfTLtqOjlnCtXLhN81E2zD2G9d+9eE4u4avfp08eiwkS7MQYjIh4tuhGDr7zyigls39OaFHPEIVFu3/qKCDFRWlzG/VgeeOAB65vNMf369TOX8+nTp8ccO/cgkh1rY2yJQlQe4YuTONH4RYsWucOHD0ccwz4izIjp/v37R7yHICbTg3mhNp2oNQsHHsR2ly5dXIMGDSzyTykG0W5M1YDrsoiB6Rvu7PxMDXswIk/Un0i8B6fz3r172zw1btzY7h28ZzS///67pboENyGEEEIIIUQ2ci+vU6eORQARAYg0opBAxJIUZZE1Qbx5qLXGJRynbQ+p3rB79277lwjymDFjLJr722+/WQQbARmE8xMxOouGSDdp0ghzIuC4fHOPeJHuAgUKJJlenpo5OP/888PPi6M6cP9KlSqZOI9VS44YZnEgeA0/X4hb3M9vvPHGiHN4vWbNGvuZRQbSxIlwM2/XXHONq1GjRjhaz/5oI7XgmKPvGYuBAwfagokQQgghhBAim0a6n3nmGYvwES0kzZUUX0A80R5JZE2IXgchZTq4z6dQk1o+adIki/RS1/3BBx9YRJlIN8I7OtKdGrg25mr0wl6wYIFdHwEfff1E+Mc//vc1DnoCEpGORbzn9RCJp1XZG2+8ETNCHGsOU+JFyPG4mhPR9gIbUU10+quvvrIoe3Sf7lj3DI45GrIYMHPwW7BnuBBCCCGEECIbRLoRAbHaMT388MPpMSaRBVi4cKHVFQcXUTAWS+33JbrsgOtjxIbBmo98pyRiHcSnrLPoQ+QYUutAjmkctenUm1OPzYIDJnOJgGMhhnI8W1A48xoh7+E9TOwwWiOizqIBQnzIkCEmvqMj5SmF67IJIYQQQgghsqnoBoykXnrpJbdp0yZzqS5UqJDVrVL/iyu1yBoQUb3llltSLOQoHRg/frw5dfOZ8nlj8sXPKQXHcmqQSdfGvA1DNq4/depUM08jctuzZ88ko7fJCeUyZcpYj2/GR+o1teuACVowXXvEiBEWCQYv0AHBT0p24cKFLXpP2jtlE2z4FvhsjuTAvZ/6a1LQScXHQI4FANqmeRgPC1Skl2PW5vexkEU9d2qzB5JjWpcqSbYyEEIIIYQQQmSR9HKEyyOPPGKChNZMPoqJWZY3jBLZG0zOqN2nF3vp0qWtdj/R0gGi1l7YAm7elCEQicaEDHA3x5CPaDrCm6gyxmSphdpz6sJLlChh4t4boMVzJ48GN/6OHTuauRzgbv7ZZ59Zmnr16tWttVoi0N6L3w2uRbo8gh1zOG8oB+zndwVR7sU8opvfo4wS3EIIIYQQQojMIUcoJQWp/z/UclOLS49mUm8xiaKfMTWpiIeffvopY0YrUh3pxikboXcsoJ81wpcFmawEEXfG5Q3SiLBTV873OKPmzTv6054speNLL6hN//e//+0qdJvscub6f67oJwpzelbP7CEIIYQQQojjEP93Nj5KSWWUpirSvXnz5ojUXA91pIlGBEXqIAUbd2rSqEmrpvXW22+/HX5/1qxZliLNe4jG6DppHMOjHcjJTkDwRUeOaQHGZ4pbNsZ5HqLURGuJyhIhJgJOdNuLVQzX+OIhatm4J3CPYCYETuGUIhDt5UtKv/ddu3YdNVZS2zmXLzStuA4cOJDQXLEAlKiAZZ4YK6ng/MzcAdF49lN/nsj88/wc//7771vUnfkjYk49PM+KQzzPSxr53LlzI8a6ZcsWSzv38+bh/Jtuusnux3wTTdfvmRBCCCGEENmDVIluBEcsoypSaYsVK5Ye4xJxQPBRa02a9tdff20irWHDhuaEjUs1KeGka/P53H///daLOjXlA23btnUtW7Z0X375paVHB1vBYfz13HPP2f3HjRvnPv74Y9e5c2d7j3RxhDUimnRytlime4hXROi+ffts7KSf4w9AOnsQxOrzzz9vddo4m9MnnFZnCFc23xs8PUHYTpkyxX7+9ttv7RmGDRuW7PwHYd6pMV+7dq25k7MogTkbte201qtatap9Tr5FGvXtBQsWdH379g3Pm39+jq1bt671T3/zzTdNhAcXQYQQQgghhBDHmZEaNauIssOHD1v67LJly6zFEoLklVdeSf9RCgNna9L6iZBef/31to+0fkQYpnZEgzHwooYaihQpYqL5ySefTNEMUg9NTXKHDh3C+4jMeoLRY+7J8a1atXIvvviimYMRkSZSmy9fvrj3QHwyNrImELmAmEVEY9jm74c4f+edd9yhQ4fsNc/C+z66HN1OKz2ghzm9tCFv3rzh9PLk5j/oWI54pt+3h+sRFff069fPUttZ0EBA8z73pVwjOG/8Tt17773hOac2nAUP7sXiiK9BD8I42TyxWp8JIYQQQgghsrDoJoJKqisO0Yihe+65x1olEQ0k/VdkDBs2bLD5Doo5IAJMuv9vv/1mpmdBvDhMFCLK27dvdxUrVox7DKITMbhu3ToTdBiYsQDD2HLnTqxmmAgwYtsLbu8VgMDlPS+6EfV8t4LHINiDkfesMv9BrrvuuojXRLpJl8cVnSg2c8bn5SPd8cAvgQh30P2chS4WI1iwiJVZwmeDE7sQQgghhBAiG4puxMLrr79ubtNE4BAhCAoigiJj8XXTCLcCBQpEvEftMLW+yUFqeLR3Hg7dHhZTkoJ65xo1aljrL3pME6El0tu8eXMTn4mK7kSJjmQTQU9ta7GMnv8g0S7kpNiTQv/UU0/ZggHzfOedd9qcJXdPnORjfbYXXnhhzHNwjicbxcPCSHBxQwghhBBCCJGFRTcuzKQSE40ERFZ6Cy0RG6K8iDuio8FUZg9RT9KVgyxZsiTi9bnnnut27txpwtubdQXr80lv9n21vZlYkJUrV5roJYUdAQ/UWQchxdy3kYsHY6UGnc0Lwm+++cYcz3nOzIZngOBzJDf/SbFw4UIzY6tdu3ZYTEeb3MWaN9qoMS8piewzxuhFACGEEEIIIUQ2Si8vVaqUmUEVKlQo/Uck4oIgJmKKeRfCt2zZsuYSjqDDuIzFEMRwp06drAQAgUz7riC4ZO/Zs8cNHjzYIq2Y3+G0HbS4Jw2aa5G9QC923MK5R7t27Uz8ERnH3AwjMPb73tseRDuiEuFOHXOshZlbb73VHNDJlsB4jQwKXNARs9Gp2ZkB320WJWbOnGkGaESmk5v/Jk2axL0etdiYpTFnXLdnz55HReyZt/nz51uJBqI5T548rkuXLq5MmTJW981nSgQdEU7UfPjw4Sl6pmldqiTZykAIIYQQQgiRRdzLEUcYbfFH/+LFi63mNLiJjAMDLgQbdbtEi3G2Jt0ZR3nSjXHdxngMsYsYxvgrCOdgePbCCy/YMZjgRbuLIx4RwhyHsRnp5OvXr7f3OIeWYRiaXX755VZrzFiC4GCOaMeJnMg6Aj8ahOe7775rLbnKlStnIhxTMty5PSwYbNu2LeG54blZFMCQLK29rkkfpy4aF3IWH2rWrJns/CcFc8azMjcIb8oziGIHwXyN6DdmeMwb4HyOM/p3331nbcOoHe/Vq1dEnbsQQgghhBAi65IjFF3gmwA+rTjiQjlyhFOWk0stFiIRiMrTpzvY2zsp6IFNj3Dqn4lKs6UHfKdxGr/jjjtMFCOwyfSI7neeVaGmG0f5Ct0mu5y5TrxSkDk9q2f2EIQQQgghxHGI/zub7NekMkpTlV6Oa7IQWQnS2XFeJ4KsKLAQQgghhBAiW6eXU++a1CZESjl48KBr3LixO/300935558f7jXuoe80afCkfVPXTJo1ddYc7+utoUKFChaZJk1979697u6777ZzqCmnhpx+8tF11NGRdCLY1LXHwqeRc3/uQzQ+KajRxoEd87ogpL+TLu7BAZ7XPAvGckTrmRMPqf7UhdOXm4g+9fhCCCGEEEKIrE+qIt3jx49P8n3EkxApAfM3apep86aGulu3bm7VqlXhFG6MxDAQmzRpkkWyqV2ntnrGjBn2mtrvypUrm88AtdLUnu/fv9+VKFHCzMhI96D2ulGjRlYzjRlgaqAGnnPpVU69u3c5jwf16tSqT5gwwZ4RMKKjFt7Xum/cuNFqw/v37+/GjBljRnc8L9vYsWPdihUrTIRzDWrC9+3b5xYsWBD3nixQsAXTXoQQQgghhBDZSHR36NAh4jUign7dCBAiihLdIqWp4aNHj3avvfaaq1ixou0bN26cK1iwoP1Miy7EJ//61PHOnTu7Dz74wH388cdmFuf3I4Svv/56+5nvYtAkDvf1OXPmWIuz1Ipub3B2zjnnuHz58iV0Dj3MGb8X3SwUHD582NWvX99eY8qGi7s3fyOi/dxzz5mT+4gRI+y5ie5jaEdEn2wSIu3x4HqYwAkhhBBCCCGyaXo5EcTghmj69ttvrYVSdPquEMlBpPfIkSOudOnS4X1nn322K1KkiP385Zdfmjlf4cKFLZ3cb0TGOTcenIPbOGnlXI9zEN2I2GMJ/bk3bNgQ7pmOKzuCGyENa9assX3BZ6M2nZZi+CdUqlTJhDYRcyL1RMlZ5IrHY489ZmYOfqMXuhBCCCGEECIbRbpjQXRu0KBBrmHDhm7dunXpdVkhbFGHNmD0HeffIAjUeAwZMsQNGzbMarYR3ohcoskI/KATf7SBP5kb6Qnp8rQJI9pNTTh90T/99NOI53vggQcshTwa2sCRQUKqPecQ3adlGDXny5cvd2eeeeZR59Djm00IIYQQQghxHIluu1jOnG779u3peUlxAkCNNWZjS5cuNZEJZFDQm5oUa1KpiVrjTh40H0uOhQsXulq1atlCEBA55prFixePSBffsWNHRP1zUu78voY7pW3x7r//fjN1I2We573xxhvD71GDTr06PcaT+t2ilzlb7969TWyTWl+nTp0UjUMIIYQQQgiRDUT39OnTI14TKUS4YGIVFBNCJALRauqeqXmmVprIcPfu3cP94Ekrp+YZrwBczRHhmI199NFH7sorr3TVq1ePm33x9ttvu0WLFrmzzjrLDR061O3atStCdON2Tmo3kWiELFHkYDQ92sWcseEwPnv2bBPQuInTmy85SBfHzA2ztL59+0a8h9FbmTJlzDgNcU5EHhH+4Ycf2u/UzJkz3aZNm8yUjeeYNWuWLSD49PtEmdblf2MQQgghhBBCZHHRfccdd0S8pnUSEUMETHSrJyESgVRw0qwRv5iFdezY0eqRPaRmI1jZj1N5njx5TKhiLhaPHj16mFhF8GKq1rJlS/vuBq9L/TORba5DlBuzNSLRSUWcMTlDOCPQibwHU8XjwQICtd2YvkUbDbJwQH06Cw1cj0UsxnDXXXfZ+ywGTJ061RYAMGBjMQHvBEzjUkLtJ+e4nLlyuxONOT1jL8oIIYQQQghxLMgRii5oFeIEhcWjadOmRSwqIXTfeecd9/nnn6f5+kTzidBHZ4pkNCwmEI2v0G2yRLcQQgghhBDp/Hc2Qb2kMkpT5V5OlC+We/Jvv/12VOqsECnl5ptvtogzpmekU5933nnu5ZdfdgcPHnRNmza1SDj1zxiSeYgU0wYMA7Hzzz/fde3a1f35558R18SojFZjOJnT7iuYOv6f//zH/q1du7aJb//aQ49s9vFL1aBBA3fgwIGEnoX0diLSjIse3Fu3brXn8LzyyiuuWLFilqZetGhR9+KLL4bf+/77720s9CanPzfHXH755fasQgghhBBCiOxBqkQ3PYBJBY4GIa7+wCI9oE83KeTLli0zAd66dWtXr149E584eVeuXNnaZ/GdI928WrVqrmTJktZ+i97W9P0mHT36mtRLY9g2ePBgWyCibhpwAvdp7PgT+NdAWzKi3dRWsyF6cer3BFt9BTdS2hHov//+u4lnDN2o2fbJJbT+IkV9wIABbu3atZZ63rNnTxtnEGrdSatfvXq19SAnBX/v3r1x5477seoW3IQQQgghhBDZKL2c+lQMqajjDoKbMnWopNAKkVqISuMOvmDBAnvNz0SYceoeP3687du5c6dFtBcvXuxmzJjhpkyZYsIVcQtEjDEoI9WD72v0NYHIOD4EXkDHSy+n3pz7EWEHouXz588P992mB3csvv76a7sWEWv6bEdDtJ4+4riae1gowCgN8zfOo8UY4+NZgOg9+1iIYByxYMyxFr+UXi6EEEIIIcSxTy9PkZEaqb4IEzYcpb3AAQQN0e9WrVqlbeRC/P/mYh7cxHE1p9e2h5RzoI0YYpsIcPD7iIs+30fSuX0bsuA1AdHO+clBWrkX3LHOi9fqC3FcsWJFGzdmbkTn77zzTvs9IsWcCDp13i1atAifg6iOdkPn2YJGbtddd509czwwh3vkkUci/mNwwQUXJPucQgghhBBCiPQnRaL72WeftdTYZs2aWSQtKA7oX4w4CQoEIVILfbuDIKiD+7zApnVWWq6ZyPmpPY/FAtLXiVp/8MEH7vnnnzeHctLbST0HatVLly591HlpgfpxNiGEEEIIIUQ2E91NmjQJR/CorY0WI0JkBhiRkV7OgpAX4wsXLrToNL20E4XvMxkb6QnjIerORv02aeaksBOJzp8/v7U0owd5UpDGTo9uHwlfuXKl9fQWQgghhBBCHKd9usuXLx/+mb7BR44ciXg/qXx2IdKbNm3aWBYGdc6I0W+//db17t3bhC313IlCpsZHH31kAplIMWng9ODmeqmBiDbXI608b9689hq/g1dffdX98MMPli2CozoZI1WrVjUDtBUrVrj9+/dHpIe/8MIL1pubxYVnnnnG3ifbJKVM61JFv5tCCCGEEEJkB9GNYzQmTpMnT47popze0UIhkqJAgQJmPobL91VXXWUtwaiV7tGjR4ombv369dYKjJRvromRWVpg8QnDNRYEqKsmyv30009bGzHAyZw0c4zaGDvO6tR/0yotCEZqbPQKp36cPt84uwshhBBCCCGOU/fytm3buk8++cScl2nbRCSOtk0vvfSSiYPk0mWFyIrEcy+nXRiCN73ASf3qq682MZ4U3r2cVmEcn1ZXRbmXCyGEEEIIcezdy1PVp5sWTbRkqlu3rrkp33TTTRZVpM8wvYeFSKsoJVWciC8p3jiVE33G8btp06ZWq03E9/333w+fQ+9sWoCRFo67eNeuXa3+OXhNUrnJ0CASni9fPhPUwdRyqF27tolv/9ozYcIE28cvFb23iYgnAmNu3Lix9e1mXES6oyGt/NFHH7XoOtFujNVIaw9CjTrPQGScOcENnTRzIYQQQgghRNYmVaJ737597uKLL7afUfS8hrJly1o6rRBpZdy4cZZCvWzZMhPgrVu3dvXq1TMDv1WrVlmdNFkWlDqQZVGtWjVXsmRJt2bNGjdixAg3evRo63kdfU1ELbXVgwcPdn379jV3cVi+fLn9O3bsWLdjx47wa6C1F9HumTNn2obAJ6ODumzEdLyN90kb5/h3333XHMwR04w/CHXo9BufNGmS++KLL+w5qfHevHmzvU9NOa3Hihcvbsd99tln7vbbb49bxoGIZ9UtuAkhhBBCCCGyUU03ghtBQP/jokWLWm03UUYi4GeeeWb6j1KccFCb7Wuy6TuNyEWE+57WOIEjrhGpfO/oQz18+HCLUvOd3L59u+vSpYsd583U6NONwRpgTMbxGJ1VqlTJnXvuubaf7y9R8CC0B8P8zPfqRuxzHkZoSaWdsyCF+H/ttddMNHvhH3RUR5gj9PkXN3Mg6j179mxbEKD645577rHe3GSXeC677LK49x04cKCNTQghhBBCCJFNRTcpvkQUcTEnjZeoGwLmjz/+cEOHDk3/UYoTDgRysG/1OeecYyZjHlLOYffu3W7t2rXWH963CwMcyH/99Ve3detWWxyKviaQ7s35yUFauRfcwfMorSDNPR78juDsH+zDTWp7kSJFwq+//PJLi1gXLlz4qGg1zwwIe6LficIiRdD9nEg3ixJCCCGEEEKIbCK6H3744fDPt956q1u3bp31DkaARAsbIVJDdA94BHVwnxfYRKHTcs1Ezk/teYnAwgCLCvz+8G8QUtTh1FNPTdE1qWtnE0IIIYQQQmTTmu4g9OmmFVKdOnUkuEWmQP9qap2DRvwYjxGdDqZyJyKu07Pd3SWXXGLXpIbcg/nZd999F359zTXX2D2JnLNoFdx8mjsLWaSzCyGEEEIIIU6QSDciAafykSNHul27dpmIoM67Z8+elopLj2SRPUi0fdWxYtSoUW7JkiVmPsZ3KbpndSzatGlj48dwDVMyjMeo3SbF2tdzJwL3Q9ySmk6kGJfwWC28qLlOBCLV/C5gpkaqeN68eV337t0jxkRaOS32cDjH2RwRvmfPHhsHYrt69eqWLk5qPc/ZqlUrd8opp1jLPlLOU9Kve1qXKkm2MhBCCCGEEEJkkUj3gAEDzFgKB2gEgOfyyy93r7zySnqOT5xAUHuMaKb++P7773ctW7ZM6Dxabc2aNcuczjFgQ5gidr0RW6IgejEv4/6I3/RgyJAh1lIP3wOEM0ZtJUqUiDgGIzVEd8eOHa3emz7huKf7WnSEOc7n1IhjWEj9Om7o1JQLIYQQQgghsjY5QsGc3AQh9fWll14yR2ZSeBEDRLqp7UYQqH9w9iErRbq/+uorE6abNm2yiHJWw0e6V69ebXOWUqgFnzZtmonqY72YQX/xCt0mu5y5crsTjTk9q2f2EIQQQgghxHGI/zv7l19+STKjNFWRbvoix3JtxlwKB3ORNTl48KBFVEl7xoGbyG6QCRMmWGsqFlKoJ6ZVlXf3Zm2Gz/ypp56KOAdnbcTkhg0bkr0/bbFq1apl9+dLWb9+fStPADInvDs5CzhcE5EbD77YGI+tWLEi/N3DGbxMmTLhY2jVFXTt/vHHH+2eRJs5lrFE34NMDWrEc+XKZa3Hgm26YpVZNGvWzI7j2ZJLXYfatWvbs/nX991331EinJR6FkM8PBttwBD8mKoRzX/77beTvJ8QQgghhBAia5Aq0V28eHG3YMGCo/YjBNIrLVekP9QWUytNajLpyp9++qlbtWpV+H0WTPr162eZC++8844JUkQhIBQRmKRCB+F1uXLlkmyd5YUjInffvn02BtK4iWjfdddd9j7/zp07134mTXzHjh1JtrliRYloM8/gW28xRqLQOIID96GtnX+2KlWq2IIC312M1hD/VatWtbZeMHHiROvrTfkEbcjwLcCngN7a0dDSi3pr3kPM8zvB9YJbUIiTLu7ni2fzrxMBwT1+/HjzUPj666+te0DDhg3t+YQQQgghhBBZm1QVhSJMmjRpYhFvxNTUqVPNvAphMHPmzPQfpUgzCNHRo0db9JeyAEAwBt29EdUeos3PPfecK1mypJ2LiESA89kjiqktRsi+/vrrR0W/Y4ExGMJ48+bNYTHN9+Wyyy4zAcp9fF/qc889N+zcnRREgxHdGJvxb6VKlazE4bPPPjMxzb7OnTvbsW+++aZ9V4lk+3ZjCGCi3hxXuXJlM18j+o8TPxBZ/uabb6yUgu97cC4R3Dj3E2kP9vAOkj9//vDPPBNwv0SeLSjuEf8sSFC64T8bnpFx+UWF6HPYgmkvQgghhBBCiGwgun2tLRHLGTNmuL59+7rTTjvNhNi1115r+xA+IuuxceNGi+iWLl06vI8Ua4y7PPSKfvzxxy3STV2+70VNxJZILiISsTlmzBgT3XzeiDtctJODyDFiOxi95pqIUN5DdKcUBCcLCaR5E/VFOCNoEdE4f5Py7tO0eSZeRwtkhDNzQ+o9/2LA1qJFi/D7f/75p0XVg9x99922WPHxxx+nuId2SmHMhw4dOur3is8yXlYJkfE+ffpk6LiEEEIIIYQQGSC6L730UkuNpfURjsyINqKX5513XkouI7IgiE7Sr9lIsyYyi9jmtU+/BlzFGzVq5J555hmLFJMWnjt35phzkdZ+4MABS5GfP3++RYQR3YMGDbK6ZxYJ+M766DSu4TxbNDyrT0l/+eWXIxYmgNrxINWqVbOMAXqDV6hQIU3PQPuwaC/DoC+CH9d7771nLu1BaGsWC1qM0S4tGOlOKlVfCCGEEEIIkUVEd7Q4eP/9902siazPJZdc4k4++WS3dOnScCsqotn0WCdiTFr23r17TbB6geZNyqIFJ9kNI0aMcLNnzzaxmwiYk1H7zOavT+r2zz//bBHv1ECUnIj28OHD7dkwNGNBiIUAyhyCqddkYpBizvuxnAWJZiPSyeagb3ZStG7d2trj1axZ08RwrBTvWDBGovLRgh/X9mhzOo4F5gZxzQJIovfh+HiCXAghhBBCCHFsSVOj31R0GxOZBDXZpE5jpkbtNOKze/fuFmkFhDg9159//nnrc40QxFQtGqK+nE8dNSLX1xnHg1TvW265xQzUcCdH0NKejLTtNm3amJDEMT0euJrj5o04jwXp48OGDQungJN9gcBHYL/wwgvh47gvPbMpjaAsgvTwLVu2mB8Bdd+8JiW7ffv2di1qwkmdZ+GBxYlg5BjatWtnArpGjRq2+FS2bNlkPoH/jQ1HeO6LKGbcmA9S5059O3NJBJ2596njpMMz15inke7PfXBuxwiOxYNgrXlyTOtSJclWBkIIIYQQQohMdi/HgMqbUAX3iewBopOygNtvv93deuutJuBIufYRVwTuW2+9ZdFVIt7xDNJoLcaCS9OmTRO+N98TXNPPOussSwvn/hiCIY7TAqKdsbCoEBTiCOJg2y1S4InKs7iAURrCnEUIarq9ECV1HqM10uZZIODazEm8nuEsBiDUif4vWrQo2bE2aNDAFhuI9AdFNQ7pCH/q2kmXp61bEBY/OIZabcbNggAR9qzYy1wIIYQQQggRSY5QCsLVREVvu+22cOoqRlrUtJJuHITooTh+oeUWDuikiidXz+8j3USLSQdPKclFugHzN1qckZadlYl+lvQYN/XfPhU9HtR0E72v0G2yy5krc+rv08qcntUzewhCCCGEEELE/DubTNSkMkpTFOkmlZW0ZC7MRq9g6mD9a7+J4xPSrbdu3erq169vYpuNfaRk873IlSuXRc9j9aAmHZr6a44pU6bMUXXMyYE4xRSN8zF3Q/DHgwg34jbIHXfcEe457p+FtG3MyVg0wjzN9/xOChaaiEgzjjx58rjatWuH32NhgSg10Xwi6yxQrV+/PuFnZN5wKee6/B4RaQ/2UfcZA9TTU0/OuOkpLoQQQgghhDhOarpJuxUnLm+88YalZBOxxh0cSIueMmWKCVoMzTBqo50YohOB6I3DqCWnhhl38W7dulmKOyZuSUVp6eFNyyzc0+vWrWs151yTntVE2jk/tTz44INm5DZp0iRbOJo2bZqlbePG7x3PoyGlG5FNLTw12Ixr1qxZ9h6u6CxKUXftM0E+/PBDa8lG7Tv3Sg5Sy7kGdfUkoNAznNR1hHuw1RkRctL/qY3PmTNNtgxCCCGEEEKIDEZ/sYuEQVj7jRRpnOuJupI2jYhu2bKlpTuTTo54pN81IpyMiN69e4d7TY8bN86MyxC6RM3jgaBFFHft2tVqv6+++mrbTz9tBPKyZctM4KcUnMBZQOJfBDcQ9caNnf20HosFUWXqsoM9sP3iA3XwLDAwTpzSfeSb+nUEfiJEtx8bNWqULXDQgxzDNg9mbEnV0xPFZwumvQghhBBCCCEyB4lukWoQv4jsG2+80SKxPhqLC/eePXvcf//7X0tH9/uCLt5EgNeuXZvk9QsVKmQp7ERzMT/zTutcFzHK+akR3USzEciFCxeO2I9QxZkdgsZsLBqMHDnSaq9ZSIgF6e6Mk4h8sK83Ue6ffvopoXHt2rXL9ejRw9Lcd+/ebWM8dOiQLQ4EScrtHTBcCy4MCCGEEEIIITIPiW5x3IE4j/YHZHHA8+uvv5owXrlyZYRADortoLmZN0U49dRTM3TcZAfQK500fBYcSFNnsYI09iDRxoXRPPbYYxEtzoh0+97oQgghhBBCiGNLiozUhAhyySWXWJ01JmlBcYshGOnWQZYsWRL+mbRr6rFpf5UItNmiX7bn22+/tfT2eOfT/mzHjh3h10SMg8ZttOtiH9FkoubBjZpzCO7DJA4wgvvoo49i3pOxME7S6T0IaMYaPRfxYB4xpaOOm3p2RHeiUfIgnMdCQXATQgghhBBCZA6KdItUQ8S1devWZpJGyjg9sAcPHmwp0RiuBenbt6+lbpMujhEZDt04iicCZmvt2rVzzz33nKVwUyONA3q81HJqo4n0YnzGwsDQoUMjWo6RVn7vvfea0zhmZYhw0uER1Ajr6tVjt6eiLh0DN67pe25Td96lSxczX6tVq5aln7/00kuWak8tOu7o7E8ErkEPdNLHiU4zr+kZXZ/WpYoEuBBCCCGEEMcYRbpPYDBES1T4UmeMc3h0v2xctKljbtSokRmI4TY+Z84ca5sVfVyHDh1ciRIl3M6dO631FlHyRMAJHWGLgRj146SAY1gWj2bNmlmqNqKatlsXX3yxmbsFwTCN9zt27Gj15cwDEXoWDuLBNTBcmz59upm6Ie4xcwtek+fD9Iy0cFLcEeXJ9dH2jB492rIAmEfm07diiwbDOpzLhRBCCCGEEFmfHKHo4ldxwkATdz5+TMkSEd2ITkQh0W1qoV977TV3IsGiA47riS5UZBT/+c9/rA95dC/yeBA1p+93hW6TXc5cuV12ZE7P2NkHQgghhBBCZBb+72x0VVIlnYp0n8DwBUlEcAdZt26dW7x4sdUcCyGEEEIIIYRIGonuE5hgejntsnw6c65cuVzZsmUt3Toa0rX37dtnLamoqw4alCXF448/Hu6z7SFFmppl0sXZSMOmZhsjMBzISStv27ZthPM44yTFm1ppaspLly5tUXgPPcNZSJg5c6aljXONO++80+rM6Q9OlJjUd54VMzUP+/v16+fuvvtuuy7Xf+GFF5JtPUaKOc9AvTpp3zijw/z58+15SKUPQnT6pptuCr/+7LPP7DXXwGGccdH/3IPZGz3Qef+iiy5yEydOTGi+hRBCCCGEEFkDiW5hdO7c2U2ZMsWE6apVq8y1u0qVKiawg2AixnEIclzCEYRBUZxSMFSjPRebF5fUiL///vtW44yIZvNgokakfdKkSe6LL75w9erVc1WrVnXr168PH4PAxnSNY2bPnm2ivHbt2lZfzYZZGWZnb7/9dsRYhgwZ4q666iq3evVqM0GjBv3DDz+MOW6EMfODgGcu3nrrLTd37lwbH5QrV85qybmXh3lCNFNz7vucM3ael2ehTh0R7q/hF0boAf7JJ5/YeF988UUT4knBwgSpLsFNCCGEEEIIkTlIdAsTkCNGjDDRedttt1mLq5dfftkEMMI32sG7UqVK7oorrjCBvmvXLqtzTi3UhvvWXNRBEDFGqCJoiTrjJO7bdP3www9mVobAJTrMAgBRb6Ly7A+KW54HV3LEL5FuxCzPwrNhdEZ9OkI2CCZtiG3czXFL57xnnnkm5rhff/11d/jwYTd+/Hh3+eWXW8R7+PDhNnbmBHBwD44L8zjOqV+/vr0eOHCguagT/ca5/IYbbrDFAq7JcbRVY/GBz4KsAkzaeIbffvstyTnlupQO+E09uoUQQgghhMg8JLqFRVwRqohOD6nRtORau3ZtxAzhyu2hTRgp3NHHpAVqxRHinvPPPz8c2SWdm5RwRLFPSWebN2+ePYOHlHIEuYc2ZaSPc2xwX3TEOPhs/nW8Z2M/UXFS0T3M399//229uX2UGjd336OciD2C25+zZs0a2xd8FhYbuMbmzZvtHqTbI7Y9RYsWTbYO/7HHHjMzB78RKRdCCCGEEEJkDurTLY4J1GhHG+XHSkuPbq+FYzgiFKiXRpCvXLkyQphDUFDHukZS180oqI8nZZ5oN/XYRK2D9ec8zwMPPGB13NHQuoxId2qgJp5NCCGEEEIIkflIdAuLCtMze+HCha5QoUJhQUytcnRbKqK2vpc17cMQhsWKFUt2Fqn/xlQM4Y3gBeq4UwLp4kS6iVAHzcjSCx+RDr6O92zsJ0pNar6PXDN/LC4Q/ffcf//9liZfsGBBm+dgNgH9uL/55htLrY8FUe0///zTFhlKlixp+4iiR/dKF0IIIYQQQmRdThjRHewzndI2WZndZzmjQTTSe7tTp06WMo6oHjx4sBmSUZccFMjUdFN3TXp29+7dzQgtkb7VN998s9uzZ49dl1ppDM6I/CbVzy4a0sqJHlPnjeBFhHNNar6vvPJK258WEM2MD6M4UtQXLFjg3nvvvZjHUovNXDRp0sSc2RkHdeCNGjWyufGQLs4z9u/f3/Xt2zfiGl26dLFabYzTEOd8DohwzNuoD0e8Y7RGNJwadVLN+c5Qa58apnX531iEEEIIIYQQx44TRnRnBghDRFJ0ZJIIcrAWOCswaNAgS7dGNB44cMBdd911bs6cOebODb4vN6IUV2/cwmkBhjkYUfLkIDKM8/YTTzxhrblw7MYEbdSoUSkaJy7fmJt17NjRbdu2zcbszdHSCtdcsWKFbbRNGzp0qInmWCDKmR/mgig0r3kmzglC5Jvabp67cePGEe+xUEA9OosXRO7JAiAaftddd4WPITUdQU6rNsQ84r1nz56per7aT85xOXPldtmROT3TtqAihBBCCCFEZpEjFF1oe5ySGZHueKI7q0DaM7XRr732mssKHDlyJCEBnxFZA8HrEJVnQYE+4ukB2QJEwqdPn56mZ00ttAzDxbxCt8kS3UIIIYQQQqTz39mYFyeVUZpt3cuJcNIaCYMq0m1xkg72XaYfM+nIvIfY/v777yPOJyUYYRUEkYX4CjJmzBiL8mJMhZN2sIcyUU1aZxG1pi1TmzZtzBzLi/ymTZvaB0ANMxv3BO4RFHS0wqpVq5aZgfFh4XDt204Fx0o7Ks7lg23QoIFFpBMh+n7UCVMvTHq3j2AzvldeecX6WRO1pYVVUCTyPBzDAgJfLuaV84PQOuyMM86wtHTANZtnYZGDtHWeMfg5EAEmNX3AgAEuf/784VpoIuLcn2gz0V3S0T0IYi+w+XnLli3u4YcfDs8xNdbMYXQP7nfeecc+p+g543gi0HwGvXr1ck8//XTMvtdE5QsUKGDXKF26dIQhGtDWi+8Ac8cc8t3gc6JVGe3F+JnPkDnmO8uzAfNJJJuad8ZN6zFczYO8++67Vv/NOfT+7tOnj32GQgghhBBCiKxPthXdCG76GY8cOdJ9/fXXJrwaNmxo6bqIvTp16phzNLXIiBr6L6cU6mjbtm3rWrZsae2qEKFB0ytSh+mrzP3pWf3xxx+7zp0723v0XEboIqR27NhhG8It1uIBYnTfvn02dup5N23aFJFiDLTEQjjOnDnTNo4lJTw1fPXVV2aAhtBr1apVeD9iDpFMCne1atWsbplxRcMzkc6NmPTQ37tevXrWQ5q6a8QppmwIcUQt9dIsKlCjTJTXQz025mA8N89Fajdu3tQ/s5/ab3ptx2Lq1KlmUMaxfo65LwsSwf7YwGvEO4sCQahjZy79XCCmV61aFXEMCy2LFy92kyZNsrnhOXkOUuyBZ+NcUs35vtHHnIUEBH3lypXtPdLGaR9GvTjj9jXyXAtjOBYwMExDXFesWDE879SVM39cm3rvl156yTIouH48WCRgYSS4CSGEEEIIITKHbFnTjaigRnbu3Lnh3spEAIkqIkqI7CJyfNSSCCqi+cknn0zRfaifpc4XwePxLtIQTGnmnhyPwCJSS+ow0U2ir/ny5Yt7D0QnY6MvM5FSYDGBCDS13/5+iHPElheN1F5zblLiKx5EXKknJsrsa7Z95JmUc2B+WVBYtmyZCcxoEOSMgag20V3qrLkuz45IJjrLz4hmjNeIdCN8iXojbBGjgEgm+utTrRGk7EPU86wIdwzTYsE1SY/nuOAcs8jCogci3Pf5JvOB70sQshJGjx5t6fWIX0DsIuQ9RMAZN/8SjQcWT3gu9jNPzz//vC06+EUVMiwWLVpkiwi+tIBsBRYb+GwR+MD3lfllfL7F11NPPWWLK0TqWexhIYQFIwzb/PecmngWdzByi7cgxXlCCCGEEEKIzCdbim4ihog9IopBEDUINKKtpAAH8eI8URBC27dvt6hjPBBxCJx169ZZNJGU38OHD4eFaCKsXbvWxLYX3IAxGOKU97zoRtQHo7ReTKYnCHEPwpeIdrx7EAmn9zXRfyLLRIJZZCAqi8s27cFI/Y4WzMwPUXsP6fnB2mY+U4Q24hKxz+ZT3hOlVKlStmhB9gGCFVHNNaMj5oyD70zwu4KQD7b8YkGENmUI6eiFHxYTgIg8Y4weA6I7CGPwghtII0f4++t4+P76OeIYIunBxRXGk9T37LHHHnOPPPJI+DXfzeD3SwghhBBCCHHsyJai29dN086JOtsgRAxJT04OUsOjPeToTe1Jri0TtclEY2m1hSBCrBG5xDQLIZcSkZgICNwgRNCJfidCcs+amnsglEnXJsUc0c2/pMQjuP1nVKJECTdx4sSjzg0Kz2gXdxYWSO8mGv7BBx9YnTVRYqL+KTHAI9r9wgsvmOgmIk19ve8PnhJ4DqLppH7zbxDS5VNC9LNybRZPouvDwT8rxxC1plwiGl8XHg2/Az5yLoQQQgghhMhcsqXoJhKMqCDll1ZKsdpTBU3AYMmSJUcJP6KxiFEvxnydrRd/RJdJ4caILRpEGIKUFHZELUyePPkoYUpUMikYKzXobD4aSe0uack8Z3rAs5JqHYx8ks6eVkgxJzJNTTv17KTXe6hNfvPNN62+O6W9oRHut956q22kUCNAuX4s4RlvjqnvJwWbFHnm06dnB6EEgYWGpUuXWm9ywN2eenf/vSJSz/WJ+NPWKxZExlkUCBL9OhbMEd9BnjfawC94DJH0oJeAEEIIIYQQIvuQLUU3gpj6WczTEL5ly5Y1l3DScBF41FUjhjHJIuKJQKYeOgjO17Rxou80EVtqdDGzCgpEIqxcC+FIzS7O19yjXbt2JoKIFlPPi2Eb+zF1C4KQIlKJcMddneh3dAQcYUmKNQIW4zVS1HFBR/TRKzs9QFwOGTLEnhlhT/Q4OmqbGkjXppaasePIHUzTZh/3xCQOozPqpEk3r1mzpqU+eyf3aEjJxkiOa1NvTi02n3Ew5Tt6jufPn2/RdhZi8uTJY/s5F5FO3T2C2tdpUy5AKjjmaESqyUzge0KKN58zPbP9IgqQVs6zkDbPdwoRzveGz5R0fNLYWVxg4QbHcr4LLBDwXUouss5nT9kDtfV8D7kXJQ1kcDBGPn8+KzIqeAa+p4yNlHPM8IKLHIkwrUuVFC+ACCGEEEIIIU5Q93LMpHr27Gk11USLqf1FrCD+ECi4RGNIhdhFDGN4FYRzMPoiBZljMLSKdhcnOooQ5jjEFeLHO1ZzDiILc7bLL7/c0qgZSxDMvBDtpF0TbUZYRYMww3QMkYjQRIhRz4yQSy8QjYAwrV69uok8hHhaYewYryEC/T08RP1pe8ZngfhlvhG4iPCgY3o0RLUxU6N1Fufw2b3xxhvh1mbRIOhJ9ed5gmnrwP3IZAieS630Tz/9FH7NwgARbMQyc88CDmnxQUhPR3Rjqof4Z/6IZPNsLGKQRcB3hO8D3wsWcFgQipf+HZw/FhX43PmO8N298cYbTdyzmANVqlSxhQhS7anvL1OmjJnWUR8uhBBCCCGEyPrkCEUX+4rjDmqGSZEndTolddFpgcwCoszevTszoK95s2bNTOR7EXusaNGihRns0fIrORDrCG0WAMgWoNUYCwlkBaQHlBNgcleh22SXM1f6eg0cK+b0rJ7ZQxBCCCGEECLm39lkXSeVUZptI90nMqRbE1UnMorhG9FVWkx5iJ6Sqsx7iG0EXBBSu2nvFYSIfnRd8ZgxYyxKTNo2hl+kZAeFImnxmIMR7SUl3hvcIfIxLuPLRzSXzaeTcw/u5aEun+g3qd58UekTToQ8eqwIaM7lS03EnlT/eODqTUSbPua0+WJdibFzLunnZEgE15q4NqncvvXYPffcE+HazmIFkXwi6czppZdeGu4DztzyfES2ifjjrN+tWzdrRUbPca5JJD3o2B6Ea/fo0cNaiXFfIvakrXvBjQBnXoKfL5DFwdwnNQ9CCCGEEEKIzEeiOxuC4EakkXr94YcfWkSVPtMIQmrGSSHHKA0xSCo0Dt4pZcSIEa5t27bWK5q2WRjTBc28qC3GpAwTNVpzUceMcZlPq0dYIxZJvWaLTt33iwcIbnpjz5s3z56Fem5SrYMgWBGZpFmzcSyCOh6k8RctWtQENCngjA+zMkoIhg0bZgsG9Ab3UJtPuQKimfsgpOlZ7kGkY8ZGnTZt3JgbXzvuYR4wlaPUgPuzEEKUGz8Bou3U6seCZ2Yetm3bZun01J6z8ICxHiCsWWTwIt/Da2q8g23kgu3MWHULbkIIIYQQQojMIVsaqZ3IIKioT6dHOCZciDkEH9FV+jsj2ngPgQhEhxG91J6nBEy6qGHu0KFDeJ/vGQ6kjnu4B8eTxk1tM47iRJUR/QjfeGBGhqBngcA7t7OYQHSdmml/P0Qp6epeYDZq1MjODfauDkJ03EfWvXkcddCMh5ps7slrUsABUeyhnp7FBO5N5J4IPNF4DNS8sV0sp3GENhF5PodJkyaZwPct2KJ7fAdhkYHn4zNlQYB5I/KNgP/iiy9sLjEDZCGDz9H3Zyebgc853qIMbcaEEEIIIYQQmY8i3dkM0pdJn0aUIQip0UbsEaFFjNGCinRmotJsRHgR5ymB6+CijdN3PBB8vE+fdMQwQnjv3r02tkQhaowg9oIbaJPGM/GeB5EbjOh64ZkomI8FncSZDwzxfKsxotEYqREV5z6+XRhiG+jFjpBmnonmL1q0KO69aDvH/Ef3PI8HgptIO0If0zTGinEc4/vkk0/smFKlStlCBBF7eO2118xIDQO2WDz22GOW2u83HzUXQgghhBBCHHskurMZvm4ap3YEnt9If46u+40HqeHR/nkIPw9p6klB+jVO7tQe4xKPaMUFHo4cOeLSm2gBi4BGrKYH1EwjdkmFx4GeCPu0adMinoV2cbQ7o27bL0bESpdPZO6iYQEBgj3ZqR0nfd2LfiDa7dvekVpOzXy8lmTU4PM8wU0IIYQQQgiROUh0ZzMQZ4gqBJmPZvuNiDF1waQ2B1myZEnEa0QdEfGg8Ea4e4j2El0mhTsWiGxEL47bRGZ9f+kgpEX7SHI8GCtR2GAklsUDHM+DIjStLF269Kj5wAyNXuXUwxOhp0acCDW14LGi6MwZLeSIMlOvPmrUqJj3YiGCWu7gIkZS0CIMvv322/A+atxpaxZsC9awYUMT/kTEmSPGIoQQQgghhMgG0DJMZC+6d+8eOuecc0KvvvpqaMOGDaGVK1eGnnvuOXu9ZcuW0CmnnBJ69NFHQ+vWrQtNnDgxlC9fPtR1aP/+/Xb+N998E8qRI0do0KBBdv7w4cNDZ511VqhQoULhe3CtXLlyhYYNGxb67rvvwveAzz//3K737LPPhjZu3BgaP358qECBAhH3WLhwob2eO3duaM+ePaGDBw/a/n/+85+hcuXK2c9///136Oqrrw7ddNNNdv2lS5eGSpQoESpfvnx4HL179w5dddVVEc//zDPPRIw1KbjW6aefHnr44YdtPrj3SSedFBo5cqS9v3v3bpuvTp062bO8++67ocKFC9vYV69ebcf07Nkz9M4774TWr18f+uqrr0I1atQIlSpVyt7bvHlzxLE//fSTfTZ16tQJLV++3OaO+eHeMHXq1FCRIkUixlirVq3QZZddZnP25Zdf2vWLFy8eOnLkSMRx99xzj421atWqoZTwyy+/2Bj5VwghhBBCCJE+JPp3tiLd2RCctnHUxjCLaHHVqlUt3ZwWYtQlk/JNjTcO2jicY9IVhHMwPCMlnGOIjEenSxNJJaLLcdQTk05OnTFwDg7gmLPh1k1aNmMJgvEXxmo4kRMlxmgsGtKj3333XXfWWWdZffKtt95qRmZvvvlmus5X48aNzWSO2mjMyTCHw5UdGBtp22+99ZZF14l4P/XUU0dF7amTJorNOImQU+Mdi3POOcec3CkDoDa8RIkS7uWXXw6nyFNjHYxqe/M4+nPjOs85HDt79uyj0uqbN29uKe9B4zchhBBCCCFE1iYHyjuzByFOHHATx5As2KtbJAb9xH1dOQsBiULLMFzRK3Sb7HLmyp0tp3tOz+qZPQQhhBBCCCFi/p1NYC0pHyVFusUxh3pwXMDPPvtsaynm23sBter07saZnS8uPat37doVfp/+2fQeD0L7MsS8B0O5K664wkzNiDwTQccwLdb5nNe+ffu44wHqvsuWLety5cpl0XCc24nSk02QHBUqVHAPPvhgxL49e/aYaPY187SBI9MAJ3j6chP1/vTTTyPuz3UYO7/YtC+jZZgQQgghhBAi66M+3eKYQ+urRx55xAzOFi9ebGISQzFcwb3gnjdvnvUgb9u2raWoB0VoUKAjghGtCHnO419SyRG1pHkj3DE2SyqhI954aMuGGRwinbR93j9w4ID1L08UXMcR3ZjOYYAHmLEhsBHSwPuYo5Gynj9/fnNPp2SAfuIYvtWsWdNaxdE7/JVXXjFDNZ5VCCGEEEIIkfWR6BbHHGqje/fubT8jKocPHx6O+iI0N2/eHO7dTb0zNeW08kJ0BkGg4rrev39/6+tNbfnXX39tIvmDDz6wiDF9yol6p2Y8iO4PP/zQbdy40UQ/UXAYMGCAvZcIderUMVFN7TpRe6CGHGFPtJyFA1qA8S/PA0S9qelmP/X4RNgZnx9jcs/DIgSbh+i4EEIIIYQQInNQerk45iByo3tV06YL4YzY9oIbiGSfeeaZ9l40CGpapfE+qeT8jOEbEfPbb7/d3X333WZitn///lSNBzA9YzxecAOGbImCYG7UqJEbM2aMvV61apX76quvTHT7RQai6bRdI3rtNyL9iH0g/Z2FBaLvCG/M4JICUztqS/wWnE8hhBBCCCHEsUWiWxxzol25ifiSFp4I//jHP45KFQ/2xMZZnOj0+++/b4L9+eefd0WKFLHoeUaMJ9EUc8a0detWi16TVu57cONyzpjpfU7U3m8sMgwbNix8/qZNm0y8I9Kvu+46e6544LSOmYPfgn3QhRBCCCGEEMcWiW6RZaCVGQIxKBKpdf75559NQPsWXzt27Ig4D5EaLZqJCvfp08etXr3a6rupk04NCHbGEzRzI9U9JZAOjlAm6v76669HtPzCFI1IN5F1IvXBLRhdJ1pNC7apU6daTTnXige149SyBzchhBBCCCFE5qCa7hOYrNa+i2gukWxMyxCW1EC3adPGelcjWoEo8ZAhQ6zW+/rrrzdTMtK1Ea+A2Rn12JUrV3Z58+a117iF/3/tnQeYFFX2vq+KgriuPwQRgRWBRVkTChIETCigomTUBQURRREUxYCAAwaQqEiQoCKrGIgikk0sghIWQVFEwBUzSVhd1sSi/X/es8/tf3XR09MzTE9P+N7nqZ3pquqqW7dbdr57zvkOgj4nULtdtWpVG8vbb79tkeqJEydGxX12DdVwJ2/VqpXtwyUdB/QOHTpYL3HM1ngOxsszkPZO727c2S+77DJLQSdVfsmSJTl6ntm9m0qACyGEEEIIkcco0i3yBfv27XO33Xabu//++00wjx8/3lp9ValSxU2bNi16XtOmTV1GRoa1+MJYDTdxBKuHqC7i+PLLLzeRyvUQs4jWnEDqN8LYtxwjet6vX79ovXaydO3a1X5SZx5+H0KeZ2Chgcg6RnBE01l8ACLhuLgjtHE157nGjRuXo+cRQgghhBBC5C2HRBL1UhKFmvwU6SZaTRo20e7KlSu7/Mbnn39u4yJdHQFO327aeBEFTwai4mxr1qxxNWvWjIl0h9PjcxvcyzFUa9R3uitWoqQriCzOaJbuIQghhBBCCBH372x8lBKVdCrSXURAKBJNxRkbd26iv0GmTJliKdxHH3201RK3b98+6uDNugw1xiNGjIh5D2IRIYn4zApaYvke3HwhSdf2ddK00PJtsIhsc01EbmbwpSYCjYAFTM+OPfZYV69eveg5pJ0HXbupy+aeOJ1zLmMJ34Me2ESTiURXr149Gk2mHpxe37By5UqLWtevX99ah3Eez5YZmLz5cTCPtWrVcieddNIBc88+/oO95pprLHrvYX94UYSFEgS7EEIIIYQQIv8j0V1EuOeee6wNFf2i6WFN32naVwXF4cMPP+w++OADi74iSH1bK0Qw5l+kQQfh9fnnn2+CPBGIYkTunj17bAw4eRPRvvrqq+04P9944w37ffXq1WaUlqjNFeIU4ckzAI7ejJEoNG7gwH2oBffPRlo6CwqI53feecfEP6napLUDPb779+9vQhrncPpjk8b+7LPPmgjmGPCTSHWpUqVs0aFNmzZm8hZs9+U3Utq5F67lwPzybEEjNtqCMd/z5s2zjXEPGTIkG5+sEEIIIYQQIj8jI7UiAEJ00qRJFv2lhzUgJitWrBg9J+ioTbR59OjRVjPNexGQCHAEJ6KYPtUIWZy4w9HveGAKhjCmbZcX0xihnXbaaSZAuU/p0qWj7uRB1+5EqfGI7rvvvtt+Ynj2ySefuOXLl5uYZh9130BNOMKfSLY3P2PBgKg351FDTv9rov+tW7e246SS45yOadq7775riwvswz2cKPOvv/5qhmbUW3fu3DnuGOkdXqFCBYtwc9/TTz/9gGdjXET6WRAA2oIxX4j/nMLY2IJpL0IIIYQQQoj0INFdBCCaSkS3bt260X2kWGPa5aFPNGKSSDcO2b5PNanTRHLLly9vTtrPPPOMie65c+easGvXrl2W9ydyjNgORq+5JqKXY4ju7EIUm4UERC/RYYQzghYRjes3Ke8Ic+CZeO2FreeXX36xuSH1np9dunRxN910U/T4/v37LaoeBCM0FiveeustE9V+LnMK6ePBcZH679P6c8rgwYPN8E0IIYQQQgiRfpReLkx0kn5NrTVp1kSffV9rn37t215NnTrV/fzzzxYpJi28ZMn0GHMReSbtmxR53MoR2D76jQhnkaBatWp2LtF6aqlJBw9umzdvttp1n5JO7+vgcczdqOEOgiv6+vXr3YoVK3LlOQ4//PCY10TE/YIH0EIt7HVIlkEi+vTpY3Xvfgv2PRdCCCGEEELkLYp0FwFw2Ebc0bPat6Eimo3oJGJMWvbu3butlthHo71JWVhw0meadl6LFi0ysZsMmJMh/Nj89Und/v777y3inROIkhPRHjt2rD0bhmb05WYhgNpoX88N1GCTYs7xeK6CRLMR6dSZ0zM7Ed26dbM08ebNm7v58+fH3CcRjJGofHYh3Z468GCqOGn6iShevLhtQgghhBBCiPQj0V0EoCab1GnM1KidRnzSa5ooKiDEjzjiCDdmzBh3yy23WIQX068wOIZT200klSjyueeem9T96beNOzmCFidu0rZvvfVWE6w4pucUItuMuW3bttE0bwQ+AvuJJ56Insd9hw8fbmZuDz30kKWHf/HFF1afTd03r0nHvv32202AUxNO6jwLDyxO9OrVK+a+9BNHQF9xxRVu4cKF1j4smTRyarUbNGhgghgjtmRo1KiR1XxfeeWVttBAXT2fQ06Y3ft/2QxCCCGEEEKIvEPp5UUEROd5551n4g0RjFAk5dpHUxF2M2bMsMgzEe/MDNIQ76ScZ2YeFg9SpnFNR2iSFs79MWtDHB8MiHbEr6/dBn4P7yMFnqg8iwsYpSHMeQ5qur0IJXUeozXS5lkg4NrMSWY9w++44w4T6kT/MVrLCkzacG0n0n/22Wcn/YwscDAWBD419S1btky6N7gQQgghhBAi/RwSCReMChGAyDZp4LS1Alpu4YBOqvjxxx+vuSoAkJJOBL9R3+muWIn01OAfLIszmqV7CEIIIYQQQsT9OxsfpUQZpUovF0lBuvWuXbvM4RzHcgluIYQQQgghhMgapZcXYEih7tGjh22ssJQpU8ZlZGRE3a6pR+7YsaOldZNifdlll7ktW7ZE34+APuuss2KuSc019cf+OP28SQ0vUaKEpUYT4R42bJj7+uuvrX0WddQco86YFlrUj7NRt0zNOKnltCabMmVKzH3YTw9s0qYZGynfOIL7Vl+8l2tyzF+TjXsxPn6Sok6KNzXiWcGc8DykmDM2jNOo4Q6Ox0fzPdRQk2LuCT4zhnLUo2NOh+O7Hxtj5lpsxYoVs17kftGCnuL07ea9tG/Dad1DjTmp/3xWHOd9CxYsiH6O1KVTBsAcU09PGrwQQgghhBAi/6NIdwEHUUx98urVq834q2vXriYs6TdNajgi+9VXX7V0h969e1sNMs7h4VZV8UAk0kebtAkv8hCc1HTXqFHDBCTXRnBSM02PaeqVX3vtNat5HjBggNVwr1u3zmrAMSy76KKLotfHrO2xxx6zjbHRvgshTR0ziwfcn3HTjxtoZcbz3XfffdaXm97avAbulYhZs2a5kSNHWsszBO327dutf3ey0FaM2mr/zPQEp10Z7b1wMv/pp5/M2RyDOGqvaetF6zJM14CFEead+yP4acmGYduHH35oIrp79+42r8wjoptzmVdgLniNaRsLKyxM0LYtMxD4bB4+PyGEEEIIIUR6kOgu4BB9Rkz6iDIijtdEixGH77zzjqtfv76dS0SW84nokiKeFYg+IqsIOESmh+gvqeaIYEQ4BCPmnTp1MsHvhTBCm37XmLMFRTdC/KqrrrLfEd24oSMw6Rnu93HOn//8Z3uNs3rfvn3tJyDQEe44kGclur/88kt7BkzcWHBgYaJOnTpJz/OLL754wDP7cQGLEtdcc425qXuIXPt7c5yfCG5gQYG2a+x/5JFH7FibNm3MxM0/W3DsLGZ4p3efiZAZgwcPtgwAIYQQQgghRPpRenkBp169eia4PQhXottERklvJo3ZQ7swhDnR64Ph/fffNxHoxWcYrk9rrCC8Dt+XPtseXyPuRaffh8O4j9QSmablVzDdnIg+fayJNCeCRQaiw4hZ3kOkOZm09GSfmeMYzMWDhRAc1U8++eSYsRMJJ1oPpLoPHDjQ5okFhPXr10ffTwSdCDkLGywwZOWWTqYAZg5+oyRACCGEEEIIkR4kuosw1E2HzetJi84Kot+5QTDF3S8cxNtHCrdP8SaCi8D1G4KWRQbqqRNBhH/Tpk1u3LhxNn7SwEl998/LvRLNRVbPnOg446bW+7333osZO4sQo0aNirYs++yzz9x1111nz0RU20fNqcWn5vvOO+903377rYl7IuWZQc06afnBTQghhBBCCJEeJLoLOBh5BSGNmxph+m0TyQ0e3717twlPjgHGXNQ2B8UmYjDIEUccYVHacISa8/bs2RN3TJiikdYehNf+vjmlZs2aNn7SusMbCwhZgTAm5Xv06NFmYoZxGwLXzwURcw9CPhg9z+qZOf7mm2/GPUaEnDncuXPnAeMOpu2zMEDq/Msvv+zuuusu99RTT0WPMT7S9p9//nkzu3vyySeTnDUhhBBCCCFEOlFNdwGHet9evXq5m2++2Yy9iI4++uijJrxbtGhhqdS4hB999NFmQIYRGPuBum/qlHEjb9u2rdUYY9YVjIxSP7x48WITu6Sn45KOgzfp0KRL42yOgRpmadQrk95+zz33WK02YpMaamrMZ8yY4ebOnXtQz9q/f39zO6cem/EitEk5/+ijjyw1OxHUoSN8SbfHER3xyvsRrxMmTHCNGjVyY8eOtfFzHvXkwag7z0ztdcuWLa1m2j8zixaYpPFszGvVqlWttpsFD9zHuQ7zhPs4TvKYpNWuXdtSxhHpiHWM1zCeI6LNubiVL1myxBYv/HPXqlXLDOCor583b170WHaY3bupot5CCCGEEELkNRFRYLngggsit956a+SWW26J/PGPf4yUKlUq0rdv38jvv/9ux/fs2RO57rrrIsccc0zkyCOPjDRt2jSyefPmmGuMHz8+8qc//Sly1FFHRTp27BgZNGhQpFKlStHjO3fujDRu3Djyhz/8gXB4ZMmSJbZ//fr1kSuvvNLuW7Jkycg555wTWbVqVfR948aNi1SpUiVy+OGHRypWrGjv/de//hU9zuvZs2dHX2/dutX2rVu3LrqPe7HviSeesGeARYsWRerXr2/Pw73r1KkTefLJJ7OcK+5Vt25dew/PWq9evciZZ54Z6dmzpx3/5ptvIk2aNLFj1apViyxYsMDuOXny5Og1Pv/880ibNm1innn58uWRbdu22ZzPmjUrctZZZ0WOOOKISJkyZSKtW7eOvnffvn2R/v3721wXK1YscsIJJ0RatWpl8wg9evSIVK1aNVK8ePHIcccdZ5/bd999Z8cefvjhyF/+8hd75mOPPTbSokWLyGeffRZJlh9++MHmkZ9CCCGEEEKI3CHZv7MP4X/yXOmLXIFINeZapBvnZ0jlxrWcCC69r7MLUWoiwd9//32RnL+DBSM6MhQa9Z3uipUomZYxLM5olpb7CiGEEEIIkeq/szEvTuSjpJpukSNoCUaqNZDyTLp52bJlzdCsYcOG1lorDHXdpFNzDq7rpIUnI9hpG8YXGbMztgceeCB6XwzFSJknbZvUcc4P3xNxTUp5qVKlrB0Z4t+DSRuO4LiSU1/tr+3hfk8//bRr1aqVXYO0fVqxBcfHOcEFgUT3ZD8LCJ4pU6aYaRrp/9yfXuXUfoevTyo653FNWsCR7i+EEEIIIYTI/0h0i4MG0Tpr1iz37LPPWl05BmEIzbDpGLXe1JsjyDEGw9QsK7d0BCaRaFaOMDpj887d1FJjhkY7Lfp1Y3RGRB1h6nuMswBA+y3OW758ud0zaAzHmBHsGM5R205Lstdffz1mDDimU6POdS6//HKrz87MUM23DsM0LrN7BuH5GTu16fRP//zzz21BI0y/fv1s7tasWWOt4G644YZM54zFCFbdgpsQQgghhBAiPchIrQATjuqmgx9//NGNHz/eUsAxAgNctxGukyZNMqHtof9048aNo2K3YsWK1i8bQZsZuKeTskG0N+j0jYHc5MmT7ScGbqSJN2/e3By+iabj/k2LLUQ6CwKVKlWy92FGFoRzGRcQxcZMjaiyHycggjFSA8zUcD9fvXq1u/TSSw8YL8KdiDStyTzhewYJimd6iHNtjNZoM8bCgWfQoEHuggsusN8xxMN8jR7m8VqlYfTGQoEQQgghhBAi/SjSLQ6Kf/7znxatbdCgQXQfrt916tSxPtRBcAb3kM59yimnHHBOstDqi+gxbt+IU9zEEd6IYaLQRNsZG+LUC+54ILqDcJ1genf4HKLiRN3D54Qj3clC724i4Tiyk2LuhTWLCZmNgTFCZmPo06ePpeP77auvvkp6PEIIIYQQQojcRZFuUSAhEnzYYYeZaOVnEB8hJr08K4JtwYCIOnXe2T3Hk8w9g1kCpOGzvfDCC5Zyj9jm9b59+zIdA/eHzMZQvHhx24QQQgghhBDpR5FucVDQl5oUcMzDPES+qdumrjnIypUro79jLLZ58+ak+k1z/XBNND3A2Ue0l6h2cPNp6ESHSRXPS7Jzz08++cTt3r3bDRkyxJ133nmuevXqmUavhRBCCCGEEAUTRbqLCNQl47CNWVdutvgi3bpbt25Wu03KOGnS1DX/9NNPrkuXLjHnYlJWunRpd/zxx5sxWJkyZaIO6Ik46aSTLLKNmK1Ro4YZpZFWjqFZx44dzWAMEb5r1y47B+FLWjlp1meccYa79dZb3S233GLifcmSJa5du3Z271SQnXsyVxwfM2aMnYubO6ZqqWJ276YJWxkIIYQQQgghch9FuosIo0aNMrOzVECktk2bNu66665zNWvWdJ9++qlbvHixtcsKn9ezZ09Xq1Ytt337djd37lwTnfHAxZs0amqkcTBHlF599dWWgo2oB4zUEN2YplEfjoAnwo6YBYT5a6+9Zs7g1JhTUz5nzhxz/04V2bknz8JnMmPGDMsKYH5GjBiRsrEJIYQQQggh8p5DIpFIJA33FfmYZCLduHlTS/3888+nZAyI7sqVK7t169aZQVpmUPucmXA/WFJ57bwcHy3DcIBv1He6K1aipEsHizOapeW+QgghhBBCpAr/dzbmxYkyShXpLkLp5T6Vmz7Ot99+uytbtqy1nKKXNRHiMNRpk6rNOfXq1bP05/3797uPP/7YelAnaoVFf2rqlDEW+9Of/mT3wzgsmDJO+y1aZuHaTXT6ySefjB5HcANp40S8L7zwwpjnoIUWrcKIcAMO3bQeY5GANPcWLVqYcA8/P620iDDzHwXR86BhGfeg9/cdd9xhqeAYmgHPTTs0DNpIjSei/91338W8j+ejXzn3pqb8gQceiJkPUvtvvPHG6L0bNWpk0fB4n4+HcfjnTjQ+IYQQQgghRP5ForsIgjikdzW9steuXWvmYwg4Wm0FoU6bemkEOWKR1lZEnulDjeBGtMaDVl30sCblfP369W7atGkmwhGMQbg210JYk25+8803W7024tb3n0aU02v75Zdfjr6Puu1NmzZZL/B58+aZcRvjR7wvW7bMFgu4BmMIimreR4syIvkvvfSSXTPcz5o58cZwEyZMMLGMQGaMa9ascYsWLXI7duw4oLc476O+fdWqVZb+Tv064/NQ041J2sKFC81xnTR8WouF5zwrwuOLB4sqrLoFNyGEEEIIIUR6kJFaEYNo8/jx462WmOgtPPXUUyYQJ02aZELbM2DAANe4ceOo2KtYsaLbunWrmaQlYvDgwWZyRkQWqlWr5kaPHm09qLm3F9SXX365GY4Rleaa1D8TMW7fvr37+uuvLcWdmm3vRu5B3D799NPR1GpS3GmfxT7fTot6b6LeCOwmTZrYPs5/5plnTNizaIAw5nkxLzv00EOjY/U14zBw4EAT3ETlPVyD6D3u69RwAxkBzJe/xtixY03kM38sONA/HNHtW3lRu42p3cyZM13Xrl2T/vzC48ts/sOLCUIIIYQQQoj0INFdxCAKTWS4QYMGMT2gMf0iChwEEewhbZpU7vA58SBtmgg3vac9WAcgjBHtvk0YQhUqVKgQ85PIuzceo0YiDO7gwVpm7od5G5HuIL/88os9r8c7nwefD1d0UtMrVapk+zB5Cz8L7uO+93cQrh0U3UFOOOGEaPsvrsF9cG4P8vPPP8eMLxnC48vMQb1Xr17R10S6WSQQQgghhBBC5D0S3SLXQWCSKk7UOox3FvdiPwhRaoR5VhDpDt8PMRoU+R7S4rNDvGuTVj906NADzkVYJ/MsXINzibqH8UZ1RNrDnoYsjmQ1vngQTfcRdSGEEEIIIUR6keguYlStWjVaE+yju4g76rZ9Orhn5cqVUZGMkznp1D5KnQjqlTFbI2KdU3wk+7fffkvqftSNYwyXyDWQiDPRZczd/PMRwU4UBeba1L9j/JbTVmNcg5p13s914sHiAIZtQWiXFhbzQgghhBBCiIKFRHcRg0hpt27drJaZlHFENTXC1FR36dIl5lxqnkmJxrG7X79+5pgddtiOR+/evc3tHOM0HLu5JyKcunFqncPg3I1hWRAENOIY4zJqyakDJ9Uc8UoPcM73UWLqx4cPH2614YyZ87/44gszSsM0jteAqRrPeP/995uzOTXYjNHXc8eje/fuVvNOizTvTk4q+9SpU62GnLZpmUEdPPPFuEhl53fmmpT0b7/91s2fP9+1atXKzOQwa+MZnnvuOTuXOnVEOPXkucXs3k0TLkoIIYQQQgghch+5lxdBhgwZYs7itL4iCouIRMiWKlXqgPN69uxpqduI3blz5ybVF5r65qVLl1pknLZhCMf+/ftbi694jBo1yozdghAVxnxt4sSJ9j6Ea2ZQp/3222/bAkLr1q0tGo+4pqY7KDJxC8eI7Pzzz3dXX321a968eUxrL4Q8YwkuAHBvsgKIuGPIRj05GQEI/kRiPZxqvmDBArtv586dTXRfc801tjDAggbgvp6RkWHCvnbt2m7v3r1mIhcGE7fHH388qfsKIYQQQggh0s8hkXAhqSiUEKklKksEtSBDXTSu5qS7+0h3MvhoOo7huX3tRGJ79uzZSWUHJAvp6Yj+cClAIjBSI0ugUd/prliJ/28kl5cszmiWlvsKIYQQQgiRKvzf2T/88EPCjFJFugs5+/fvt9TuFStWWJus/AiC2AtTekxjwEZ6OSnlDRs2tHrzMESfiahzDqns4XrozCC6jDEaUX3S3pkTotCkmyO4gWMIZsblhW44unzWWWfFRMm3bNlikWzGc+qpp8b06Pbgkk5/bwQ9aepE77lveB5oJ4bxGqn9pLd7Q7ULL7zQxn/nnXfa+Hx7NCGEEEIIIUT+RaK7kIMYpWYYcXnLLbfkyjXp740BWbwt2M86J5BejXEZ9dBr1641MzZSr/fs2RNzHjXpjz76qAlyTMgQ0vHcvsMgYhH2pKN/+OGH5kruzdS4L2zatMlt27bNUs2TAZdy0tpJvV+1apWbMGGC1bUHYWw8B23Nli1bZosG3PfSSy+1WnMP7cloI8ZP5oC0e596T4069enUrTM+NiGEEEIIIUT+RkZqhRwispik5SYYiOECHg8iuDnlxx9/dOPHjzeRibAHTMyIGk+aNMmEtgcTtMaNG9vviFPEKKncRJLj4YUr0XHq2anNhipVqhwwdqLs2Ukvf+ONN9wnn3xidfG+bp3FB/8MgLs64py58xHqyZMn231Ia6de3EfZMZujFKB69equWbNm7s0333Q33XSTjY/9CPdy5cplOh4WFdiCaS9CCCGEEEKI9CDRLbJNhQoVUjJrRHiJCDdo0CC6j5ZZderUcRs3bow5F4dvD2L0lFNOOeCceJC6jnv7a6+95i655BIT4Ajxg4H7EikPGsUFx+fblWFYh2AOgtkbz+0hIyHoiE6aORH57DB48GD34IMP5uBJhBBCCCGEELmN0stFkYIWZp999pk5tyNmSb0fM2ZMwvfgUh72G0wmlT3If/7zH3OBp/d2cMPhvX379tHzwn25iYoTIc8Offr0MTMHv1FLLoQQQgghhEgPEt0i31C1alWri6beOShuqdvGnCzIypUro7/jNo54pVVYMhCVpr6dGum77rrLUtjBt0OjPVgQasaD9dOka2/dujX6mvsibIPnBMcHtGbDbI3UderUgxuOh8nCGMPjC1O8eHFzTwxuQgghhBBCiPSg9HKR52TW9go3cVK/qd0mZZy+28OGDbOadPpuB8FMjFTxTp06WT11mTJlkmrNxT2ptaZXNmIdwzIv1itVqmSR5Xnz5rnLL7/cHXnkkWZ21qhRI6sJx6yNGmx6jgdTwElT53qMZfjw4SbK+/XrF3PfDh06mMCnhpzac2rQcSJH+GMex+tkQEDffffd9gwIeJ47WWb3bioBLoQQQgghRB6jSLfIc4hcd+3aNfoaIzQfJR4yZIjVWZP+TXSYOmgMyjAYC8J5OJrjYL59+3Y3d+7caKQ6EUSJcTBHaOMcjlgeN25ctFadWuj77rvPHX/88a5Hjx7RdO0LLrjAXXHFFWZshrgnKh9MP0dIYy5H/Tkp7IMGDYq5b8mSJd2aNWvM/A2nc+7PQgI13dmJRN9www328+yzz7YIvBBCCCGEECJ/c0gkXKwqRIqgNVY8YUx0mR7XS5cuzZWIeX57RoQ+z4g4P1hwOqefOFH6ZB3WibyTwt6o73RXrERJlw4WZzRLy32FEEIIIYRIFf7vbHyUEgXSFOkWxoUXXuhuu+02E7BElYn0UutMG6/OnTub6zb1xwsXLowKSSK1lStXtjRs3MPDfa2vv/56iwoT9cXZm3O8WH788cfd/v37o07o9M1GmHIMcPRu0aKFjYMU79q1a1trrpzCtSdOnGjRaqLORJpXrFhhkXSendT2+vXrxziJJzMGxvvwww+7jh072n9oRPBJRUcQv/rqq1aLTo31l19+GZ0PDwZpOI37OaxRo4abOXNmzPUXLFhg0XiOI7Y///xzfWOFEEIIIYQoQEh0i5g0b2qEV69ebQKc+up27dqZGF27dq31kibtmxprBCN1yDNmzHAff/yx1Tn37dvXTZ8+PWZG6TG9adMm67VNrXSQjz76yFLEgd7UpJiTeu7dvqmr5v3r1q2zVHBqqhGviaDWGYEc3oDaacQxruH0wMY1/Oabb7b0cVK/SfrwKeXZGcOIESNMMHNORkaG7WOOhg4dan25N2zYYPXXYRDczz33nJswYYKdc+edd7prr702GvHHnI1UdO7JmElbJ/VdCCGEEEIIUXBQerkwiPYSvV62bJm95ndSJRB9CEOgdpq+0USI69Wrd8DMIVg5x0driewuWrTIRGow5TqcFk4UmprorIzQTj/9dHMd98I4Xnr5N998Y7XVYapVq2ZGZghk7y5OL+1JkyZF66SnTp1qUf147080BuqrGb+HSDfXQSgjxj3Mx/fff+9eeeUV9+uvv5pZHJHzYE9vhDWC/cUXX7RFjDlz5pgg9yC6EfOJ0su5Nlsw7QXHdqWXCyGEEEIIkffp5XIvF1HOPPPM6O+4c5cuXdqdccYZ0X2kWcPOnTvt5xNPPOGeeeYZE9UIVeqZzzrrrJgZ5f3JGJyFIcr8wAMPuPnz51sEnFR07pFVpNunq8ejbt26BzxL+PkwNuM/Hv6jSXYM9PoOwzMH5zMMae2Ia4zVgjCHiHjYuHFjzJghKNAzgwg6hnBCCCGEEEKI9CPRLaIcfvjhMbNBBDq4j9dAajlRYVpX4R6OEKTmm3ZZq1atirkGtdI5gWuTkk5kmlpyaprbtm1rojSnxHuWzJ4vO2OI94yc668XDwQ9IOjDCwXUgB8MpMv36tXrgEi3EEIIIYQQIu+R6BY54p133rFa71tvvTW6L2hClh0QvqSzh69POnarVq2iIjWvTcRSOYagwRrtyOKB2RtmbEFIi88Krnuwwl0IIYQQQgiRO8hITeQIaqQxH6OH9ubNm81AzJugZRfqojErox6cWmV//Zdfftnqoj/44AMzPfMR6LwilWMgM4BIOuZpGNixYIFZ3ZgxY+w1UDu+ZcsWd88995gZHXXe1IsLIYQQQgghCg6KdIscges3bt1XX321pVH/9a9/tai3bynmee2116w9WKJe2qSokw5NizJSrYkmP/bYY2ZwRjQdR3Val8VzAM8OpL5j1sb1adOVFeEx9O7d21K1cwtajR133HFWg/3ZZ5+ZMVrNmjXNQA1OPPFEN2vWLBPmiPE6deq4Rx55xMY0fvx4SyPPDrN7N01o8CCEEEIIIYTIfeReLlLKrl27rOaZ3tjZcSoPE8+pPDsE70sqO+NCSBcrVvDWnbI7F95VUe7lQgghhBBC5B5yLxdpBbMxHLyJ5OY3cGYvV65cnjy/EEIIIYQQomijmu4i2pP7tttus0hpqVKlrFUWqd2kcNNfmnpj3Lp9qjiR4S5dulhKNq7cp5xyihs1alTMNTEcI4o8aNAgV758eTvHR2VJL/e/A8ZkRJ79a+qZW7RoYeP4wx/+4GrXrm39q5PlhRdesPf5jag6wpp7YCiGA3kQ0ss5Rq02NdoVK1a0dO0gpM4feuih7osvvrDXGJ4xRq5PivZVV13lduzYET2f1mK0S3v66adtnkqUKGH76ctNKj7Pxj76fM+bNy/6vuXLl7vzzjvP5hWH8dtvv90+Bw/t2a688ko7znV5ViGEEEIIIUTBQaK7iIJZF+nVq1evNgHerVs3165dO6tfxtCrSZMm7rrrrrNe0l6Yzpgxw3388ceuf//+Vnc8ffr0mGtihobhFyI3KCw93mht8uTJ1vfav8YV/PLLL7f3I3YvvfRSE5pZ9eT2NG/e3AQ0G2NHvNarV8+cv6dMmWK12JmBsKYeHZOyIIjbBg0auEqVKtnzI7j37Nnjli5das9HDTb17OHe29Rge/M13nfZZZeZC/rzzz9vczdkyBBbEPCLDTxrmzZt3Pr16920adNMhPfo0SNmMeOrr75yS5YscTNnznTjxo2L9knPjF9//dVSXYKbEEIIIYQQIj0UvIJWkSvUqFHD3X///fY7hlyIQUT4TTfdZPsQ1kR/EYMI2AcffDD6XiKuK1asMNFNxNdD7TaR3szSqn2qOYZhwfRuxsIWNBij/hrRHBSgmUFkns0btyGIEalE3IHINOI3Mzp06GBmboh8zMt8H3I/PywGfPjhh27r1q3RftfPPfecO+2002zhgMi8Tylnv39OxsKixsaNG93JJ59s+6pUqRK9LwZq3NvXZuOWPnr0aGshxtwzHrINuIa/x6RJk6yVWCK4bvDzEkIIIYQQQqQPRbqLKGeeeWb0dyKvpUuXdmeccUZ0H+nQ4KOqTzzxhKtVq5YJSlKsn3zyyQMi0bw/J3XMRLppn4WYRJBzfYRqspHuILwPYewFN5x77rkJ30NaOPf20W6i2Tw3kf/gNb3g9n22GSvHPETFgzXsRLvJEPCCOwxtyGgBFkyNb9q0qYl+BD7XxuiNefdUr17d7psIFlF++OGH6EakXAghhBBCCJEeFOkuohx++OExr6lxDu7jNfioL6KYaDAClqjy8OHDrQVXECLdOYFrk7I9YsQIqyWnfrlt27YWOc4riDgjuu+77z77Sdo3CxHZIfz8PEdWiw3Ue1PHHYaIO/3PcwJ17GxCCCGEEEKI9CPRLbKEmmRqvenD7aEeOScg7DFmC1+f2mUM1rwYxewsJxCxJrJLzfgJJ5xg+1auXJnl+9q3b2/p5O+9957VTk+YMOGAa7L5aDf12ZikEfFOlE3w9ddfm3iOF+2mJzfXYaEhHkS19+/fb2Py6eXUzHNfIYQQQgghRMFAoruQupOTMu1dww8Wao2pVV68eLHVc2NORi0zv8cDAY0wfOWVVw44hmM5NdKYlBGNxT2d62M+hnkaEfaMjAyLsOeESy65xARup06dLBqPiVi/fv2yfB/jIjW8UaNGLhKJmDlb8JqkzhMNZ04RwixAUHt9zjnnZHpNjp9//vlmlPbYY4+ZuP7kk0/sGYmkY/BGvTx16zfeeKNFyhHhRP3Hjh1rDvCcRzScGm9Szan/ziqCnhmzeze1+nYhhBBCCCFE3qGabpEliL7WrVubW3fdunXd7t27Y6LeYWgnRq1yPEhRR1QSMT777LNtH4IU8U00HeFNXTNR4Bx9oQ891EzYfv75Z1enTh0Ts7QxSwZMzhDpRNyDwhaRPGfOHBsjIhoRzrm4jWcFbuZEqXFIJyp+7733RiP9RMKpHycSTtsw5gMDu2A9Ok7vvEbA8xl07drVlS1bNkdzI4QQQgghhMh7DokQ1hOFityOdBcVEkXoCzIsJBxzzDGuUd/prliJkmkZw+KMZmm5rxBCCCGEEKn+Oxvz4kQZpYp0F1JIzyaqeuyxx1p7rgceeCB6DFdw+k7jls2Xg7ZfO3bsiBGfLVu2jLkeac2IeQ91z6RcExHGcIzo748//hj3/bwPs7DMxgOkXTds2NCVKFHCIsJvvPGGRZiTEcB///vf7dxgrTPO4ezzteFE3nH9JkWeGm2endRtar8zgxR6Us6HDh1qrxkzixmk15OOzn9g11xzjdu7d29Mj2yelWg0z8Iz+X7kQDo6hnEe5ok6d+rYgRpwxk3Pb+A+jzzyiLvhhhvMwA6DNZzjhRBCCCGEEAUDie5CyrPPPms1wjiMDxs2zD300EOW1o0YR3Dv2bPHUpvZR19rUseTBaFKujRCkLZWiF5SnxMlTWQ2HiDdGvFZsmRJO46ozKwO+4UXXohpscXme3BTH52In376yQQvovntt9+2xQec0+Px1ltvucaNG1tqOrXXQQM5FgLmzZtnG3NIj3MPCwuklPO8a9eutTpu0uWZbyBNnPkC5mvZsmW2GLB8+XLbx/UqVKgQY65GSj5ifd26dZbW361bNzNUywyEP6tuwU0IIYQQQgiRHmSkVkihXnjAgAH2O0ZlGHNhYAYffvih9YH2TtyYpJ122mkWkfUu2VmJbszEENr0poZgj+/sjAdhi/hGzCJGiYIDYpdjYTA4o648CEL92muvddOnT084hv/+97/mSl61alV7jYEZ4j8MNeEdO3Z0Tz/99AGLESxaEDUn6gzXXXedPQfjJdKP4RnH/ULAU089Zc83adIkd88991jUn99ZaPjoo4+srzn34NmJvPMTYR7k8ssvj9bQswAwcuRIt2TJEjNai8fgwYPdgw8+mHAuhBBCCCGEEHmDIt2FFERuENpn7dy50yLTiG0vuIF0bqKtHEuGGjVquIsvvtiEdrt27UxY/utf/8rReICoLePxghswQYsHYpcocHAjMgykXieCSLoX3OExBAU8z0Q0PF70n3RvL7jD12DhAGGPM7uH1HGexc8thmmkoxO1JqqNwEaI++g3+4Jp/OG5I/WceQqPO0ifPn2srsRvtDoTQgghhBBCpAeJ7kIKYi8IYi3ZNlw4gIdTxRGTnsMOO8yitwsXLjTBPmbMGIu6Ej1PxXiSGS8Exxwcb6IxhJ8TUU5/7GeeeSbpa2TnOVjcYNECke0FNo7oiHBczLds2XJApDu796QVG7X6wU0IIYQQQgiRHiS6ixiYiBH5DEY/6Q2NCRkCGjAPCxuMYUwWFn5EdEljRjCSJk1adk5AsDOeoJlb0HwsKxgvBMccHm+ylClTxuq5MTLDYC6e8M4MBDvz8M4770T38X6exc8tIKpJD6euHNGNuRyfCynqRM7pMy6EEEIIIYQoHKimu4i0D/PgMk5aeIcOHaylGLXZ1AsjBDHrgkaNGrnhw4dbrfe5557rnn/+eas/9n21ScGmjrlJkybm0s3rXbt2mXDMCkzSHn74YXPp9vXj1G4jWDt16mQma6Rf33///VFxnxWkmJOejrs4wpWIMeZj2QUHcfpxcx2E90UXXWSGcVOnTnXFimX9nwpGcZicUbuNkCbdnefBwK1Lly4xnwnZASwWEFX3+6hzJ7U9Vczu3VRRbyGEEEIIIfIYRbqLGIhYhGWpUqUsrRkRXqVKFTdt2rToObhtZ2RkmBM3whgRjLGYh3RlorQYfBGVRSAjcr15WGbgoo15GWZg3MNHdElXxxEc0cv9brzxxqh7OW23soL065deesnajlH/TIuvgQMHHsQsOaubRnhjOscCBcZnyYCTeZs2bcxgrWbNmhYxp00Z8+2hrpv08GAaOaKbe4TruYUQQgghhBAFm0Miifo8iUIT6SaqnW6IlhNlp0VZ5cqVE55LijY9rhGtQfOzVEJPb8ZFunwwO6Cgw2IHPcUb9Z3uipUomZYxLM5olpb7CiGEEEIIkeq/szEvTuSjpEh3IYKWVUSk6V1NbXA4xRpHblLIcd8mktu+ffuoCzZrL6Rp08c6CLXRRMcRv1lB32t6gHN/vnTURPs6bdpo+bZiRNa5JiLXQz045mzse+ONN6Lp2N4VncgwKdvBXtykvQdd2KkL556YlXEuYwneA2gDRho8EXRSu8eNG5fp8xB5phc55/FsWcEzTZw40V1xxRXmlM59VqxYYXPH4gfp5/Xr1zeX8yC0GfP14NS38zmFr8u4W7VqZdel5dqrr76a5XiEEEIIIYQQ6UeiuxBBLTGO2KSPv/baa+aQvXbt2hhTL+qpP/jgA0vnRpBef/31UWGHwJw8eXLMNXlNGjqCPBGIYkTunj17bAwIaCLavu0WPxHTsHr1ajM9CwpmUti7d+9uApcxIa5JFecZHnnkEROsCHDqx/kdYd+5c+do2jfPRso6CwrLli2zSDnn0Pt63759ds4LL7zg+vfvb3XftPDiuqTRP/vsswc8z6+//mr11Sw6cL2s2pF5mF8WPngfz8LCxs0332xtvNasWWOLG6TYBxcbevbs6e666y7LBOBcngujtSAY1rGgsH79ekvrJ+WduY4HY2fVLbgJIYQQQggh0oPSywsJ1EOXLl3aor/ejAtRVrFiRde1a9e46eWIQF+zjUD99ttvTVy+++671lsaIVu+fHmLfmNylghENjXdtA3zYhpX9NNOO81ENvdBiGLGxjn0u84KhCg9vDF0e+yxx+z9RIlZXPD16JjAUXvOc1PHjZj25muIbaLeLDBg+sbCAaIYczQP71mwYIE9s08vR2RjpoZ4nTdvnqWMJAP3pb6de8DKlSvNiG7SpEm2oAGYsiGqf/75Z3uNAzxzhMGcB3FN1sL8+fPjXpdjfF60bGNRIQxjR6SHUXq5EEIIIYQQuYfSy4sYiFFEZt26daP7SLEmXdnz3nvvuSuvvNKENRFhb+TlU6cR2M2aNbMe1TB37txoxDcrELuI7WD0mjZZiF6O5QTGt3z5chO9CHjStolm405OmvUXX3xhKddA9J40bp4LQcrG8//yyy82NwhVfpK27o+zIbrD6d6Ics4nWyBZwe0hOu85/vjj7adPq/f7GJOPPjM3CO8gvA7PWfC6RPpJ3/elAWGIqlNX4rdgezghhBBCCCFE3qKWYUUERCSClY00a9pVIbZ57dOvAedwnLdHjhxpqeWkhSNw0wHRbKLwpMjjlk46OLXoOITXqFHDFgmob/aR/lq1atmzheFZOQ5PPfVUzMKEd08PQvo2kXPqsWmflh1wUvf4iHu8faTj5/S6/jqZXaN48eK2CSGEEEIIIdKPRHchASMuhBk1z77+mBpoosJEjGmntXv3bhOsPhpNenkYBCeRVMy9Fi1aZGI3GTANI6LKFkwv//777y3inROIkhPhpX81z0aNNH3BWQgg7TvYcov2XLQ943g850Ai1oh06syph04EvbZPP/1017x5c0vxDt4nt2HeqD8Ppu/zOqdzJoQQQgghhMhfSHQXEkiVJnWaemdquxGf9Lo+9ND/eeUhxHHHHjNmjLvlllvMtMvXCIejvhiZkaJMFJma5GSgvpo0agQt9eP79++3emsEK47p2YUxINhx/WbMbdu2tf2kjCNUEdhPPPGE7cNsjbp1XNExc3vooYeslp3085dfftlqvnlNnfPtt99uApxaaFLnWXhgcaJXr14x97/tttvMpI2UdmqnaV+WinZsROd5PmrdmUNS+hmzN53LTWb3bpqwlYEQQgghhBAi95F7eSFi+PDh7rzzzrO6bQQcQhFR51Osads1Y8YMi6IS8Q63B/Mg3kk5x/ArWUh3xjW9VKlSUZMzRDDiOCeMGjXKxotoR/wicD38Ht4HGKKxuNC6dWsT5jwH9dNeaJI6T+st0uZZIODa3COznuF33HGHCXWi/xitpYKhQ4faxmeBoRotxxhf+NmEEEIIIYQQBRO5l4sDwL374osvtlRxbwaWnyHSfdFFF1nEmpT0vCI3It156ap4MO7lizOa5fq4hBBCCCGEKMjIvVxkG9Ktv/76a2s5hWN5OgU36eUtW7aMjou0cFLmS5QoYRH8f/zjHwe8h1poasA5hz7fpNAnA7XuOJZXqFDBTOOIgr/00ksHGNHRf5s0/hNOOME9+uijB1yHNmi4ofvzKlWq5F599VW3a9cuS3tnH+ML1tITaQ8uFDD3CPkpU6bY9RDL11xzjRnKCSGEEEIIIQoeSi8XURCaCEVqqYcNGxYzM7iCB1ttBTfSonMC78vsmhieeajJnjVrlnv22WfNyZx+27iu04c8CPXsiGEEOen0pNnTazwrSEEnDR/TNIQ69eE4uNNf3INoxtGctHbacPXu3dstXbrU6sqDz4/rOy2/1q1bZ+3XuA4i/Nprr7WxY3jH60gkkul4aGFGb3HM4ti4D+UAQgghhBBCiIKH0stFUhBp3bFjR9xjOIsj1rMLRmeZieIBAwZYdBmxT504EeH27dvbMd5DFJiaa4S2Ty+fOnWqOZsDghzzNN531VVXZXtsGKjhlk6tNe3GMKfj98suu8yOszBB/Tz3o+6b52dM7CNKDdu3b7eoeEZGhpm7wcqVK82cbtu2bdb+jPHxHFzPR7qpzee99Bz3iw64yPPeZCAzgC2Y9oKjvNLLhRBCCCGEyPv0crmXi6RAAHoRmFskEuq+LzVRX0Q20ePgsTp16riNGzfGvCfotI7L+SmnnHLAOfEgek0P8OnTp7tvvvnGTOQQrb4/OWNgH9Fu344NEOWkhgefg/Rxj0/PJ109vG/nzp0muuOBeA/ONcKd85Nl8ODBthAghBBCCCGESD9KLxdFHiLLuKWTMr5kyRL3/vvvW/o6Qju7+MUC7+ie2b7ff/89qWv49yQ6Pwzt3lht8xuGeEIIIYQQQoj0INEt8jXUQNNfHJM0D5Fv6rZpfRYkmH6Nk/nmzZutdVhWcG2i2NRd16hRw1qd8d7gGBDCq1atOuD6+ZHixYtbektwE0IIIYQQQqQHpZeLfM1RRx3lunXrZrXbpIyT3o3J208//WR9uINQN03tNSnc/fr1c2XKlIk6oCeiWrVqbubMmdaLm/rxxx57zOrXvajH2I17MQauj4s61z/00PSsWY0dO9bNnj3bvfnmm9l63+zeTSXAhRBCCCGEyGMkukVa2oFhHIZDd1Zgkkbqt3cUx9DtnHPOcYsXLzaBHASH7549e7otW7ZY2625c+dalDwr7r//fnNLJ6WcOm7uhVgnNTuYgo6hGo7o1FvfddddMccz6+GdCr777jurMxdCCCGEEELkf+ReLvIcxCots4L9qcPQN/uwww5zN954ozmTk86d6Pz8Bu7ppKTntvncwbgqyr1cCCGEEEKIvHcvV023yHP4YmYmoPfv3+8+/vhjt2LFihz3/04lyZqrkQqfHwS3EEIIIYQQIr1IdIu0pJf7Wmtac91+++1WJ12iRAlXu3ZtV7NmTRPct9xyS4zZGe24OKdevXruo48+SroXONfGAZyNOmyuQZ02G+no9N7md2rBSWEnfTuYJt6jRw/rpU2NOCno9Av3/cCD5m4cf+6556Lv4z0enhN3dPplY3T25z//2U2aNCl6nOdJNA5qzmk9duSRR1pd+SWXXGJ9zIUQQgghhBD5G4lukVbuvfdeN2vWLPfss8+6tWvXmns4ddVTpkyJqdnGxOzRRx811/LjjjvOaqsRulnRvXt3czCfN2+eGY9NmDDBPfPMM9YW7O2333YvvviiO/vss92aNWvcokWLzEDtqquuirkGY/MO6ry/Q4cOVi9OjbeHGnPM3Vq1ahV3HB07dnQvvfSSGz16tPUOnzhxoglsoL69UaNGmY5j27Ztlm5/ww032Hupcz9wIkUAADcBSURBVG/durWl6McDgU+qS3ATQgghhBBCpAcZqYm0QaR2/Pjx7m9/+5tFeeGpp55yr7/+ukWBEdqeAQMGuMaNG0dFcMWKFc3BOyyQw3z55ZeuTZs2rlmzZvYacesZOHCgRdUfeeSR6D4EOdFo2oGdfPLJUXdzHNODLcRwVef+RKQB8d68efO4KeVca/r06fZcRKiBtmRBN3IEd2bjQNyTdo/QrlSpkh0n6p0ZgwcPdg8++GDCeRFCCCGEEELkDYp0i7SBAzfR6gYNGkT3YT5Wp04di+gGOffcc2PqpU855ZQDzokHqeuIa+6BcF+/fn302AcffOCWLFkSTTVnq169enRsnlq1asVcs1ixYib2X3jhhejiwZw5cywCHg+i6pjCXXDBBXGPZzUOov8XX3yxCe127drZwgTGcpnRp08fM3Pw21dffZXlPAkhhBBCCCFSg0S3KNTgfk47MCLSH374obUbGzNmjB3zLcAQxcGNlmPnn39+9BpEtcMgsElX37lzp7U+o9b60ksvjTsGjiUiq3Eg2ImSL1y40HqHM34WHbZu3Rr3etSM454Y3IQQQgghhBDpQaJbpA3StH2ttIfIN3XbiMsgK1eujP5OlJe0a2q1k4E0bUzZXn75ZeuvTaQYSC3fsGGDO+mkk8zYLLjFE9pB6tevb9edNm2aRbyJQBOljwcR6t9//90tXbo07vFkxoEJHNF60sbXrVtn80Z6uxBCCCGEECJ/o5ruIuIWjlkXEdmswKQrr/piIyi7detmtdukjJ944olWO40hWZcuXWLOfeihh8y1G2fvfv36mVO4d0BPBA7i1ItTn80zkcbtxTomawhwTMowdGMMn376qZs6dap7+umnLcKcCFzMMVZjAYDrZgZiulOnTmaEhpEa6eK4qhMlJ009q3FgrkZUvUmTJubEvmrVKrdr166kFx08s3s3VdRbCCGEEEKIPEaiuwgwatSoTJ2u082QIUMsCkz69969ey39GyfwoHO5P4/2XqRcn3XWWeYeTrQ3K3777TcTtV9//bUJTlLAR44cacfKly9vUXZaeSFocf3GqIxzaC2WFaSYDxo0yN4TrEuPB4Zxffv2dbfeeqvbvXu3LTDwOplxMG6c1h9//HFrI0afc5zcvflcsrQautgVK1HS5YTFGf8zohNCCCGEEEJkj0Mi+VWNibSQF5FuIrpEkZ9//vmUXL8wQ/9vFh0Q4MlCyzCEeqO+0yW6hRBCCCGEyCX839mYFyfyUVJNdxFJL/ep2ERRcfQmTblEiRKuYcOGVkMdhsjrmWeeaefUq1fPffTRR0ndi/ZfiHX6YmP2Rc/ttm3bWso4bbAqVKhg7bMwNyMK7aEvN1FuWm6VK1fOUrdJvw4uBlDXTJo153Fd6qo3bdoUPQen7xYtWlgKOg7gtWvXdm+88UbM+Oh5TfswzM0qV65srb5I/w6KWFLxMWCjHzj/8dBmDIdxzwMPPGDCl+chYs29iGDzPKTHM37mlyh4kGSvy1wwJv4DvuaaaywDwH+O1IWTucBcsH3++edJfS5CCCGEEEKI9CDRXcSgZnjWrFnW63rt2rVm1tW0aVO3Z8+emPOosyaFGUGOSMRdG5OzZEBgU7tMTfKiRYtMMLdq1cpMx0itpif1e++952bOnBl9D9d++OGHTYRSe46YRGSGoZ6bcVHnTOsuFgR8m63TTz/d7odIJWWdfYybXt2ejh07um+//dbGxDw8+eSTMeIeMEVjH27hjBOjM1p2BecIgc9x7vfSSy9ZX3HEPGnsCOOhQ4e6+++/3+qvs3tdnp9FCzauRWo9ILZpnXbTTTfZ4gEbZm5hWFhh1S24CSGEEEIIIdKDarqLEPSTpraYaLSvB8bAi3ZUiEaEtoee1o0bN7bfEegVK1Y0t2yMv7ICAc19cCcHIt1Eb3fs2GFCGKhXxnzs6quvtteYjHmqVKliop1INe20/HuA6LHvd33fffeZ0CUKT5usMBiS0XLr1VdfdT169HCffPKJRb5ZSCBaDhiVVatWLfqe5cuXu9WrV5s49tccMWKECWEWCbp27Wr7EPVEuonM47ROSj5R9wULFlgdNlF+hDfPWLdu3Wxdl8+H6wK17kT3eW4i39SxE+Unmp4ZgwcPNpdzIYQQQgghRPqR6C5CEEVFEAdNv2hzVadOHbdx48aYc4moBsUrIjJ8TmYgCr3gBtK9SZcOimf2BSPMRH5JrybSTT054hOIUgfbh5Hy7jnhhBPsJwKVNG8EOteYP3++RYH379/vfv7552ikG1FMdJwIs4dIf9C0jftzHZzSg3Ad5s/D83hh7J+HOvWgAVvwGXN6XZ4xHInPij59+rhevXpFXxPpjhcRF0IIIYQQQqQeiW6R64T7VVN7HG+fF9ZE4ElxZ6PnNensCGVe79u3L9Nrcw3w17n77rstak8EGTFN3TZR9vA1EoEwRuiSfh4maCyX3Wc8mOv6ayQLkfR4kX8hhBBCCCFE3iPRXYQg+kx6MiZptKQCIt+kW9PPOsjKlSstegxEnulFnd2+0MlC2je13tQu+4gsNdvZheeiDpz6cS90g0ZjROuJfq9bt87VqlXL9tEPm+fzEAXfvn27RcSJOucWuXVdPr+gAZ0QQgghhBAifyPRXYQ46qijXLdu3ax2m5RxRDVu2xifdenSJebchx56yFKhSZHGvKxMmTJRB/TchnEgJseMGeNuueUWq9HGVA369+9vKdvhRYF4EDHmfNpq4Q6ekZEREyWuXr26u+SSS6x+mppzosp33XWXRcR91JzjpNbzrMzNySefbMZrpKwj5n0teDKwcOE78uXWdRHsmLMxXmrtr7322qR6isPs3k0TtjIQQgghhBBC5D5yLy9iEE1u06aNGXQRfSXSu3jx4pi6Zn9ez549LSJMhHbu3LkmjFMB6eSYh82YMcPqt7k3KeLAAgHHkqF79+72s0mTJuZaTnp6sH4bnnvuOVtIwGANsYsTODXUtEYDxCxmaBzv3LmziWPadn3xxRf2vngwPlqPheHeOKrn9LrxIIWe2nHo1KlTjDO7EEIIIYQQIv9xSMSH4kSh5a9//asJteeff94VZqiXxkWcdPFgnXQiaPFFSjuu5rTvCkIaN2I5q0gyoptIPH24swOp/eEa7mRhXLjJJ5N9gJEazueN+k53xUqUzNH9Fmc0y9H7hBBCCCGEKKz4v7N/+OGHhBmlinQXYqhf/vjjj92KFSvcaaed5goi1Gh7YUn/6dtvv92VLVvWItMNGza0evR4td24nHMOfbxJV/e89dZb1kJs69at7t1337VoMynbRKARz4h1jhNxx4yMSDL3JcJcoUIFS9GnBZg3ROMnkWv+Q0MIs+GgDlz38ccfj96bY6S1N2/e3K5DGzCYM2eORcUZL+3SaPfFZ+fZsmWLjY/jjAuzOCGEEEIIIUTBQKK7EIPYpFYYwU2tdG5Af29af8XbHnnkEZdK7r33Xjdr1iyrZV67dq05lJNCvmfPnpjzSEl/9NFHTZCTuk6qOVFl4Gffvn1tTkgv5zjC2UecqW+nvzb9uzds2GACnx7fLFxMnTrVrV+/3rVr1876jCOG69evb8KalS3alLEh0DMDQc59P/zwQ+tNvmzZMtexY0dL5WeBZOLEiSb+vSCnJr1169aW2k8t94QJE1zv3r0TzhOLBKy6BTchhBBCCCFEepCRWiHmrLPOMhGZmyBG6S0dD8zZUgVtxYgSI0gR/vDUU09Z1HfSpEkmtD0DBgxwjRs3tt8R6BUrVrRU7KuuuiramiwzEOXjxo1zNWrUsNdEuidPnmw/y5cvb/sQ1YsWLbL9LDSQUkIUu1y5clk+R/v27S0y7kF433fffVafDUS6MZFjgYHnIO0dd3fq7v39uaefg3gMHjzYouVCCCGEEEKI9CPRLbIFKdbp4J///KcJ4gYNGkT3EZ2uU6eO27hxY8y5uIQHFwJoFRY+JzOIKJOa7iEiTW03xmfhaDLu7tkl7FL+wQcfWDq8j2wD9/vll19swYRxU3PuBXf4+eLRp08f16tXr+hrIt2+FZsQQgghhBAib5HoFiJAsH2Y7/WNCd17770XdQ33kFKfXajlDsL1iUqTQh7GO6pnF2rR2YQQQgghhBDpR6JbFAiqVq1qUWiiwpUqVbJ9RL6p2w738KY/Nr2/ASfzzZs3u7/85S85uu/ZZ59tkeedO3e68847L+45jItzcgIGaps2bbL69Hgw7q+++spqxU844YTo8wkhhBBCCCEKBhLdhQzcvmld9corr6SkxVZucuGFF1rduXf4Jp2a/uHUae/du9fGFYwQd+vWzWq3SRlHVA8bNsze06VLl5jrPvTQQ5b6Tf/rfv36uTJlyiTVWisepJV36NDBzM6oK7/55pvNmO3NN9+0NPRmzZqZSzkRa/ZRC16yZEnbkqF///7uiiuusOdp27attScj5RwTvIEDB7pLLrnExkDN9/Dhwy1VnPNywuzeTRO2MhBCCCGEEELkPnIvL2SMGjXKzMYKIpie4eZNKy8iuxiUBRkyZIhr06aNCXMixJ9++qkZjJUqVeqA83ADr1Wrltu+fbubO3euRaNzCoZpiG5c0jExQ8ATYffRdBzMcYe/+uqrzQ2dxYBkwdRt3rx57rXXXnO1a9e2FmcjR46MRvMR4ZjAYV5H/fqNN97oKleunONnEUIIIYQQQuQth0QikUge31PkE/JbpBtXcMTs0qVLo+f89a9/tVrq559/3qUbItqksofT2dM9b1lBdJwFjEZ9p7tiJZKLwIdZnNEsR+8TQgghhBCisOL/zv7hhx8SZpQq0l0I08t9KjUO27fffrv1msaUq2HDhiZqw1AnTao05xBpJbU5Gb744gtLtSbSTPo3va8XLFgQPc51fF9vUr2JUH/33XeZCkl6a7/99ttmZHbBBRdY32r6Y3NdD32raYlFtBfTM9K5Z86cGbOQwPuJgFOPzTmNGjWymuyFCxdajTT/QdC6K9hOjfvTj5uN/3BISc/IyHCJ1qRoI9aiRQt7Pq5JS7IdO3bYsc8//9yi1GvWrIl5D0KZKDbPkcwckdJOlJ3j1HQzR0IIIYQQQoiCg0R3IYZez7NmzbK07bVr15pZF+nMpEkHoU4aMYcgJz0aIY1JWVZ0797dhD1CmdZaQ4cOjTp6U1eO2EX4Ijzpa40gRZjG4+WXX3Y33XSTtcMitZy6bNprIbhJ3fYguJ977jk3YcIEt2HDBnfnnXe6a6+9NiY6Dg888IAbO3aspapjRMZ9EbSIYZ7tpZdesug+42VDQDNPxYoVc6tXr7Y0/ccee8z6kscD0YzgZi65N3Xon332maWY+6g49dikpgfhNQsjCPJk5ojPhuvPmTPHUtBZVOCzTASfCatuwU0IIYQQQgiRHmSkVkghQjp+/Hir7yaSCk899ZSJw0mTJpmY8wwYMMA1btzYfkd4VqxY0eqIMxPIHoQqNdZnnHGGva5SpUr0GIIXMUkNtOeZZ56xftG4iYf7XmOOhvkYtdflypWzLRiJ9mKS673xxhvRXtXcc/ny5W7ixIkWHfdgQuZ7emO0Ru9qIvpE/YEo9jfffGNjAoQwkX7qqYmU09ubhQResxgQBtM0jm/dujXaA5vFABYJWLygPpv6axYMEO+08EIs8x4EdDJzRG9uPitS6y+++OKYzycRLEzQhkwIIYQQQgiRfhTpLqT885//tIiuF55w+OGHmxnXxo0bY871AtaLXwRn+Jx4kLruxS3Cff369dFjOHAvWbIkGklmq169enRsWYGhWvC9L7zwghmnIcRZIAgeQ+yGr0m6vIe0bQQ9hmdE+9kQ/TiO+9dEuEmtD/boZl62bNkStx0Y84M49oIbTj31VIue+7kjzZ96dBYwgAUQauiJgiczR2z79u1zdevWPeDzSQQLDNSV+I1IvxBCCCGEECI9KNItcgyRXNLV58+fb6nPRFhJU7/ttttM0JKmTsp5GN9vOhGklr///vsxwpkab+B+FSpUiDmfSHIQFhg8COnga7/P11WnCqL21GOTUt66dWv34osvWtq6J6s5YpEhJzAX4fkQQgghhBBCpAeJ7kJK1apVTfSRUu3bTxH5JvU57L69cuXKaPsrnMxJbcZwLBmI9JJCzUaElRR2RDctvagnJ6pLFDm7YIBGBDoIkWTEJGntwVTy3GLVqlUHzEu1atUsWh2G+SGCzOaj3SwKUKfNOIMLE6effrobN26c279/v4lvT1ZzxGfIYgHjCn8+qXh+IYQQQgghRO4j0V1IW3jhJt6tWzer3SYlGdFG/2jSs6lxDoJpWenSpS2a3K9fP3PuxoTt22+/Tdgei2PUi5OqzZhJlfZiHZM1BDgtv7gWYyByO3XqVDMnCwtZ3MNJhQ735g6CQ3jbtm3NPI0oNW7svIeFBY516tQp7nw+8cQTSc0ZYr5Xr17u5ptvtvrrMWPGZOoWjkkatewdOnQwR3IENTXwPBdReg/zQdp679693Q033GCLCZ6s5oh0cz4rPkM+H+rR+XxIOaf3eLItwzyzezdN2MpACCGEEEIIkftIdBdihgwZYuIU1+69e/eaGKSVFi2+guDo3bNnT6tfpv8zgo70ZoR7Iqh1Rjh+/fXXJuYuvfRSMx4DTMAQw4jNJk2amAkaEXfOwbk7J+BqzmIEpmmksuMWzmsixn379nUHC6ngP//8s9W9I56Zk65du8Y9l/R0DNGI6p9//vn2TNRjs/gQBuGMizqiO0gyczR8+PBoGvrRRx/t7rrrrgMi8kIIIYQQQoj8yyGRRI2IRYGLdBM1RTDieJ0MmHsRsSYtOp0Q6UbwZzd6m1vzmRv3z2wuH374YTdjxowYo7mDAad17vHKK68kdT4tw8ggaNR3uitWomSO7rk4o1mO3ieEEEIIIURhxf+dTfZtooxSuZenEKLMRGQrV65sacU1atRwM2fOjB5fsGCBpWZzDHFIxDncaxohGARR6N2vg22maFVFDTfiLujkTbsq0qCJWlN7fOutt1rk1IvSzp0725eEyC0b9wTuERSgpF7Tl5qUZ75QpFLTUzo81ilTpth7+fJdc801FmHPznz5NGtahvmxeBhfUGgSPeaetPoiis8xzgkasMF7771nx72D+aZNmzIdA6nbPXr0sEg/1yXyzGfoQeySfk4qPsep1543b17MNcgmIK2cuSIFHvM0IuL+GUnnp+0X9emMn/7cQWgrRv9uvheklRNt95+ZEEIIIYQQomAh0Z1CEGu0s5owYYLbsGGD1SJfe+21bunSpWbAhakWacOIRAy37rvvvmzfg17cpHg3a9bMUpJpL8U1PewbPXq03Z8ez2+99ZYJW0CAIqwR0aRus919993R95LGjXBEsLNwgLgkpRxDNtKir7766pixIPYRvpzHxnOS4p4sjI97kT5N/TnilL7ima0q8ZwsKFB/TTSZNO14UAdNbfaaNWvMsCyc5h2EuXr11Vfd9OnTTZzTqswvciCYqWHn2ckkwDiN5wvWp1MzP2LECFt8YCGFc3kmf08EOGPhHCLfuL83b97cUvt9f3X2UQKA6R2LKPQlZyFACCGEEEIIUfBQTXeKoD73kUceMcHk+2BXqVLFLV++3MQsQg53am/URe9lIpzx2kclgj7Z1PnyE6EaJmiExj05D6dx3LSJjBORJjpMZDkMkWqMwhgziwIYpfl2Xzt37rT+3AjD2rVrR0UpKdbUHgO15G+++aYbNGhQUs9Cb236fQOu4WPHjrX305c7DO23GDdGZESccQz/5ptv3E033XTAudzfu32zsMECxS+//GLv8xD1973HuTcRaq7vnd+Bz3L16tXWh5sMBf+ZBmFBgkUWPltq45lnFg+8MEdsszjA3AKfN/PK4geGbzwXY2OxxtfUMw++tRgR9mS+e2zBBQohhBBCCCFEelCkO0XgQk3UE8FItNhviCkiwgg3otJBvDhPFoQvDuMXX3xxpucgFDlOX2vEMEJ49+7dNrasQJDTtgvRRmr6eeedZ6/ZiJJTJ81zBEW9F9yAQGeMyYLoDpLo/UShOT8onDFAy+q6wUWDzOqlyTxgEQQBTv9xD/tJC/eCOx6ksCO44z0D88jnxWJFEF77eeQnZQhBEzuOs6CRKC0+nGHBZ+c339JMCCGEEEIIkfdIdKcIX4M7f/58E2t+IyU5WNed8MM59FAX9rkjkuoJtp+KBzXiV1xxhYlO+kFT2+zbZ1G7nNvQUzoIkWLEYl69P5nrck3I7Lo4oW/dutXS1XEyp3adNmXJzHf4Xv5+ee1VSL906vT9RimDEEIIIYQQIj1IdKcI0p0xysKAzEeH/UbkEaMtUpWDrFy5Mub1cccd57Zv3x4j2oImYUSViS6Tgh0PRDbikhR2ekUToSXSGoQUc+q0E8FYEW5B8cbiAaZiPGc68On4wTRqUt1zA2rcqVcndX3atGm2YLFnzx5bvKA92ubNm3N8Xd8mLAiv/Twy1x988IHVdgePswDDMycD3zvuFdyEEEIIIYQQ6UE13SkCQYwpGeZpCF9qhIk6IqAQQdRVI4bvueceq5dGIFMPHW5jtWvXLqvVJtqKy/XChQtjRBQO31yrbNmyZvKFWzj3wC0bgU9kfMyYMVYTzH7qjYMg2onKI9xJayY9mi3IJZdcYoZl1HdTe7x//35zQadOGlfwdNC+fXszSMPZmzptFjeolw5Gs5OBhQ/6c/P8pODj9k5K+Nlnn21CFyMz6t1Jped56cndpk0bO4/5/eSTT+x+9NZOBj5v6tZJQce5fPLkybaQgmEbMMcc79Spk322fP58lpQFJFPPnYjZvZtKgAshhBBCCJHHKNKdQkhRzsjIsBpbIpgIM9LNcQI/8cQTLYKK2zdiFzGM8VoQ3oMRFynhnINADLqLA+IMIcx5tA0jndw7YfMexCFGXog8RH2w/RVQm41oJ7JLZD2eGRuics6cOeaojehEhGMgRhQ4u4RbkeUUFh4wKkOwIl4R4P3797djwTpvn26dGdS2Uyvt0/ZZLGEOWEzAII4UfVq7IcCBz4z99EMnOo1RHYsd4TZlmUGdeK9evcz8joUMFlJwS8e8DVjwoOUYkXXuw2ILNfmYqQkhhBBCCCEKHodE8rrgVOQ5OHPTvupf//qXRWzzAgQ+gpQU9CBEbjEJC0fTcwOixb7vuK+/JlsAUZ4bQj8epObzTGXKlLF2ZAcDBncslODCnpufFQZuGKo16jvdFSuRs3lfnNEsV8YihBBCCCFEYcH/nY3+SFTSqfRykacQTc8tcIIn4k5aOHXQtOLC+CwZw7PcglZg8dqt5YQuXbpY3TiiWwghhBBCCFE4UHp5AYQacdLESVNHYBIdDTqikw6NaRrHiHCTIh2EWmGiv0GIBJP6HeSZZ56xlHWMuahz7tGjR/QYaeukRxO1xhiOGm/v2E5k3UecSU1nw7CNlmmkaXM930KNiHeTJk3sd1aHEM07duw4YKxTpkyx8bGSRI9ratcxmbv22mstDZ/a+Xbt2rknn3zygPmiBp2x814i0qT8BxM8uDbp5KSWI6CpFw+2FCPqTK01CwbMKang1GIDc8vzBdPLN2zYYGn+PA/XpNUabeISMX78eMsKCJcPcH3mbM2aNQd8XvQQzw13dyGEEEIIIUTqkOgugCC4ifJSB47AQ3AiPpcuXWoO461btzbjNIQgJm0YjWUXRGD37t3NqAyXcOqOMQ7zIARHjx5t93/22WfdW2+95e69995onTiiENG5bds2GxPO4owH926EJb+vXbvWhDR11Yz99ddfd5999pnVlwdBsFL7Pm/ePNs4d8iQIXY/ROkvv/xibb5GjhwZN22d8ZH6TU38qFGjbMHg6aefjh6nnpv6e6Ll3Idr0q/bg0jHrR0TO/poMzeI93gQpabunYUF5gSDvBtuuMGEf2Zwberu+Ux97biH+aGG3ot8D68ZY/h8wNGdVJfgJoQQQgghhEgPSi8vYCCoMFx744033Lnnnmv7SLFevny5mzhxook0TNNwRg+21ho6dGi27jNw4EAz++rZs2d0H8ZeHuq1PdyT8zFkw9CNqDZRZSLAPvW6YsWK9hPxS8QYAY/Ipv0WgploOSA8ia4j0v39iOZSI07UGHDyxm180KBBST0L10aQMx4/H7y+6aab7Dii2MNcspjAvYncE4HHGR03c+/UHs4ICILpHc8+derUaM9usg4SfZ6Ysg0fPtzM9Vh0CMPCCXPLYgFinsUKngFzu8wWZR588MGk5kYIIYQQQgiRWhTpLmB8+umnFhlu3LhxNEWbDbFKRJhIbN26dWPe48V5spBaTT9vXLMzA9HPceqpEcMIYYzAGFuyMFYEsRfcgCM4BmIc8yByveAGUt2D6d9ZQY/yYBsx5gOHd9+fnGg0mQGIXu5DazBAbEO3bt1MRJPmTnT93XffzfReRPBJJ/eCOytwVic9nkyFzGjZsqXVjs+ePdteswBB2UBm4p9rktrvt2B/dSGEEEIIIUTeItFdwPB107QeQ+D5jRTlYF13IkhJDpvW+5ZZkJURGenX1Cxj+kULLUQrEV7Yt2+fy23CAhYBnVu1zD/++KNr2vR//atxPyfC7sWtfxZagn3xxReWxu8XI8K1157smriRgk4vcDIA2PxCB+nr9OsGMgfoJU5KOWN68cUXY6LzYYiG8zzBTQghhBBCCJEelF5ewCASjKgiCusjskGImlJ/HWTlypUxr0nvxoQM4e0jwEEjMKK9RFFJ4SaiGgaRjeglhd3XFE+fPj3mHISijyRnBmMlCsvmo90sHmAoxnPmFqtWrTpgPjBDI3r8ySefWISeGnE/hrBpmZ8zeqKzEcm+55573IgRIw44j4UIashZxEgm2s2ixc8//xx9jehHUC9btszKBIIp5qeffrql71MfTt2+EEIIIYQQIv8j0V3AQBATZSXqivBt2LChpRC/8847ZuJF7TZiD1GIUEMgk44chN7V9JYeNmyYa9u2rVu0aJGZhAUjoriGU0dctmxZi/TiFs49brvtNqvHRlSOGTPG0rLZj6lbEOrBicoj3HFXx+AsbHKGQRgO6DiDY7yGmMQFncUEXz+dG7BA0atXL3fzzTdbPTTj9jXvpJSzQMA+0scZS1DsQv/+/V2tWrWs1pwabMzcWDCIBy7pXAuHddK8qe9G5NepU8fqyYmisx+xD+F7fffdd/aT6wf7dPOaNHnaoiHKc9IWbXbv/0X0hRBCCCGEEHmHRHcBBKdtIq8YZmG8hTirWbOmiWOgvhvHbcQfYg/jtWA6MgKOiCn7uVabNm1MyAfbbRHRxRUcwzGOke6MQAdENKZeCHzEPRFz2ouRAu1Zv369iUucyIkkkyqNkA9ClB0zMIQ8jt9EzS+99FIbd27CuIgmMxdEtzGHw5UdmEcWJfr27WvC388vbcM8iHKehbR6xC6Rbmq841G6dGlLGWdeWDzgfoj5Bg0a2HEWSDZt2pTjPt7UkydKLU9Eq6GLXbESB7q7J8PijGY5ep8QQgghhBBFnUMi4eJeUWChPzbp4PSVDkZJUwmCFSdzUsILOumYv+zAYgD13yxoZAdahhFxb9R3ukS3EEIIIYQQuYT/O5vAWqKMUhmp5WNIHyeaXblyZYuwEmEOmqUtWLDA2lFxDLFIJDYIkWWirEGI5oZdr4lSkzpNrTjO4KRIe4hokwJ+1FFHWc0z6d/ezA2R2rlzZ/uSEbVm89Fs7uEjxz7Fu0WLFua0zhfyqquucjt27DhgrFOmTLH38uUlRZu09mQI3w+4XjC6zvjoz92qVStLdaeuO1z/HgQndrIHiFKzqMD8co2XX37Z5ptr8JmsWLHigDptP5+My6eyw9ixY60220NfcK4ZTM8n7f7++++Pzgt14nwP+B3X9ezMixBCCCGEECK9SHTnYxBapIojyDZs2GB13LSWWrp0qZmPYaZFTTUmaNRv33fffdm+x/jx41337t0t3Zrez4hQarY9pHzTt5r7YxBG6jRts6B+/fomdBHR27Ztsy2eqzeLBwjuPXv22Njpz01aPKnnQWh5hgilZpqNczE4ywyEvG+Zxu/UOwfbqAUd2T30r0bwEy2+/PLLrYabcYVBZNOWjbEz3mDku1+/fvaczDuLHvTZph4dqKHn+ghj5hOhTKq/r6sn5RyzOGrqgWckdZ8FDGDMiHjq7j20T+OejIfa+6zmhbpzVt2CmxBCCCGEECI9qKY7n4Jwouaafti+z3aVKlXc8uXL3cSJEy2CigmXj6Ji0oXIo846OwwcONBMz6hz9tSuXTv6O6njHu7J+RisURNOrTMRaSK15cqVy/QemKkxtq1bt0YdwllMIBqMW7e/HwIXcep7ctP7m/cOGjQo7nXLly8fdV1HpFKHTuTdQ616mOuvv95EMjC/LCisXr3aask9OLuzIEAknPZcPGcQBHezZs2iIp7noH969erVLTOAtl8IbUCUI7KHDx9u9ybKfeyxx5pwpkYesc38jxo1ys5nLAhvFjQ83J8xJTsvLNYwLiGEEEIIIUT6UaQ7n4KII72Z6GYweotYJSJM9LNu3box7/HiPFl27twZ7TudGYh+jleoUMFEH4IPYzTGliyMFbHtBTfQEozoMceCot4LSyDVnTFmBn2ticqz8TumaP41m2+HFoRUbQ8p80Tpw/dgznn/tGnTDhDc4WswRvDX4Hm8aZqH16SF00KNMWEah9gmmo4gJ2WfRRYczRHjLEIEnd6zOy+YvpHy7zeyIoQQQgghhBDpQaI7n+LrpufPn2/RXL8h0oJ13YkgNTzskxdMuc6q7RQ1zFdccYWJTOqUSZ1+4okn7Ni+fftcbhPua41AJfqdG8+anXsQxX777bdtrrMapxf2yY7TR+UR3fTiPvvss034eyGO6A73X8/uvFBLzjWDmxBCCCGEECI9SHTnU4gEI56oVQ5Gb9mIGNP2i1TkIPSDDkLkl7TkoBj16dhA9JQoKqnK8UBkI+5IYadHNKnSRMaDEAkmgpsIxkq0NRhxRdAS6eU5cwOelZpyD3XMpLPnBOqlSVUnwp+Z8E70rPQtD8Jr5o72YcG6bpzIfe02P8kq4NxgPbcQQgghhBCiYKOa7nwKgpjaYczTEL4NGza0VGFEGZFL6qoRw/SDxkQNgezNujyINwy7hg0bZvXDixYtMiOuYOQToy+uVbZsWXPqxhWbe9A7G4FPtJi+2Ri2sT/osg2IdqLyCHecvEmLDqZGezduHNAxLcN4DdMxUqoRn+ecc06uzFejRo3s+Rknaev9+/ePitycMGLECFtM4LpEoKnXTgbqs0kPp70XdeGYouFYTg28h8yBUqVKWb04hnH+s+LzJoodTk/PLWb3bqqotxBCCCGEEHmMIt35GIQbhlwYYxFBxeyLdHNaiJ144omW8o3bN2IXMYwxWBDeg9gjJZxziIyH3cWJ6CKEOQ9DMNLJqT8G3oMxGOZsGIC98MILNpYgGH4h2hGYRJsR+GEQknPmzDGhSRo1IhxTOGqmcwvqmBHxjJ/08JYtW5rR3MEwcuRIcyJHeG/evDmp99SsWdNNnz7dTZ061eYM8f/QQw+ZiVpwPs477zz7yWKKF+IshrAIQa25EEIIIYQQonBwSCRcCCuEKFSQao/LPJkSqu8WQgghhBAib//OVqRbCCGEEEIIIYRIERLdIt+DmVywbVp447gQQgghhBBC5EdkpCbyPeXLl49xXY93XAghhBBCCCHyIxLdIt9TrFgxc1IXQgghhBBCiIKG0suFEEIIIYQQQogUIdEthBBCCCGEEEKkCIluIYQQQgghhBAiRUh0CyGEEEIIIYQQKUKiWwghhBBCCCGESBES3UIIIYQQQgghRIqQ6BZCCCGEEEIIIVKERLcQQgghhBBCCJEiJLqFEEIIIYQQQgiJbiGEEEIIIYQQomChSLcQQgghhBBCCJEiJLqFEEIIIYQQQogUIdEthBBCCCGEEEKkCIluIYQQQgghhBAiRUh0CyGEEEIIIYQQKaJYqi4shMgfRCIR+/nvf/873UMRQgghhBCi0OD/vvZ/b2eGRLcQhZzdu3fbzz/96U/pHooQQgghhBCFjr1797pjjjkm0+MS3UIUco499lj7+eWXXyb8x0CI3F75ZaHnq6++cn/84x81uSJP0PdOpAN974S+d0WXSCRigrt8+fIJz5PoFqKQc+ih/7NuQHBL/Ii8hu+cvndC3ztRFNC/d0Lfu6LJMUkEtWSkJoQQQgghhBBCpAiJbiGEEEIIIYQQIkVIdAtRyClevLgbMGCA/RRC3ztRmNG/d0LfO1FU0L93BYtDIln5mwshhBBCCCGEECJHKNIthBBCCCGEEEKkCIluIYQQQgghhBAiRUh0CyGEEEIIIYQQKUKiW4hCzhNPPOFOOukkV6JECVe3bl23evXqdA9JFCLefvttd+WVV7ry5cu7Qw45xL3yyisxx7EN6d+/vzvhhBPckUce6S655BK3ZcuWtI1XFHwGDx7sateu7Y4++mhXtmxZ17JlS7dp06aYc3755RfXvXt3V7p0afeHP/zBtWnTxu3YsSNtYxYFn/Hjx7szzzwz2ov73HPPdQsXLowe13dO5AVDhgyx/6+944479N0rYEh0C1GImTZtmuvVq5e5l69du9bVqFHDNW3a1O3cuTPdQxOFhB9//NG+VyzuxGPYsGFu9OjRbsKECW7VqlXuqKOOsu8gf6AKkROWLl1qgnrlypXu9ddfd//9739dkyZN7LvoufPOO93cuXPdjBkz7Pxvv/3WtW7dWhMuckzFihVN8Lz33ntuzZo1rlGjRq5FixZuw4YN+s6JPOEf//iHmzhxoi3+BNG/dwUE3MuFEIWTOnXqRLp37x59/dtvv0XKly8fGTx4cFrHJQon/F/K7Nmzo69///33SLly5SLDhw+P7vv+++8jxYsXj7z00ktpGqUobOzcudO+e0uXLo1+xw4//PDIjBkzouds3LjRzlmxYkUaRyoKG6VKlYo8/fTT+s6JlLN3795ItWrVIq+//nrkggsuiPTs2dP269+7goMi3UIUUvbt22cr8qTzeg499FB7vWLFirSOTRQNtm7d6rZv3x7zHTzmmGOszEHfQZFb/PDDD/bz2GOPtZ/8u0f0O/i9q169ujvxxBP1vRO5wm+//eamTp1q2RWkmes7J1IN2T3NmjWL+XcN9N0rOBRL9wCEEKnhu+++sz8Mjj/++Jj9vP7kk0807SLlILj9dy78HfTHhDgYfv/9d6ttbNCggTv99NOj37sjjjjC/d///Z++dyJX+fDDD01kUx6DV8Ds2bPdqaee6t5//31950TKYIGHEkHSy8Po37uCg0S3EEIIIQps9Oejjz5yy5cvT/dQRBHglFNOMYFNdsXMmTNdp06dzDNAiFTx1VdfuZ49e5p/BYa4ouCi9HIhCillypRxhx122AGOvbwuV65c2sYlig7+e6bvoEgFPXr0cPPmzXNLliwxk6vg947ymu+//z7mfP3bJw4WMij+/Oc/u1q1apmLPiaSo0aN0ndOpAzSxzG/rVmzpitWrJhtLPRgUMrvZI7p37uCgUS3EIX4jwP+MHjzzTdjUjF5TXqcEKmmcuXK9sdo8Dv473//21zM9R0UOQXPPgQ3qb1vvfWWfc+C8O/e4YcfHvO9o6XYl19+qe+dyFX4/9Rff/1V3zmRMi6++GIrayDDwm/nnHOO69ChQ/R3/XtXMFB6uRCFGNqFkf7GP8p16tRxjz/+uBm/dO7cOd1DE4WE//znP+7TTz+NMU/jDwFMrTCuot524MCBrlq1aiaOMjIyrKc3vZWFyGlK+YsvvujmzJljvbq9PwAmffSC52eXLl3s3z++h/RUvu2220xw16tXT5MuckSfPn3cZZddZv+u7d27176Df//7393ixYv1nRMpg3/jvF+Fh9abpUuXju7Xv3cFA4luIQoxV199tdu1a5fr37+//WF61llnuUWLFh1gbCVETqFf7UUXXRR9jdABFnv+9re/uXvvvdcWerp27Wrpvg0bNrTvoGrTRE4ZP368/bzwwgtj9k+ePNldf/319vvIkSOtW0ObNm0sEklv+HHjxmnSRY4hxbdjx45u27ZtJrLplYzgbty4sb5zIq3o37uCwSH0DUv3IIQQQgghhBBCiMKIarqFEEIIIYQQQogUIdEthBBCCCGEEEKkCIluIYQQQgghhBAiRUh0CyGEEEIIIYQQKUKiWwghhBBCCCGESBES3UIIIYQQQgghRIqQ6BZCCCGEEEIIIVKERLcQQgghhBBCCJEiJLqFEEIIIYQQQogUIdEthBBCiHzN9ddf71q2bOnyK59//rk75JBD3Pvvv+8KArt27XLdunVzJ554oitevLgrV66ca9q0qXvnnXfSPTQhhCiUFEv3AIQQQgghCir79u1zBY02bdrYuJ999llXpUoVt2PHDvfmm2+63bt3p+ye3O+II45I2fWFECI/o0i3EEIIIQoUF154obvtttvcHXfc4UqVKuWOP/5499RTT7kff/zRde7c2R199NHuz3/+s1u4cGH0PX//+98tGj1//nx35plnuhIlSrh69eq5jz76KObas2bNcqeddppFgE866ST36KOPxhxn38MPP+w6duzo/vjHP7quXbu6ypUr27Gzzz7b7sH44B//+Idr3LixK1OmjDvmmGPcBRdc4NauXRtzPc5/+umnXatWrVzJkiVdtWrV3KuvvhpzzoYNG9wVV1xh9+PZzjvvPPfPf/4zepz3/+Uvf7Fnql69uhs3blymc/f999+7ZcuWuaFDh7qLLrrIVapUydWpU8f16dPHNW/ePOa8m2++2eaW655++ulu3rx5BzVPsHz5chv/kUce6f70pz+522+/3T43IYQozEh0CyGEEKLAQZQWMbt69WoT4KRLt2vXztWvX9+EbZMmTdx1113nfvrpp5j33XPPPSYQEcTHHXecu/LKK91///tfO/bee++5q666yl1zzTXuww8/dA888IDLyMhwf/vb32KuMWLECFejRg23bt06O84Y4I033nDbtm1zL7/8sr3eu3ev69SpkwnNlStXmqC+/PLLbX+QBx980O67fv16O96hQwe3Z88eO/bNN9+4888/38TtW2+9ZWO84YYb3P79++34Cy+84Pr37+8GDRrkNm7c6B555BEbE/MTjz/84Q+2vfLKK+7XX3+Ne87vv//uLrvsMks3f/75593HH3/shgwZ4g477LCDmicWCi699FKLtPOs06ZNs7np0aNHNj55IYQogESEEEIIIfIxnTp1irRo0SL6+oILLog0bNgw+nr//v2Ro446KnLddddF923bti3CnzkrVqyw10uWLLHXU6dOjZ6ze/fuyJFHHhmZNm2avW7fvn2kcePGMfe+5557Iqeeemr0daVKlSItW7aMOWfr1q127XXr1iV8jt9++y1y9NFHR+bOnRvdx/vuv//+6Ov//Oc/tm/hwoX2uk+fPpHKlStH9u3bF/eaVatWjbz44osx+x5++OHIueeem+k4Zs6cGSlVqlSkRIkSkfr169s9Pvjgg+jxxYsXRw499NDIpk2b4r4/p/PUpUuXSNeuXWP2LVu2zO71888/ZzpeIYQo6CjSLYQQQogCByniHiKwpUuXdmeccUZ0H2nRsHPnzpj3nXvuudHfjz32WHfKKadYhBj42aBBg5jzeb1lyxb322+/Rfedc845SY2RWumbbrrJItykl5Nm/Z///Md9+eWXmT7LUUcdZef5cWPORjr24YcffsD1ScsmetylS5doBJtt4MCBMennYYg0f/vtt5bGTuSZ1PuaNWtGI9Xcs2LFiu7kk0+O+/6cztMHH3xg9wiOFQM3Iutbt27NYjaFEKLgIiM1IYQQQhQ4wiKU2ujgPl4Dgi63QRgnA6nlmJONGjXKaqdJEUf0h83X4j2LHze1z5mBgAfq2evWrRtzzKeCZwZ12tSbs5H6feONN7oBAwaYU3yiex7MPDFe6sSp4w6Dk7oQQhRWJLqFEEIIUWSgttoLvH/9619u8+bNZkIG/Ay3zeI1Ed9EIta7cgejvP69mJpRpw1fffWV++6777I1XqLg1GdTdx4W50Tzy5cv7z777DOrAz8YTj31VKvz9vf8+uuvbW7iRbtzOk9E06kPx+ROCCGKEkovF0IIIUSR4aGHHrL2WLiWE9XFjM33AL/rrrvsGK7bCE7E7tixY93dd9+d8Jply5a16PCiRYsspfyHH36w/aSVT5kyxdKxV61aZcI4u1FkTMb+/e9/m2nZmjVrLIWba27atClqwjZ48GA3evRoGzPGZpMnT3aPPfZY3OsReW/UqJEZpGFmRlr3jBkz3LBhw1yLFi3sHFzWMW8jDf3111+3c3CC5/kOZp569+7t3n33XXsmUth5ljlz5shITQhR6JHoFkIIIUSRARfunj17ulq1arnt27e7uXPnRiPVRGKnT5/upk6dai2ycAVHpCPOE1GsWDETvRMnTrTIsxevkyZNsmg618VJnbRqBHp2oFYd13JSsxHDjJt0ch/1Ji2clmEIbWraOYe6ad/GLAx11KSijxw50oQ1z0l6ObXnCOdgS7DatWu7v/71rxYFv/fee6OR/JzOExH0pUuXmlCnTp0Wa7yXORNCiMLMIbippXsQQgghhBCpBLMw+lIjgv/v//5Pky2EECLPUKRbCCGEEEIIIYRIERLdQgghhBBCCCFEilB6uRBCCCGEEEIIkSIU6RZCCCGEEEIIIVKERLcQQgghhBBCCJEiJLqFEEIIIYQQQogUIdEthBBCCCGEEEKkCIluIYQQQgghhBAiRUh0CyGEEEIIIYQQKUKiWwghhBBCCCGESBES3UIIIYQQQgghRIqQ6BZCCCGEEEIIIVxq+H+P1GFl+hCAYAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_selector.plot_feature_importance(topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c750f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Prob_Impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>duration_sub_pdays</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>0.148376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>f263</td>\n",
       "      <td>-45.695000</td>\n",
       "      <td>0.114110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>campaign_add_cons_price_idx</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>0.107117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>duration_div_previous</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>0.096442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>duration_sub_pdays</td>\n",
       "      <td>3503.000000</td>\n",
       "      <td>0.078533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>f254</td>\n",
       "      <td>18.824335</td>\n",
       "      <td>0.000211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>campaign_mult_cons_price_idx</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>pdays_sub_cons_conf_idx</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>pdays_mult_cons_price_idx</td>\n",
       "      <td>93.950180</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>pdays_div_euribor3m</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1344 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Feature    Threshold  Prob_Impact\n",
       "3               duration_sub_pdays  3600.000000     0.148376\n",
       "11                            f263   -45.695000     0.114110\n",
       "14     campaign_add_cons_price_idx   163.000000     0.107117\n",
       "18           duration_div_previous   143.000000     0.096442\n",
       "33              duration_sub_pdays  3503.000000     0.078533\n",
       "...                            ...          ...          ...\n",
       "833                           f254    18.824335     0.000211\n",
       "748   campaign_mult_cons_price_idx    50.000000     0.000138\n",
       "1126       pdays_sub_cons_conf_idx     3.000000     0.000111\n",
       "629      pdays_mult_cons_price_idx    93.950180     0.000040\n",
       "1130           pdays_div_euribor3m     5.000000     0.000004\n",
       "\n",
       "[1344 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_selector.get_probability_impact_summary()[[\"Feature\", \"Threshold\", \"Prob_Impact\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e05eca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f0': 'age',\n",
       " 'f1': 'duration',\n",
       " 'f2': 'campaign',\n",
       " 'f3': 'pdays',\n",
       " 'f4': 'previous',\n",
       " 'f5': 'emp_var_rate',\n",
       " 'f6': 'cons_price_idx',\n",
       " 'f7': 'cons_conf_idx',\n",
       " 'f8': 'euribor3m',\n",
       " 'f9': 'nr_employed',\n",
       " 'f10': 'age_log',\n",
       " 'f11': 'age_sqrt',\n",
       " 'f12': 'age_square',\n",
       " 'f13': 'age_cube',\n",
       " 'f14': 'duration_log',\n",
       " 'f15': 'duration_sqrt',\n",
       " 'f16': 'duration_square',\n",
       " 'f17': 'duration_cube',\n",
       " 'f18': 'campaign_log',\n",
       " 'f19': 'campaign_sqrt',\n",
       " 'f20': 'campaign_square',\n",
       " 'f21': 'campaign_cube',\n",
       " 'f22': 'pdays_log',\n",
       " 'f23': 'pdays_sqrt',\n",
       " 'f24': 'pdays_square',\n",
       " 'f25': 'pdays_cube',\n",
       " 'f26': 'previous_log',\n",
       " 'f27': 'previous_sqrt',\n",
       " 'f28': 'previous_square',\n",
       " 'f29': 'previous_cube',\n",
       " 'f30': 'emp_var_rate_log',\n",
       " 'f31': 'emp_var_rate_sqrt',\n",
       " 'f32': 'emp_var_rate_square',\n",
       " 'f33': 'emp_var_rate_cube',\n",
       " 'f34': 'cons_price_idx_log',\n",
       " 'f35': 'cons_price_idx_sqrt',\n",
       " 'f36': 'cons_price_idx_square',\n",
       " 'f37': 'cons_price_idx_cube',\n",
       " 'f38': 'cons_conf_idx_log',\n",
       " 'f39': 'cons_conf_idx_sqrt',\n",
       " 'f40': 'cons_conf_idx_square',\n",
       " 'f41': 'cons_conf_idx_cube',\n",
       " 'f42': 'euribor3m_log',\n",
       " 'f43': 'euribor3m_sqrt',\n",
       " 'f44': 'euribor3m_square',\n",
       " 'f45': 'euribor3m_cube',\n",
       " 'f46': 'nr_employed_log',\n",
       " 'f47': 'nr_employed_sqrt',\n",
       " 'f48': 'nr_employed_square',\n",
       " 'f49': 'nr_employed_cube',\n",
       " 'f50': 'age_mult_duration',\n",
       " 'f51': 'age_div_duration',\n",
       " 'f52': 'age_add_duration',\n",
       " 'f53': 'age_sub_duration',\n",
       " 'f54': 'age_mult_campaign',\n",
       " 'f55': 'age_div_campaign',\n",
       " 'f56': 'age_add_campaign',\n",
       " 'f57': 'age_sub_campaign',\n",
       " 'f58': 'age_mult_pdays',\n",
       " 'f59': 'age_div_pdays',\n",
       " 'f60': 'age_add_pdays',\n",
       " 'f61': 'age_sub_pdays',\n",
       " 'f62': 'age_mult_previous',\n",
       " 'f63': 'age_div_previous',\n",
       " 'f64': 'age_add_previous',\n",
       " 'f65': 'age_sub_previous',\n",
       " 'f66': 'age_mult_emp_var_rate',\n",
       " 'f67': 'age_div_emp_var_rate',\n",
       " 'f68': 'age_add_emp_var_rate',\n",
       " 'f69': 'age_sub_emp_var_rate',\n",
       " 'f70': 'age_mult_cons_price_idx',\n",
       " 'f71': 'age_div_cons_price_idx',\n",
       " 'f72': 'age_add_cons_price_idx',\n",
       " 'f73': 'age_sub_cons_price_idx',\n",
       " 'f74': 'age_mult_cons_conf_idx',\n",
       " 'f75': 'age_div_cons_conf_idx',\n",
       " 'f76': 'age_add_cons_conf_idx',\n",
       " 'f77': 'age_sub_cons_conf_idx',\n",
       " 'f78': 'age_mult_euribor3m',\n",
       " 'f79': 'age_div_euribor3m',\n",
       " 'f80': 'age_add_euribor3m',\n",
       " 'f81': 'age_sub_euribor3m',\n",
       " 'f82': 'age_mult_nr_employed',\n",
       " 'f83': 'age_div_nr_employed',\n",
       " 'f84': 'age_add_nr_employed',\n",
       " 'f85': 'age_sub_nr_employed',\n",
       " 'f86': 'duration_mult_campaign',\n",
       " 'f87': 'duration_div_campaign',\n",
       " 'f88': 'duration_add_campaign',\n",
       " 'f89': 'duration_sub_campaign',\n",
       " 'f90': 'duration_mult_pdays',\n",
       " 'f91': 'duration_div_pdays',\n",
       " 'f92': 'duration_add_pdays',\n",
       " 'f93': 'duration_sub_pdays',\n",
       " 'f94': 'duration_mult_previous',\n",
       " 'f95': 'duration_div_previous',\n",
       " 'f96': 'duration_add_previous',\n",
       " 'f97': 'duration_sub_previous',\n",
       " 'f98': 'duration_mult_emp_var_rate',\n",
       " 'f99': 'duration_div_emp_var_rate',\n",
       " 'f100': 'duration_add_emp_var_rate',\n",
       " 'f101': 'duration_sub_emp_var_rate',\n",
       " 'f102': 'duration_mult_cons_price_idx',\n",
       " 'f103': 'duration_div_cons_price_idx',\n",
       " 'f104': 'duration_add_cons_price_idx',\n",
       " 'f105': 'duration_sub_cons_price_idx',\n",
       " 'f106': 'duration_mult_cons_conf_idx',\n",
       " 'f107': 'duration_div_cons_conf_idx',\n",
       " 'f108': 'duration_add_cons_conf_idx',\n",
       " 'f109': 'duration_sub_cons_conf_idx',\n",
       " 'f110': 'duration_mult_euribor3m',\n",
       " 'f111': 'duration_div_euribor3m',\n",
       " 'f112': 'duration_add_euribor3m',\n",
       " 'f113': 'duration_sub_euribor3m',\n",
       " 'f114': 'duration_mult_nr_employed',\n",
       " 'f115': 'duration_div_nr_employed',\n",
       " 'f116': 'duration_add_nr_employed',\n",
       " 'f117': 'duration_sub_nr_employed',\n",
       " 'f118': 'campaign_mult_pdays',\n",
       " 'f119': 'campaign_div_pdays',\n",
       " 'f120': 'campaign_add_pdays',\n",
       " 'f121': 'campaign_sub_pdays',\n",
       " 'f122': 'campaign_mult_previous',\n",
       " 'f123': 'campaign_div_previous',\n",
       " 'f124': 'campaign_add_previous',\n",
       " 'f125': 'campaign_sub_previous',\n",
       " 'f126': 'campaign_mult_emp_var_rate',\n",
       " 'f127': 'campaign_div_emp_var_rate',\n",
       " 'f128': 'campaign_add_emp_var_rate',\n",
       " 'f129': 'campaign_sub_emp_var_rate',\n",
       " 'f130': 'campaign_mult_cons_price_idx',\n",
       " 'f131': 'campaign_div_cons_price_idx',\n",
       " 'f132': 'campaign_add_cons_price_idx',\n",
       " 'f133': 'campaign_sub_cons_price_idx',\n",
       " 'f134': 'campaign_mult_cons_conf_idx',\n",
       " 'f135': 'campaign_div_cons_conf_idx',\n",
       " 'f136': 'campaign_add_cons_conf_idx',\n",
       " 'f137': 'campaign_sub_cons_conf_idx',\n",
       " 'f138': 'campaign_mult_euribor3m',\n",
       " 'f139': 'campaign_div_euribor3m',\n",
       " 'f140': 'campaign_add_euribor3m',\n",
       " 'f141': 'campaign_sub_euribor3m',\n",
       " 'f142': 'campaign_mult_nr_employed',\n",
       " 'f143': 'campaign_div_nr_employed',\n",
       " 'f144': 'campaign_add_nr_employed',\n",
       " 'f145': 'campaign_sub_nr_employed',\n",
       " 'f146': 'pdays_mult_previous',\n",
       " 'f147': 'pdays_div_previous',\n",
       " 'f148': 'pdays_add_previous',\n",
       " 'f149': 'pdays_sub_previous',\n",
       " 'f150': 'pdays_mult_emp_var_rate',\n",
       " 'f151': 'pdays_div_emp_var_rate',\n",
       " 'f152': 'pdays_add_emp_var_rate',\n",
       " 'f153': 'pdays_sub_emp_var_rate',\n",
       " 'f154': 'pdays_mult_cons_price_idx',\n",
       " 'f155': 'pdays_div_cons_price_idx',\n",
       " 'f156': 'pdays_add_cons_price_idx',\n",
       " 'f157': 'pdays_sub_cons_price_idx',\n",
       " 'f158': 'pdays_mult_cons_conf_idx',\n",
       " 'f159': 'pdays_div_cons_conf_idx',\n",
       " 'f160': 'pdays_add_cons_conf_idx',\n",
       " 'f161': 'pdays_sub_cons_conf_idx',\n",
       " 'f162': 'pdays_mult_euribor3m',\n",
       " 'f163': 'pdays_div_euribor3m',\n",
       " 'f164': 'pdays_add_euribor3m',\n",
       " 'f165': 'pdays_sub_euribor3m',\n",
       " 'f166': 'pdays_mult_nr_employed',\n",
       " 'f167': 'pdays_div_nr_employed',\n",
       " 'f168': 'pdays_add_nr_employed',\n",
       " 'f169': 'pdays_sub_nr_employed',\n",
       " 'f170': 'previous_mult_emp_var_rate',\n",
       " 'f171': 'previous_div_emp_var_rate',\n",
       " 'f172': 'previous_add_emp_var_rate',\n",
       " 'f173': 'previous_sub_emp_var_rate',\n",
       " 'f174': 'previous_mult_cons_price_idx',\n",
       " 'f175': 'previous_div_cons_price_idx',\n",
       " 'f176': 'previous_add_cons_price_idx',\n",
       " 'f177': 'previous_sub_cons_price_idx',\n",
       " 'f178': 'previous_mult_cons_conf_idx',\n",
       " 'f179': 'previous_div_cons_conf_idx',\n",
       " 'f180': 'previous_add_cons_conf_idx',\n",
       " 'f181': 'previous_sub_cons_conf_idx',\n",
       " 'f182': 'previous_mult_euribor3m',\n",
       " 'f183': 'previous_div_euribor3m',\n",
       " 'f184': 'previous_add_euribor3m',\n",
       " 'f185': 'previous_sub_euribor3m',\n",
       " 'f186': 'previous_mult_nr_employed',\n",
       " 'f187': 'previous_div_nr_employed',\n",
       " 'f188': 'previous_add_nr_employed',\n",
       " 'f189': 'previous_sub_nr_employed',\n",
       " 'f190': 'emp_var_rate_mult_cons_price_idx',\n",
       " 'f191': 'emp_var_rate_div_cons_price_idx',\n",
       " 'f192': 'emp_var_rate_add_cons_price_idx',\n",
       " 'f193': 'emp_var_rate_sub_cons_price_idx',\n",
       " 'f194': 'emp_var_rate_mult_cons_conf_idx',\n",
       " 'f195': 'emp_var_rate_div_cons_conf_idx',\n",
       " 'f196': 'emp_var_rate_add_cons_conf_idx',\n",
       " 'f197': 'emp_var_rate_sub_cons_conf_idx',\n",
       " 'f198': 'emp_var_rate_mult_euribor3m',\n",
       " 'f199': 'emp_var_rate_div_euribor3m',\n",
       " 'f200': 'emp_var_rate_add_euribor3m',\n",
       " 'f201': 'emp_var_rate_sub_euribor3m',\n",
       " 'f202': 'emp_var_rate_mult_nr_employed',\n",
       " 'f203': 'emp_var_rate_div_nr_employed',\n",
       " 'f204': 'emp_var_rate_add_nr_employed',\n",
       " 'f205': 'emp_var_rate_sub_nr_employed',\n",
       " 'f206': 'cons_price_idx_mult_cons_conf_idx',\n",
       " 'f207': 'cons_price_idx_div_cons_conf_idx',\n",
       " 'f208': 'cons_price_idx_add_cons_conf_idx',\n",
       " 'f209': 'cons_price_idx_sub_cons_conf_idx',\n",
       " 'f210': 'cons_price_idx_mult_euribor3m',\n",
       " 'f211': 'cons_price_idx_div_euribor3m',\n",
       " 'f212': 'cons_price_idx_add_euribor3m',\n",
       " 'f213': 'cons_price_idx_sub_euribor3m',\n",
       " 'f214': 'cons_price_idx_mult_nr_employed',\n",
       " 'f215': 'cons_price_idx_div_nr_employed',\n",
       " 'f216': 'cons_price_idx_add_nr_employed',\n",
       " 'f217': 'cons_price_idx_sub_nr_employed',\n",
       " 'f218': 'cons_conf_idx_mult_euribor3m',\n",
       " 'f219': 'cons_conf_idx_div_euribor3m',\n",
       " 'f220': 'cons_conf_idx_add_euribor3m',\n",
       " 'f221': 'cons_conf_idx_sub_euribor3m',\n",
       " 'f222': 'cons_conf_idx_mult_nr_employed',\n",
       " 'f223': 'cons_conf_idx_div_nr_employed',\n",
       " 'f224': 'cons_conf_idx_add_nr_employed',\n",
       " 'f225': 'cons_conf_idx_sub_nr_employed',\n",
       " 'f226': 'euribor3m_mult_nr_employed',\n",
       " 'f227': 'euribor3m_div_nr_employed',\n",
       " 'f228': 'euribor3m_add_nr_employed',\n",
       " 'f229': 'euribor3m_sub_nr_employed',\n",
       " 'f230': 'age_binned',\n",
       " 'f231': 'duration_binned',\n",
       " 'f232': 'campaign_binned',\n",
       " 'f233': 'emp_var_rate_binned',\n",
       " 'f234': 'cons_price_idx_binned',\n",
       " 'f235': 'cons_conf_idx_binned',\n",
       " 'f236': 'euribor3m_binned',\n",
       " 'f237': 'nr_employed_binned'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_selector.feature_idx_name_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7135eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/15 11:09:42 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 928440 ms exceeds timeout 120000 ms\n",
      "26/01/15 11:09:42 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "26/01/15 11:09:43 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:322)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
      "\t... 17 more\n",
      "26/01/15 11:09:43 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:322)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
      "\t... 17 more\n",
      "26/01/15 11:09:53 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:09:53 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:10:03 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:10:03 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:10:13 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:10:13 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:10:23 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:10:23 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:21:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:21:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:21:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:21:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:21:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:21:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:21:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:21:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:21:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:21:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:39:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:39:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:39:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:39:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:39:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:39:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:39:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:39:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:39:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:39:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:40:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:40:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:40:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:40:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:40:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:40:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:40:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:40:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:40:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:40:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:40:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:40:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:41:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:41:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:41:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:41:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:41:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:41:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:41:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:41:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:43:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:43:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:43:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:43:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:43:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:43:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:43:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:43:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:43:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:43:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:51:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:51:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:52:00 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:52:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:52:10 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:52:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:52:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:52:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:52:30 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:52:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:53:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:53:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:53:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:53:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:53:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:53:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:53:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:53:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:53:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:53:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:54:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:54:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:54:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:54:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:54:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:54:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:54:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:54:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:54:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:54:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:54:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:54:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:55:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:55:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:55:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:55:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:55:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:55:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:55:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:322)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
      "\t... 17 more\n",
      "26/01/15 11:55:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:322)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
      "\t... 17 more\n",
      "26/01/15 11:55:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:55:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:55:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:55:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:56:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:56:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:56:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:56:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:56:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:56:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:56:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:56:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:56:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:322)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
      "\t... 17 more\n",
      "26/01/15 11:56:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:322)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
      "\t... 17 more\n",
      "26/01/15 11:56:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:56:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:57:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:57:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:57:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:57:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1324)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:322)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.5:54902\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "26/01/15 11:57:15 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n",
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 55402)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aays/.local/share/uv/python/cpython-3.12.12-macos-aarch64-none/lib/python3.12/socketserver.py\", line 318, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/Users/aays/.local/share/uv/python/cpython-3.12.12-macos-aarch64-none/lib/python3.12/socketserver.py\", line 349, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/Users/aays/.local/share/uv/python/cpython-3.12.12-macos-aarch64-none/lib/python3.12/socketserver.py\", line 362, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/Users/aays/.local/share/uv/python/cpython-3.12.12-macos-aarch64-none/lib/python3.12/socketserver.py\", line 766, in __init__\n",
      "    self.handle()\n",
      "  File \"/Users/aays/Documents/aays/spark_beyond/.venv/lib/python3.12/site-packages/pyspark/accumulators.py\", line 303, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/Users/aays/Documents/aays/spark_beyond/.venv/lib/python3.12/site-packages/pyspark/accumulators.py\", line 272, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/Users/aays/Documents/aays/spark_beyond/.venv/lib/python3.12/site-packages/pyspark/accumulators.py\", line 276, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aays/Documents/aays/spark_beyond/.venv/lib/python3.12/site-packages/pyspark/serializers.py\", line 597, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fix Bug - total features are 249 only 238 are captured here\n",
    "len(feature_selector.feature_idx_name_mapping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-beyond",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
